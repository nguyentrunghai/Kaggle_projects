{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will tune the **XGBoost** model using the minimal data set `X_train_0.csv` and `X_test_0.csv` which are taken from `application_train.csv` and `application_test.csv` without merging with other tables. After the first round of model tuning, we will try to do some feature engineering. Finally, we will tune the model again on the \"best\" feature set to obtain the Kaggle submission file for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from _preprocessing import change_dtypes\n",
    "from _preprocessing import deal_with_abnormal_days_employed\n",
    "\n",
    "INP_DIR = \"data/data_\"\n",
    "TUNING_DIR = \"data/tuning_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--n_jobs N_JOBS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/nthai/Library/Jupyter/runtime/kernel-6d3eda6e-29b9-44b9-be34-1d24cd717a81.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# This is useful for running non-interactively in a remote linux cluster\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_jobs\", type=int, default=1)\n",
    "args = parser.parse_args()\n",
    "n_jobs = args.n_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `X_train_0.csv` and `X_test_0.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 284.45 MB\n",
      "Memory usage after changing types 128.24 MB\n",
      "Memory usage before changing types 45.09 MB\n",
      "Memory usage after changing types 20.33 MB\n",
      "X_train_0 shape: (307511, 120)\n",
      "y_train shape: (307511,)\n",
      "X_test_0 shape: (48744, 120)\n",
      "id_test shape: (48744, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_0 = pd.read_csv(os.path.join(INP_DIR, \"X_train_0.csv\"))\n",
    "X_train_0 = change_dtypes(X_train_0)\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(INP_DIR, \"y_train.csv\"))\n",
    "y_train = y_train[\"TARGET\"]\n",
    "\n",
    "X_test_0 = pd.read_csv(os.path.join(INP_DIR, \"X_test_0.csv\"))\n",
    "X_test_0 = change_dtypes(X_test_0)\n",
    "\n",
    "id_test = pd.read_csv(os.path.join(INP_DIR, \"id_test.csv\"))\n",
    "\n",
    "print(\"X_train_0 shape:\", X_train_0.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test_0 shape:\", X_test_0.shape)\n",
    "print(\"id_test shape:\", id_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_0_prep shape (307511, 245)\n",
      "X_test_0_prep shape (48744, 242)\n"
     ]
    }
   ],
   "source": [
    "# Modify abnormal value in DAYS_EMPLOYED\n",
    "X_train_0_prep = deal_with_abnormal_days_employed(X_train_0)\n",
    "X_test_0_prep = deal_with_abnormal_days_employed(X_test_0)\n",
    "\n",
    "# Onehot enconding\n",
    "X_train_0_prep = pd.get_dummies(X_train_0_prep)\n",
    "X_test_0_prep = pd.get_dummies(X_test_0_prep)\n",
    "\n",
    "print(\"X_train_0_prep shape\", X_train_0_prep.shape)\n",
    "print(\"X_test_0_prep shape\", X_test_0_prep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `XGBoost` can deal with missing values, we will not impute them. It is based on trees, so feature scaling is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC of XGBoost model: 0.75116 +/- 0.00264\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=123)\n",
    "cv_scores = cross_val_score(XGBClassifier(), X_train_0_prep, y_train, scoring=\"roc_auc\", cv=kfold)\n",
    "print(\"CV AUC of XGBoost model: %0.5f +/- %0.5f\" % (cv_scores.mean(), cv_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_learning_rate = 0.3\n",
    "slow_learning_rate = 0.01\n",
    "\n",
    "early_stopping_begin_pickle = os.path.join(TUNING_DIR, \"early_stopping_begin.pkl\")\n",
    "grid_search_steps_pickle = os.path.join(TUNING_DIR, \"grid_search_steps.pkl\")\n",
    "early_stopping_end_pickle = os.path.join(TUNING_DIR, \"early_stopping_end.pkl\")\n",
    "\n",
    "# construct the estimator\n",
    "xgb = XGBClassifier(learning_rate=fast_learning_rate, subsample=0.8, colsample_bytree=0.8, n_jobs=n_jobs)\n",
    "\n",
    "# tune n_estimators by early stopping using fast learning rate\n",
    "xgb = tune_n_estimators_w_early_stopping(xgb, X_cancer_train_std, y_cancer_train,\n",
    "                                   max_n_estimators=5000, eval_size=0.2,\n",
    "                                   eval_metric=\"auc\",\n",
    "                                   early_stopping_rounds=50,\n",
    "                                   random_state=123, pkl_out=\"early_stopping_begin.pkl\")\n",
    "\n",
    "# tune other hyper-parameters by grid search\n",
    "step_1 = dict(max_depth=range(3, 11))\n",
    "\n",
    "step_2 = dict(gamma=gamma_grid=[0, 0.2, 0.4, 0.6, 0.8, 1.])\n",
    "\n",
    "step_3 = dict(subsample=[0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "step_4 = dict(colsample_bytree=[0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "step_5 = dict(colsample_bylevel=[0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "step_6 = dict(reg_lambda=[1e-5, 1e-3, 1e-1, 1, 10, 100])\n",
    "\n",
    "params_grid_steps = [step_1, step_2, step_3, step_4, step_5, step_6]\n",
    "print(\"params_grid_steps\", params_grid_steps)\n",
    "\n",
    "results = grid_search_stepwise(xgb, X_cancer_train_std, y_cancer_train, params_grid_steps, \n",
    "                               scoring=\"roc_auc\", cv=5,\n",
    "                               random_state=456, pkl_out=grid_search_steps_pickle)\n",
    "\n",
    "# tune n_estimators by early stopping using slow learning rate\n",
    "xgb = results[\"best_estimator\"]\n",
    "best_params = xgb.get_params()\n",
    "best_params[\"learning_rate\"] = slow_learning_rate\n",
    "xgb.set_params(**best_params)\n",
    "\n",
    "xgb = tune_n_estimators_w_early_stopping(xgb, X_cancer_train_std, y_cancer_train,\n",
    "                                   max_n_estimators=5000, eval_size=0.2,\n",
    "                                   eval_metric=\"auc\",\n",
    "                                   early_stopping_rounds=50,\n",
    "                                   random_state=123, pkl_out=early_stopping_end_pickle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
