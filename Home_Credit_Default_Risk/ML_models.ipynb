{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_ser(ser):\n",
    "    if ser.dtype == int and (set(ser.unique()) == set([0, 1])):\n",
    "        return ser.astype(np.bool)\n",
    "    \n",
    "    if ser.dtype == int:\n",
    "        return ser.astype(np.int32)\n",
    "    \n",
    "    if ser.dtype == float and (set(ser.unique()) == set([0., 1.])):\n",
    "        return ser.astype(np.bool)\n",
    "    \n",
    "    if ser.dtype == float:\n",
    "        return ser.astype(np.float32)\n",
    "    \n",
    "    if (ser.dtype == \"object\") and (set(ser.unique()) == set([\"Y\", \"N\"])):\n",
    "        ser = ser.map({\"Y\": 1, \"N\": 0})\n",
    "        return ser.astype(np.bool)\n",
    "    \n",
    "    if (ser.dtype == \"object\") and (ser.nunique() < ser.shape[0]):\n",
    "        return ser.astype(\"category\")\n",
    "    \n",
    "    return ser\n",
    "    \n",
    "\n",
    "\n",
    "def change_dtype_df(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = change_dtype_ser(df[col])\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtype_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_array=False):\n",
    "        self._to_array = to_array\n",
    "        \n",
    "    def fit(self, df_train):\n",
    "        num_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        self._mean = {col: df_train[col].mean() for col in num_cols}\n",
    "        self._std = {col: df_train[col].std() for col in num_cols}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        for col in self._mean:\n",
    "            if self._std[col] > 0:\n",
    "                df[col] = (df[col] - self._mean[col]) / self._std[col]\n",
    "                df[col] = df[col].astype(\"float32\")\n",
    "            else:\n",
    "                print(\"WARNING: \" + col + \" has zero std.\")\n",
    "                df[col] = df[col] - self._mean[col]\n",
    "                df[col] = df[col].astype(\"float32\")\n",
    "                \n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_array=False):\n",
    "        self._to_array = to_array\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        all_cols = df_train.columns.to_list()\n",
    "        cat_cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        \n",
    "        self._cat_col_idx = [i for i, col in enumerate(all_cols) if col in cat_cols]\n",
    "        \n",
    "        self._label_maps = {}\n",
    "        self._missing_imputers = {}\n",
    "        for col in cat_cols:\n",
    "            label = df_train[col].unique()\n",
    "            self._label_maps[col] = {c: n for n, c in enumerate(label)}\n",
    "            \n",
    "            mode_label = df_train[col].mode().iloc[0]\n",
    "            self._missing_imputers[col] = self._label_maps[col][mode_label]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        for col, label_map in self._label_maps.items():\n",
    "            df[col] = df[col].map(label_map)\n",
    "            if df[col].isnull().any():\n",
    "                df[col] = df[col].astype(np.float32).fillna(self._missing_imputers[col])\n",
    "                \n",
    "        self._fatures = df.columns.to_list()\n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "    def get_cat_cols(self):\n",
    "        return self._cat_col_idx\n",
    "    \n",
    "\n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_array=False):\n",
    "        self._to_array = to_array\n",
    "        \n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        df_cat = train_df.select_dtypes([\"object\", \"category\"])\n",
    "        self._cat_cols = df_cat.columns.to_list()\n",
    "        \n",
    "        if len(self._cat_cols) > 0:\n",
    "            self._cat_cols_ohe = pd.get_dummies(df_cat, drop_first=True).columns.to_list()\n",
    "        else:\n",
    "            self._cat_cols_ohe = []\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if len(self._cat_cols) == 0:\n",
    "            print(\"No cat cols in df_train, so do nothing.\")\n",
    "            return df\n",
    "        \n",
    "        df_cat = df.select_dtypes([\"object\", \"category\"])\n",
    "        cat_cols = df_cat.columns.to_list()\n",
    "        assert set(cat_cols) == set(self._cat_cols), \"df does not have the same categorical cols as train_df\"\n",
    "        \n",
    "        # one-hot encode\n",
    "        df_cat = pd.get_dummies(df_cat)\n",
    "        # drop cols that are present in test_df but absent in train_df\n",
    "        cols_to_drop = [col for col in df_cat.columns if col not in self._cat_cols_ohe]\n",
    "        df_cat = df_cat.drop(cols_to_drop, axis=\"columns\")\n",
    "        \n",
    "        # change to float32\n",
    "        for col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].astype(\"float32\")\n",
    "        \n",
    "        # if some some colums are absent in test but present in train, make them all zero \n",
    "        cat_cols_ohe = df_cat.columns.to_list()\n",
    "        for col in self._cat_cols_ohe:\n",
    "            if col not in cat_cols_ohe:\n",
    "                df_cat[col] = 0\n",
    "                df_cat[col] = df_cat[col].astype(np.uint8)\n",
    "        \n",
    "        num_cols = [col for col in df.columns if col not in cat_cols]\n",
    "        df_num = df[num_cols]\n",
    "        \n",
    "        df = pd.concat([df_num, df_cat], axis=\"columns\")\n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(estimator, X_eval, y_eval):\n",
    "    \"\"\"\n",
    "    :param estimator: sklearn estimator that have predict_proba() method\n",
    "    :param X_eval: test features\n",
    "    :param y_eval: test target\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    proba = estimator.predict_proba(X_eval)\n",
    "    return roc_auc_score(y_eval, proba[:, 1])\n",
    "\n",
    "\n",
    "def write_submit_csv(estimator, X_test, id_test, out):\n",
    "    \"\"\"\n",
    "    :param estimator: a sklearn estimator that has predict_proba() method\n",
    "    :param X_test: df or array\n",
    "    :param id_test: dataframe containing column \"SK_ID_CURR\"\n",
    "    :param out: str, csv output file name\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    prob_test = estimator.predict_proba(X_test)[:, 1]\n",
    "    submit = id_test.copy()\n",
    "    submit[\"TARGET\"] = prob_test\n",
    "    submit.to_csv(out, index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def feature_importance_df(estimator, features):\n",
    "    \"\"\"\n",
    "    :param estimator: an estimator object that has feature_importances_ attribute\n",
    "    :param features: list of str, list of feature names\n",
    "    :return: feature_imp, dataframe\n",
    "    \"\"\"\n",
    "    feature_imp = pd.DataFrame({\"feature\": features, \"importance\": estimator.feature_importances_})\n",
    "    feature_imp = feature_imp.sort_values(by=[\"importance\"], ascending=False)\n",
    "    \n",
    "    feature_imp[\"rank\"] = np.arange(feature_imp.shape[0]) + 1\n",
    "    return feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyperopt(classifier,\n",
    "                 params_tuned, \n",
    "                 X_train, y_train,\n",
    "                 num_eval,\n",
    "                 params_fixed=None,\n",
    "                 rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective(params):\n",
    "        classifier.set_params(**params_fixed, **params)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        auc = cross_val_score(classifier, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "        return {\"loss\": -auc, \"status\": STATUS_OK}\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "        \n",
    "    trials = Trials()\n",
    "    best_params = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    best_params = whole_to_int(best_params)\n",
    "    best_model = classifier.set_params(**params_fixed, **best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    return trials, best_params, best_model\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def hyperopt_lr(params_tuned, \n",
    "                X_train, y_train, \n",
    "                X_val, y_val, \n",
    "                num_eval,\n",
    "                params_fixed=None,\n",
    "                rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20}\n",
    "    \n",
    "    def objective(params):\n",
    "        estimator = LogisticRegression(**params_fixed, **params)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        auc = roc_auc(estimator, X_val, y_val)\n",
    "        return {\"loss\": -auc, \"status\": STATUS_OK}\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "        \n",
    "    trials = Trials()\n",
    "    best_param = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    return trials, best_param\n",
    "\n",
    "\n",
    "\n",
    "def hyperopt_rf(params_tuned, \n",
    "                X_train, y_train, \n",
    "                X_val, y_val, \n",
    "                num_eval, \n",
    "                params_fixed=None,\n",
    "                rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective(params):\n",
    "        estimator = RandomForestClassifier(**params_fixed, **params)\n",
    "        (estimator.get_params())\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        auc = roc_auc(estimator, X_val, y_val)\n",
    "        return {\"loss\": -auc, \"status\": STATUS_OK}\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "    \n",
    "    trials = Trials()\n",
    "    best_param = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    return trials, best_param\n",
    "\n",
    "\n",
    "def hyperopt_xgb(params_tuned, \n",
    "                 X_train, y_train, \n",
    "                 X_val, y_val, \n",
    "                 num_eval, \n",
    "                 params_fixed=None,\n",
    "                 rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective(params):\n",
    "        estimator = XGBClassifier(**params_fixed, **params)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        auc = roc_auc(estimator, X_val, y_val)\n",
    "        return {\"loss\": -auc, \"status\": STATUS_OK}\n",
    "\n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "    trials = Trials()\n",
    "    best_param = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    return trials, best_param\n",
    "\n",
    "\n",
    "def hyperopt_lgbm(params_tuned, \n",
    "                  X_train, y_train, \n",
    "                  X_val, y_val, \n",
    "                  num_eval, \n",
    "                  params_fixed=None,\n",
    "                  rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective(params):\n",
    "        estimator = LGBMClassifier(**params_fixed, **params)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        auc = roc_auc(estimator, X_val, y_val)\n",
    "        return {\"loss\": -auc, \"status\": STATUS_OK}\n",
    "\n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "    trials = Trials()\n",
    "    best_param = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    return trials, best_param\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_to_int(a_dict):\n",
    "    new_dict = copy.deepcopy(a_dict)\n",
    "    for k, v in new_dict.items():\n",
    "        if np.isclose(np.round(v), v):\n",
    "            new_dict[k] = int(new_dict[k])\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def averaging_y_hat(submit_csv_files):\n",
    "    y_hats = [pd.read_csv(f) for f in submit_csv_files]\n",
    "    result = y_hats[0][[\"SK_ID_CURR\"]]\n",
    "    result[\"TARGET\"] = 0.\n",
    "    for y in y_hats:\n",
    "        result[\"TARGET\"] = result[\"TARGET\"] + y[\"TARGET\"]\n",
    "    \n",
    "    result[\"TARGET\"] = result[\"TARGET\"] / len(y_hats)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIR = \"data/data3_\"\n",
    "SUB_DIR = \"data/submit_\"\n",
    "MODELS_DIR = \"data/models_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_full_train = load_csv(os.path.join(IN_DIR, \"X_y_train.csv\"))\n",
    "X_test = load_csv(os.path.join(IN_DIR, \"X_test.csv\"))\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_full_train.isnull().sum().sum:\", X_full_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_full_train = X_full_train[\"APPL_TARGET\"].values\n",
    "X_full_train = X_full_train.drop([\"APPL_TARGET\", \"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = X_full_train.columns.to_list()\n",
    "sk_id_test = X_test[[\"SK_ID_CURR\"]]\n",
    "X_test = X_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 5223.69 MB\n",
      "Memory usage after changing types 2568.97 MB\n",
      "Memory usage before changing types 827.62 MB\n",
      "Memory usage after changing types 407.03 MB\n",
      "X_train.shape (307511, 2147)\n",
      "X_test.shape (48744, 2146)\n",
      "X_train.isnull().sum().sum: 0\n",
      "X_test.isnull().sum().sum: 0\n",
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2146)\n",
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2145)\n",
      "Elapsed Time 1352.9275920391083\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_full_train = load_csv(os.path.join(IN_DIR, \"X_y_train.csv\"))\n",
    "X_test = load_csv(os.path.join(IN_DIR, \"X_test.csv\"))\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_full_train.isnull().sum().sum:\", X_full_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_full_train = X_full_train[\"APPL_TARGET\"].values\n",
    "X_full_train = X_full_train.drop([\"APPL_TARGET\", \"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = X_full_train.columns.to_list()\n",
    "sk_id_test = X_test[[\"SK_ID_CURR\"]]\n",
    "X_test = X_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (307511, 2477)\n",
      "X_test.shape (48744, 2477)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_full_train)\n",
    "X_full_train = ohe.transform(X_full_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = X_full_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (307511, 2477)\n",
      "X_test.shape (48744, 2477)\n"
     ]
    }
   ],
   "source": [
    "scaler = Standardizer(to_array=True)\n",
    "scaler.fit(X_full_train)\n",
    "X_full_train = scaler.transform(X_full_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246008, 2477), (246008,), (61503, 2477), (61503,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline (not tuned) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=100, n_jobs=20)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Logistic regression model on the train set: 0.79900\n",
      "AUC of Logistic regression model on the evaluation set: 0.77225\n"
     ]
    }
   ],
   "source": [
    "auc_lr_train = roc_auc(lr, X_train, y_train)\n",
    "print(\"AUC of Logistic regression model on the train set: %0.5f\" % auc_lr_train)\n",
    "\n",
    "auc_lr_val = roc_auc(lr, X_val, y_val)\n",
    "print(\"AUC of Logistic regression model on the evaluation set: %0.5f\" % auc_lr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "write_submit_csv(lr, X_test, sk_id_test, os.path.join(SUB_DIR, \"lr_data3_baseline.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning using `hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"C\": hp.loguniform('C', np.log(0.00001), np.log(100))}\n",
    "num_eval = 10\n",
    "\n",
    "lr = LogisticRegression()\n",
    "trials, best_params, best_model = run_hyperopt(lr, params, X_train, y_train, X_val, y_val, num_eval)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lr_data3_tuned.csv\")\n",
    "write_submit_csv(best_model, X_test, sk_id_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lr_data3_tuned.pickle\")\n",
    "pickle.dump(best_model, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=20)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Random Forest model on the train set: 1.00000\n",
      "AUC of Random Forest model on the evaluation set: 0.72982\n"
     ]
    }
   ],
   "source": [
    "auc_rf_train = roc_auc(rf, X_train, y_train)\n",
    "print(\"AUC of Random Forest model on the train set: %0.5f\" % auc_rf_train)\n",
    "\n",
    "auc_rf_val = roc_auc(rf, X_val, y_val)\n",
    "print(\"AUC of Random Forest model on the evaluation set: %0.5f\" % auc_rf_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning using `hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    #\"min_samples_split\": scope.int(hp.quniform(\"min_samples_split\", 20, 400, 10)),\n",
    "    \"min_samples_leaf\": scope.int(hp.quniform(\"min_samples_leaf\", 20, 200, 10)), \n",
    "    \"max_features\": scope.int(hp.quniform(\"max_features\", 10, 200, 1)),\n",
    "}\n",
    "\n",
    "params_fixed_rf = {\n",
    "    \"n_jobs\": 20,\n",
    "    \"n_estimators\": 100\n",
    "}\n",
    "\n",
    "\n",
    "num_eval = 60\n",
    "\n",
    "trials_rf, best_params_rf = hyperopt_rf(params_rf, \n",
    "                                        X_train, y_train, X_val, y_val, \n",
    "                                        num_eval,\n",
    "                                        params_fixed=params_fixed_rf,\n",
    "                                        rstate=32003)\n",
    "best_params_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = {s: int(best_params_rf[s]) for s in best_params_rf}\n",
    "best_params_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(n_estimators=500, n_jobs=20, **best_params_rf)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "auc_rf_train = roc_auc(rf_best, X_train, y_train)\n",
    "print(\"AUC of Random Forest model on the train set: %0.5f\" % auc_rf_train)\n",
    "\n",
    "auc_rf_val = roc_auc(rf_best, X_val, y_val)\n",
    "print(\"AUC of Random Forest model on the evaluation set: %0.5f\" % auc_rf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"rf_data3_tuned.csv\")\n",
    "write_submit_csv(rf_best, X_test, sk_id_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"rf_data3_tuned.pickle\")\n",
    "pickle.dump(rf_best, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 5223.69 MB\n",
      "Memory usage after changing types 2568.97 MB\n",
      "Memory usage before changing types 827.62 MB\n",
      "Memory usage after changing types 407.03 MB\n",
      "X_train.shape (307511, 2147)\n",
      "X_test.shape (48744, 2146)\n",
      "X_train.isnull().sum().sum: 0\n",
      "X_test.isnull().sum().sum: 0\n",
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2146)\n",
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2145)\n",
      "Elapsed Time 1537.468981742859\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_full_train = load_csv(os.path.join(IN_DIR, \"X_y_train.csv\"))\n",
    "X_test = load_csv(os.path.join(IN_DIR, \"X_test.csv\"))\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_full_train.isnull().sum().sum:\", X_full_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_full_train = X_full_train[\"APPL_TARGET\"].values\n",
    "X_full_train = X_full_train.drop([\"APPL_TARGET\", \"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = X_full_train.columns.to_list()\n",
    "sk_id_test = X_test[[\"SK_ID_CURR\"]]\n",
    "X_test = X_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (307511, 2477)\n",
      "X_test.shape (48744, 2477)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_full_train)\n",
    "X_full_train = ohe.transform(X_full_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246008, 2477), (246008,), (61503, 2477), (61503,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of XGBOOST model on the train set: 0.91127\n",
      "AUC of XGBOOST model on the validation set: 0.77461\n",
      "Time elapsed: 234.91595 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "xgb = XGBClassifier(tree_method=\"gpu_hist\")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "auc_xgb_train = roc_auc(xgb, X_train, y_train)\n",
    "print(\"AUC of XGBOOST model on the train set: %0.5f\" % auc_xgb_train)\n",
    "\n",
    "auc_xgb_val = roc_auc(xgb, X_val, y_val)\n",
    "print(\"AUC of XGBOOST model on the validation set: %0.5f\" % auc_xgb_val)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Time elapsed: %0.5f s\" % time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning using `hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [27:37:37<00:00, 497.29s/trial, best loss: -0.7928299059136121]   \n",
      "Time elapsed: 99458.38221 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.43432432470594506,\n",
       " 'gamma': 0.3354020590533102,\n",
       " 'learning_rate': 0.05779942715385299,\n",
       " 'max_depth': 8.0,\n",
       " 'min_child_weight': 3.0,\n",
       " 'reg_lambda': 380.36755231614643,\n",
       " 'subsample': 0.88624379991172}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_xgb = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"min_child_weight\": scope.int(hp.quniform(\"min_child_weight\", 1, 16, 1)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.01), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.0001), np.log(100)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.001), np.log(0.5)),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0., 2.),\n",
    "}\n",
    "\n",
    "params_fixed_xgb = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"tree_method\": \"gpu_hist\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 200\n",
    "\n",
    "trials_xgb, best_params_xgb = hyperopt_xgb(params_xgb, \n",
    "                                           X_train, y_train, X_val, y_val, \n",
    "                                           num_eval,\n",
    "                                           params_fixed=params_fixed_xgb,\n",
    "                                           rstate=40292)\n",
    "best_params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.43432432470594506,\n",
       " 'gamma': 0.3354020590533102,\n",
       " 'learning_rate': 0.05779942715385299,\n",
       " 'max_depth': 8.0,\n",
       " 'min_child_weight': 3.0,\n",
       " 'reg_lambda': 380.36755231614643,\n",
       " 'subsample': 0.88624379991172}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'colsample_bytree': 0.43432432470594506,\n",
    " 'gamma': 0.3354020590533102,\n",
    " 'learning_rate': 0.05779942715385299,\n",
    " 'max_depth': 8.0,\n",
    " 'min_child_weight': 3.0,\n",
    " 'reg_lambda': 380.36755231614643,\n",
    " 'subsample': 0.88624379991172}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of XGBoost model on the train set: 0.88741\n",
      "AUC of XGBoost model on the evaluation set: 0.79283\n"
     ]
    }
   ],
   "source": [
    "best_params_xgb = whole_to_int(best_params_xgb)\n",
    "\n",
    "xgb_best = XGBClassifier(**params_fixed_xgb, **best_params_xgb)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "auc_xgb_train = roc_auc(xgb_best, X_train, y_train)\n",
    "print(\"AUC of XGBoost model on the train set: %0.5f\" % auc_xgb_train)\n",
    "\n",
    "auc_xgb_val = roc_auc(xgb_best, X_val, y_val)\n",
    "print(\"AUC of XGBoost model on the evaluation set: %0.5f\" % auc_xgb_val)\n",
    "\n",
    "\n",
    "xgb_best.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"xgb_data5_ohe_tuned_01.csv\")\n",
    "write_submit_csv(xgb_best, X_test, sk_id_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"xgb_data5_ohe_tuned_01.pickle\")\n",
    "pickle.dump(xgb_best, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = feature_importance_df(xgb_best, features)\n",
    "feat_impt.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt[feat_impt[\"feature\"].str.startswith(\"APPL_\")].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 5223.69 MB\n",
      "Memory usage after changing types 2568.97 MB\n",
      "Memory usage before changing types 827.62 MB\n",
      "Memory usage after changing types 407.03 MB\n",
      "X_train.shape (307511, 2147)\n",
      "X_test.shape (48744, 2146)\n",
      "X_train.isnull().sum().sum: 0\n",
      "X_test.isnull().sum().sum: 0\n",
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2146)\n",
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2145)\n",
      "Elapsed Time 1402.5415875911713\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_full_train = load_csv(os.path.join(IN_DIR, \"X_y_train.csv\"))\n",
    "X_test = load_csv(os.path.join(IN_DIR, \"X_test.csv\"))\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_full_train.isnull().sum().sum:\", X_full_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_full_train = X_full_train[\"APPL_TARGET\"].values\n",
    "X_full_train = X_full_train.drop([\"APPL_TARGET\", \"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = X_full_train.columns.to_list()\n",
    "sk_id_test = X_test[[\"SK_ID_CURR\"]]\n",
    "X_test = X_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (307511, 2145)\n",
      "X_test.shape (48744, 2145)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder(to_array=True)\n",
    "X_full_train = le.fit_transform(X_full_train)\n",
    "X_test = le.transform(X_test)\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "cat_col_idx = le.get_cat_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246008, 2145), (246008,), (61503, 2145), (61503,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=4112015)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of XGBOOST model on the train set: 0.91190\n",
      "AUC of XGBOOST model on the validation set: 0.77176\n",
      "Time elapsed: 69.47420 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "xgb = XGBClassifier(tree_method=\"gpu_hist\")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "auc_xgb_train = roc_auc(xgb, X_train, y_train)\n",
    "print(\"AUC of XGBOOST model on the train set: %0.5f\" % auc_xgb_train)\n",
    "\n",
    "auc_xgb_val = roc_auc(xgb, X_val, y_val)\n",
    "print(\"AUC of XGBOOST model on the validation set: %0.5f\" % auc_xgb_val)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Time elapsed: %0.5f s\" % time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning using `hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [7:47:08<00:00, 280.28s/trial, best loss: -0.7895740700307722]  \n",
      "Time elapsed: 28028.48750 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.88063766163331,\n",
       " 'learning_rate': 0.039936412196415395,\n",
       " 'max_depth': 6.0,\n",
       " 'min_child_weight': 2.0,\n",
       " 'reg_lambda': 5.753974775049421,\n",
       " 'subsample': 0.6284760348606167}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_xgb = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"min_child_weight\": scope.int(hp.quniform(\"min_child_weight\", 1, 16, 1)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.01), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.0001), np.log(100)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "    #\"gamma\": hp.uniform(\"gamma\", 0., 2.),\n",
    "}\n",
    "\n",
    "params_fixed_xgb = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"tree_method\": \"gpu_hist\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "trials_xgb, best_params_xgb = hyperopt_xgb(params_xgb, \n",
    "                                           X_train, y_train, X_val, y_val, \n",
    "                                           num_eval,\n",
    "                                           params_fixed=params_fixed_xgb,\n",
    "                                           rstate=63259)\n",
    "best_params_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.88063766163331,\n",
       " 'learning_rate': 0.039936412196415395,\n",
       " 'max_depth': 6.0,\n",
       " 'min_child_weight': 2.0,\n",
       " 'reg_lambda': 5.753974775049421,\n",
       " 'subsample': 0.6284760348606167}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'colsample_bytree': 0.88063766163331,\n",
    " 'learning_rate': 0.039936412196415395,\n",
    " 'max_depth': 6.0,\n",
    " 'min_child_weight': 2.0,\n",
    " 'reg_lambda': 5.753974775049421,\n",
    " 'subsample': 0.6284760348606167}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of XGBoost model on the train set: 0.88458\n",
      "AUC of XGBoost model on the evaluation set: 0.78957\n"
     ]
    }
   ],
   "source": [
    "best_params_xgb = whole_to_int(best_params_xgb)\n",
    "\n",
    "xgb_best = XGBClassifier(**params_fixed_xgb, **best_params_xgb)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "auc_xgb_train = roc_auc(xgb_best, X_train, y_train)\n",
    "print(\"AUC of XGBoost model on the train set: %0.5f\" % auc_xgb_train)\n",
    "\n",
    "auc_xgb_val = roc_auc(xgb_best, X_val, y_val)\n",
    "print(\"AUC of XGBoost model on the evaluation set: %0.5f\" % auc_xgb_val)\n",
    "\n",
    "\n",
    "xgb_best.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"xgb_data5_le_tuned_01.csv\")\n",
    "write_submit_csv(xgb_best, X_test, sk_id_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"xgb_data5_le_tuned_01.pickle\")\n",
    "pickle.dump(xgb_best, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_full_train = load_csv(os.path.join(IN_DIR, \"X_y_train.csv\"))\n",
    "X_test = load_csv(os.path.join(IN_DIR, \"X_test.csv\"))\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_full_train.isnull().sum().sum:\", X_full_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_full_train = X_full_train[\"APPL_TARGET\"].values\n",
    "X_full_train = X_full_train.drop([\"APPL_TARGET\", \"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = X_full_train.columns.to_list()\n",
    "sk_id_test = X_test[[\"SK_ID_CURR\"]]\n",
    "X_test = X_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder(to_array=True)\n",
    "X_full_train = le.fit_transform(X_full_train)\n",
    "X_test = le.transform(X_test)\n",
    "print(\"X_full_train.shape\", X_full_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "cat_col_idx = le.get_cat_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=4112015)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of LightGBM model on the train set: 0.84583\n",
      "AUC of LightGBM model on the validation set: 0.78232\n",
      "Time elapsed: 77.44414 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "lgbm = LGBMClassifier(device=\"gpu\", categorical_feature=cat_col_idx)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "auc_lgbm_train = roc_auc(lgbm, X_train, y_train)\n",
    "print(\"AUC of LightGBM model on the train set: %0.5f\" % auc_lgbm_train)\n",
    "\n",
    "auc_lgbm_val = roc_auc(lgbm, X_val, y_val)\n",
    "print(\"AUC of LightGBM model on the validation set: %0.5f\" % auc_lgbm_val)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Time elapsed: %0.5f s\" % time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning using `hyperopt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gbtree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [01:36<2:39:27, 96.64s/trial, best loss: -0.7223299129849375]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [02:40<2:21:36, 86.70s/trial, best loss: -0.7861111262512284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [03:40<2:07:24, 78.81s/trial, best loss: -0.7861111262512284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [06:44<2:56:42, 110.44s/trial, best loss: -0.7861111262512284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [09:06<3:09:36, 119.75s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [10:21<2:46:45, 106.45s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [12:22<2:51:41, 110.77s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [14:19<2:52:53, 112.76s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [15:19<2:27:00, 96.93s/trial, best loss: -0.7879672476161173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [16:02<2:01:09, 80.77s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [17:34<2:04:22, 83.85s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [19:06<2:06:41, 86.38s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [20:58<2:16:21, 94.05s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [22:46<2:20:52, 98.29s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [24:47<2:28:44, 104.99s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [25:51<2:09:56, 92.81s/trial, best loss: -0.7879672476161173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [27:17<2:05:25, 90.67s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [29:33<2:22:30, 104.28s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [30:19<1:57:23, 86.95s/trial, best loss: -0.7879672476161173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [33:16<2:31:58, 113.98s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [34:48<2:21:27, 107.44s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [37:07<2:31:40, 116.67s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [40:10<2:55:21, 136.64s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [41:50<2:39:14, 125.71s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [43:28<2:26:42, 117.37s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [46:16<2:43:27, 132.53s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [47:46<2:25:51, 119.89s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [49:23<2:15:23, 112.83s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [50:50<2:04:38, 105.33s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [52:16<1:56:07, 99.53s/trial, best loss: -0.7879672476161173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [53:57<1:54:41, 99.74s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [55:28<1:50:17, 97.32s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [57:06<1:48:42, 97.35s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [58:53<1:50:21, 100.32s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [59:56<1:36:37, 89.19s/trial, best loss: -0.7879672476161173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [1:01:05<1:28:43, 83.19s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [1:02:52<1:34:40, 90.17s/trial, best loss: -0.7879672476161173]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [1:03:50<1:23:22, 80.69s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [1:04:41<1:12:54, 71.71s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [1:05:31<1:05:06, 65.11s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [1:06:21<59:39, 60.67s/trial, best loss: -0.7880748600064615]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [1:07:24<59:21, 61.41s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [1:08:33<1:00:23, 63.56s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [1:09:49<1:02:52, 67.36s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [1:10:45<58:26, 63.76s/trial, best loss: -0.7880748600064615]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [1:11:28<52:00, 57.78s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [1:13:01<1:00:19, 68.29s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [1:13:54<55:09, 63.64s/trial, best loss: -0.7880748600064615]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [1:14:46<51:14, 60.28s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [1:15:51<51:15, 61.52s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [1:17:11<54:47, 67.09s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [1:18:20<54:14, 67.79s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [1:19:03<47:12, 60.26s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [1:19:45<42:00, 54.80s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [1:20:44<41:58, 55.97s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [1:22:11<48:01, 65.48s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [1:23:28<49:12, 68.66s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [1:24:45<49:49, 71.17s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [1:25:42<45:46, 66.99s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [1:26:41<43:07, 64.69s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [1:28:30<50:39, 77.93s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [1:29:21<44:14, 69.85s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [1:31:02<48:45, 79.07s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [1:33:20<58:10, 96.96s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [1:34:40<53:38, 91.94s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [1:36:25<54:14, 95.73s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [1:38:06<53:28, 97.24s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [1:40:00<54:29, 102.18s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [1:41:51<54:11, 104.88s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [1:43:54<55:12, 110.41s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [1:45:25<50:36, 104.71s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [1:46:52<46:18, 99.24s/trial, best loss: -0.7880748600064615] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [1:48:22<43:29, 96.64s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [1:50:46<47:56, 110.63s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [1:52:40<46:30, 111.62s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [1:54:26<44:02, 110.09s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [1:55:58<40:04, 104.54s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [1:57:18<35:40, 97.28s/trial, best loss: -0.7880748600064615] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [1:58:12<29:28, 84.22s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [1:58:58<24:18, 72.94s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [2:01:09<28:33, 90.18s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [2:03:32<31:48, 106.02s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [2:05:39<31:50, 112.36s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [2:07:58<32:07, 120.48s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [2:08:47<24:43, 98.92s/trial, best loss: -0.7880748600064615] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [2:09:30<19:10, 82.21s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [2:11:24<19:50, 91.60s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [2:12:34<17:03, 85.31s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [2:13:31<14:04, 76.74s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [2:14:44<12:34, 75.43s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [2:15:46<10:43, 71.48s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [2:17:32<10:55, 81.91s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [2:18:17<08:14, 70.70s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [2:20:33<09:02, 90.47s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [2:21:48<07:08, 85.67s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [2:23:20<05:51, 87.78s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [2:25:15<04:47, 95.69s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [2:26:17<02:51, 85.73s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [2:27:39<01:24, 84.69s/trial, best loss: -0.7880748600064615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:28:33<00:00, 89.13s/trial, best loss: -0.7880748600064615]\n",
      "Time elapsed: 8913.33204 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.667434542409391,\n",
       " 'learning_rate': 0.09146817439402177,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_samples': 380.0,\n",
       " 'num_leaves': 160.0,\n",
       " 'reg_lambda': 197.79685074014847,\n",
       " 'subsample': 0.504377097169451}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_lgbm = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 10, 200, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 500, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.01), np.log(10000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed_lgbm = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500,\n",
    "    \"categorical_feature\": cat_col_idx\n",
    "}\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "trials_lgbm, best_params_lgbm = hyperopt_lgbm(params_lgbm, \n",
    "                                              X_train, y_train, X_val, y_val, \n",
    "                                              num_eval,\n",
    "                                              params_fixed=params_fixed_lgbm,\n",
    "                                              rstate=31029)\n",
    "best_params_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.667434542409391,\n",
       " 'learning_rate': 0.09146817439402177,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_samples': 380.0,\n",
       " 'num_leaves': 160.0,\n",
       " 'reg_lambda': 197.79685074014847,\n",
       " 'subsample': 0.504377097169451}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'colsample_bytree': 0.667434542409391,\n",
    " 'learning_rate': 0.09146817439402177,\n",
    " 'max_depth': 4.0,\n",
    " 'min_child_samples': 380.0,\n",
    " 'num_leaves': 160.0,\n",
    " 'reg_lambda': 197.79685074014847,\n",
    " 'subsample': 0.504377097169451}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of LightGBM model on the train set: 0.83661\n",
      "AUC of LightGBM model on the evaluation set: 0.78808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    }
   ],
   "source": [
    "best_params_lgbm = whole_to_int(best_params_lgbm)\n",
    "\n",
    "lgbm_best = LGBMClassifier(**params_fixed_lgbm, **best_params_lgbm)\n",
    "lgbm_best.fit(X_train, y_train)\n",
    "\n",
    "auc_lgbm_train = roc_auc(lgbm_best, X_train, y_train)\n",
    "print(\"AUC of LightGBM model on the train set: %0.5f\" % auc_lgbm_train)\n",
    "\n",
    "auc_lgbm_val = roc_auc(lgbm_best, X_val, y_val)\n",
    "print(\"AUC of LightGBM model on the evaluation set: %0.5f\" % auc_lgbm_val)\n",
    "\n",
    "\n",
    "lgbm_best.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lgbm_data5_le_tuned_01.csv\")\n",
    "write_submit_csv(lgbm_best, X_test, sk_id_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lgbm_data5_le_tuned_01.pickle\")\n",
    "pickle.dump(lgbm_best, open(out_model, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
