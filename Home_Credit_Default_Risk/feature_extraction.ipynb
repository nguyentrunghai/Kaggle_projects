{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtypes(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (df[col].dtype == \"object\") and (df[col].nunique() < df.shape[0]):\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "        elif df[col].dtype == float:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "\n",
    "        elif df[col].dtype == int:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtypes(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_type(val):\n",
    "    if type(val) == str:\n",
    "        return \"string\"\n",
    "    \n",
    "    if np.issubsctype(type(val), np.number):\n",
    "        return \"number\"\n",
    "    \n",
    "    if callable(val):\n",
    "        return \"function\"\n",
    "    \n",
    "    return str(type(val))\n",
    "\n",
    "\n",
    "class NumColsImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, specified_values=None, default=\"median\"):\n",
    "        \"\"\"\n",
    "        :param specified_values: dict {colname (str): val (float)}, impute values for some specific columns\n",
    "        :param default: str, function or float, value or function used for the remaining columns\n",
    "        \"\"\"\n",
    "        assert (specified_values is None) or isinstance(specified_values, \n",
    "                                                        dict), \"specified_values must be None or dict\"\n",
    "        \n",
    "        self._specified_values = specified_values\n",
    "        if (self._specified_values is not None) and (len(self._specified_values) > 0):\n",
    "            for col, val in self._specified_values.items():\n",
    "                assert check_type(val) == \"number\", \"Impute value for \" + col + \" is not number.\"\n",
    "        \n",
    "        self._default = default\n",
    "        self._default_type = check_type(self._default)\n",
    "        if self._default_type not in [\"number\", \"string\", \"function\"]:\n",
    "            raise ValueError(\"Unsupported stat type \" + self._default_type)\n",
    "    \n",
    "    def _cal_imput_vals(self, df):\n",
    "        cat_cols = df.select_dtypes([\"object\", \"category\", \"bool\"]).columns.to_list()\n",
    "        if len(cat_cols) > 0:\n",
    "            raise ValueError(\"There are non-number columns: \" + \", \".join(cat_cols))\n",
    "        \n",
    "        all_cols = df.columns.to_list()\n",
    "        if self._default_type == \"number\":\n",
    "            impute_values = {col: self._default for col in all_cols}\n",
    "            \n",
    "        elif self._default_type == \"string\":\n",
    "            impute_values = getattr(df, self._default)()\n",
    "        \n",
    "        elif self._default_type == \"function\":\n",
    "            impute_values = df.apply(self._default)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unknown default imputer:\", self._default)\n",
    "        \n",
    "        # if it is a pandas series, turn it into dict\n",
    "        impute_values = dict(impute_values)\n",
    "        if (self._specified_values is None) or (len(self._specified_values) == 0):\n",
    "            return impute_values\n",
    "        \n",
    "        for col in self._specified_values:\n",
    "            impute_values[col] = self._specified_values[col]\n",
    "            \n",
    "        return impute_values\n",
    "    \n",
    "    def fit(self, df):\n",
    "        impute_values = self._cal_imput_vals(df)\n",
    "        \n",
    "        cols_with_na = [col for col in df.columns if df[col].isnull().any()]\n",
    "        self._impute_values = {col: impute_values[col] for col in cols_with_na}\n",
    "        \n",
    "        for k, v in self._impute_values.items():\n",
    "            if np.isnan(v):\n",
    "                raise ValueError(\"One of the impute_values is NaN: \" + k)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return df.fillna(self._impute_values)\n",
    "\n",
    "\n",
    "class CatColsImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, specified_values=None, default=\"missing_value\"):\n",
    "        \"\"\"\n",
    "        :param specified_values: dict {colname (str): val (str, float, function)}, \n",
    "                                 impute values for some specific columns\n",
    "        :param default: str, used for the remaining columns\n",
    "        \"\"\"\n",
    "        assert (specified_values is None) or isinstance(specified_values, \n",
    "                                                        dict), \"specified_values must be None or dict\"\n",
    "        \n",
    "        self._specified_values = specified_values\n",
    "        if (self._specified_values is not None) and (len(self._specified_values) > 0):\n",
    "            for col, val in self._specified_values.items():\n",
    "                assert check_type(val) in [\"string\", \n",
    "                                           \"function\"], \"Impute value for \" + col + \" is \" + check_type(val)\n",
    "        \n",
    "        self._default = default\n",
    "        assert check_type(self._default) == \"string\", \"default must be string\"\n",
    "        \n",
    "        \n",
    "    def _cal_imput_vals(self, df):\n",
    "        num_cols = df.select_dtypes([\"number\"]).columns.to_list()\n",
    "        if len(num_cols) > 0:\n",
    "            raise ValueError(\"There are number columns: \" + \", \".join(num_cols))\n",
    "        \n",
    "        all_cols = df.columns.to_list()\n",
    "        impute_values = {col: self._default for col in all_cols}\n",
    "        if (self._specified_values is None) or (len(self._specified_values) == 0):\n",
    "            return impute_values\n",
    "        \n",
    "        for col, val in self._specified_values.items():\n",
    "            dtype = check_type(val)\n",
    "            if dtype == \"string\":\n",
    "                impute_values[col] = val\n",
    "            \n",
    "            elif dtype == \"function\":\n",
    "                impute_values[col] = val(df[col])\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(\"Unknown imputer for \" + col + \": \", str(val))\n",
    "        return impute_values\n",
    "    \n",
    "    def fit(self, df):\n",
    "        impute_values = self._cal_imput_vals(df)\n",
    "        \n",
    "        cols_with_na = [col for col in df.columns if df[col].isnull().any()]\n",
    "        self._impute_values = {col: impute_values[col] for col in cols_with_na}\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_new = df.copy()\n",
    "        for col, val in self._impute_values.items():\n",
    "            df_new[col] = df_new[col].astype(\"object\").fillna(val).astype(\"category\")\n",
    "            \n",
    "        return df_new\n",
    "\n",
    "\n",
    "def get_colnames_from_regex(df, regex_strings):\n",
    "    cols = []\n",
    "    for regex_str in regex_strings:\n",
    "        cols.extend(df.filter(regex=regex_str).columns.to_list())\n",
    "    return cols\n",
    "\n",
    "\n",
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError(\"Not implemented\")\n",
    "        \n",
    "        self._regex_strings = None\n",
    "        self._spec_impt_regex_val_num = None\n",
    "        \n",
    "        self._spec_impt_vals_num = {}\n",
    "        self._default_imput_vals_num = \"median\"\n",
    "        \n",
    "        self._spec_impt_vals_cat = {}\n",
    "        self._default_imput_vals_cat = \"missing_value\"\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        df_num = df_train.select_dtypes([\"number\"])\n",
    "        cols_num = df_num.columns.to_list()\n",
    "                \n",
    "        if self._regex_strings is not None:\n",
    "            cols_imput_with_regex = get_colnames_from_regex(df_train, self._regex_strings)\n",
    "            # make sure they are in cols_num\n",
    "            cols_imput_with_regex = [col for col in cols_imput_with_regex if col in cols_num]\n",
    "            \n",
    "            self._spec_impt_vals_num.update({col: self._spec_impt_regex_val_num \n",
    "                                             for col in cols_imput_with_regex})\n",
    "        \n",
    "        self._imputer_num = NumColsImputer(specified_values=self._spec_impt_vals_num, \n",
    "                                           default=self._default_imput_vals_num)\n",
    "        self._imputer_num.fit(df_num)\n",
    "        \n",
    "        df_cat = df_train.select_dtypes([\"object\", \"category\", \"bool\"])\n",
    "        self._imputer_cat = CatColsImputer(specified_values=self._spec_impt_vals_cat, \n",
    "                                           default=self._default_imput_vals_cat)\n",
    "        self._imputer_cat.fit(df_cat)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        dfs = []\n",
    "        num_df = df.select_dtypes([\"number\"])\n",
    "        \n",
    "        if len(self._spec_impt_vals_num) > 0:\n",
    "            some_col = list(self._spec_impt_vals_num.keys())[0]\n",
    "            isnull_df = num_df[[some_col]]\n",
    "            for col in self._spec_impt_vals_num:\n",
    "                isnull_df[col + \"_ISNULL\"] = num_df[col].isnull()\n",
    "                \n",
    "            isnull_df = isnull_df.drop([some_col], axis=\"columns\")\n",
    "            dfs.append(isnull_df)\n",
    "        \n",
    "        num_df = self._imputer_num.transform(num_df)\n",
    "        dfs.append(num_df)\n",
    "        \n",
    "        # cat\n",
    "        cat_df = df.select_dtypes([\"object\", \"category\", \"bool\"])\n",
    "        cat_df = self._imputer_cat.transform(cat_df)\n",
    "        dfs.append(cat_df)\n",
    "        \n",
    "        return pd.concat(dfs, axis=\"columns\")\n",
    "    \n",
    "\n",
    "class DefaultImputer(Imputer):\n",
    "    def __init__(self):\n",
    "        self._regex_strings = None\n",
    "        self._spec_impt_regex_val_num = None\n",
    "        \n",
    "        self._spec_impt_vals_num = {}\n",
    "        self._default_imput_vals_num = 0.\n",
    "        \n",
    "        self._spec_impt_vals_cat = {}\n",
    "        self._default_imput_vals_cat = \"missing_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollinearColumnRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold, col_regex=None):\n",
    "        \"\"\"\n",
    "        :param threshold: float in [0, 1], if two columns have correlation greater than threshold\n",
    "                          one of them will be removed\n",
    "        :param col_regex: str, regular expression to select columns\n",
    "        \"\"\"\n",
    "        self._threshold = threshold\n",
    "        self._col_regex = col_regex\n",
    "    \n",
    "    def _collinear_columns(self, df, threshold):\n",
    "        if self._col_regex is None:\n",
    "            df_sel = df.select_dtypes([\"number\", \"bool\"])\n",
    "        else:\n",
    "            df_sel = df.filter(regex=self._col_regex)\n",
    "            df_sel = df_sel.select_dtypes([\"number\", \"bool\"])\n",
    "        \n",
    "        df_sel = df_sel.astype(\"float32\")\n",
    "        \n",
    "        all_cols = df_sel.columns.to_list()\n",
    "        ncols = len(all_cols)\n",
    "        \n",
    "        corr_mat = df_sel.corr().abs()\n",
    "        self._corr_mat = corr_mat\n",
    "        collin_cols = []\n",
    "        for i in range(ncols-1):\n",
    "            col_i = all_cols[i]\n",
    "            if col_i in collin_cols:\n",
    "                continue\n",
    "            \n",
    "            for j in range(i + 1, ncols):\n",
    "                col_j = all_cols[j]\n",
    "                if col_j in collin_cols:\n",
    "                    continue\n",
    "                \n",
    "                corr = corr_mat.loc[col_i, col_j]\n",
    "                if corr > threshold:\n",
    "                    collin_cols.append(col_j)\n",
    "        \n",
    "        collin_cols = list(set(collin_cols))\n",
    "        return collin_cols\n",
    "    \n",
    "    \n",
    "    def fit(self, df):\n",
    "        self._collin_cols = self._collinear_columns(df, self._threshold)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        all_cols = df.columns.to_list()\n",
    "        nonexist_cols = [col for col in self._collin_cols if col not in all_cols]\n",
    "        if len(nonexist_cols) > 0:\n",
    "            print(\"WARNING: These collinear cols to be droped do not exist in df:\", nonexist_cols)\n",
    "            \n",
    "        droped_col = [col for col in self._collin_cols if col in all_cols]\n",
    "        print(\"Number of columns droped due to collinearity:\", len(droped_col))\n",
    "        return df.drop(droped_col, axis=\"columns\")\n",
    "\n",
    "\n",
    "class ConstantColumnsRemover(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df_train):\n",
    "        all_cols = df_train.columns\n",
    "        self._cols_to_remove = []\n",
    "        \n",
    "        for col in all_cols:\n",
    "            if df_train[col].nunique() == 1:\n",
    "                self._cols_to_remove.append(col)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        print(\"Number of constant columns droped:\", len(self._cols_to_remove))\n",
    "        return df.drop(self._cols_to_remove, axis=\"columns\")\n",
    "                \n",
    "        \n",
    "class SameCatColsRemover(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, threshold=0.99):\n",
    "        self._threshold = threshold\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        ncols = len(cols)\n",
    "        \n",
    "        self._cols_to_drop = []\n",
    "        for i in range(ncols - 1):\n",
    "            col_i = cols[i]\n",
    "            if col_i in self._cols_to_drop:\n",
    "                continue\n",
    "            \n",
    "            for j in range(i + 1, ncols):\n",
    "                col_j = cols[j]\n",
    "                if col_j in self._cols_to_drop:\n",
    "                    continue\n",
    "                \n",
    "                if (df_train[col_i].astype(\"object\") == df_train[col_j].astype(\"object\")).mean() > self._threshold:\n",
    "                    self._cols_to_drop.append(col_j)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        print(\"Number of same columns droped:\", len(self._cols_to_drop))\n",
    "        return df.drop(self._cols_to_drop, axis=\"columns\")\n",
    "\n",
    "\n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, train_df):\n",
    "        df_cat = train_df.select_dtypes([\"object\", \"category\"])\n",
    "        self._cat_cols = df_cat.columns.to_list()\n",
    "        \n",
    "        if len(self._cat_cols) > 0:\n",
    "            self._cat_cols_ohe = pd.get_dummies(df_cat, drop_first=True).columns.to_list()\n",
    "        else:\n",
    "            self._cat_cols_ohe = []\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if len(self._cat_cols) == 0:\n",
    "            print(\"No cat cols in df_train, so do nothing.\")\n",
    "            return df\n",
    "        \n",
    "        df_cat = df.select_dtypes([\"object\", \"category\"])\n",
    "        cat_cols = df_cat.columns.to_list()\n",
    "        assert set(cat_cols) == set(self._cat_cols), \"df does not have the same categorical cols as train_df\"\n",
    "        \n",
    "        # one-hot encode\n",
    "        df_cat = pd.get_dummies(df_cat)\n",
    "        # drop cols that are present in test_df but absent in train_df\n",
    "        cols_to_drop = [col for col in df_cat.columns if col not in self._cat_cols_ohe]\n",
    "        df_cat = df_cat.drop(cols_to_drop, axis=\"columns\")\n",
    "        \n",
    "        # change to float32\n",
    "        for col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].astype(\"float32\")\n",
    "        \n",
    "        # if some some colums are absent in test but present in train, make them all zero \n",
    "        cat_cols_ohe = df_cat.columns.to_list()\n",
    "        for col in self._cat_cols_ohe:\n",
    "            if col not in cat_cols_ohe:\n",
    "                df_cat[col] = 0\n",
    "                df_cat[col] = df_cat[col].astype(np.uint8)\n",
    "        \n",
    "        num_cols = [col for col in df.columns if col not in cat_cols]\n",
    "        df_num = df[num_cols]\n",
    "        \n",
    "        return pd.concat([df_num, df_cat], axis=\"columns\")\n",
    "\n",
    "\n",
    "class Standardizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_array=False):\n",
    "        self._to_array = to_array\n",
    "        \n",
    "    def fit(self, df_train):\n",
    "        num_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        self._mean = {col: df_train[col].mean() for col in num_cols}\n",
    "        self._std = {col: df_train[col].std() for col in num_cols}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        for col in self._mean:\n",
    "            if self._std[col] > 0:\n",
    "                df[col] = (df[col] - self._mean[col]) / self._std[col]\n",
    "                df[col] = df[col].astype(\"float32\")\n",
    "            else:\n",
    "                print(\"WARNING: \" + col + \" has zero std.\")\n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumColsQCuter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, labels=None, exclude_cols=None, \n",
    "                 nunique_min=1000, keep_old=True, \n",
    "                 output_type=np.int32):\n",
    "        \n",
    "        if labels is None:\n",
    "            self._labels = list(range(1, 11))\n",
    "        else:\n",
    "            self._labels = list(labels)\n",
    "        self._nbins = len(self._labels)\n",
    "        assert self._isunique(self._labels), \"labels must be unique\"\n",
    "        \n",
    "        self._exclude_cols = [\"SK_ID_CURR\", \"TARGET\", \"SK_ID_BUREAU\", \"SK_ID_PREV\"]\n",
    "        if exclude_cols is not None:\n",
    "            self._exclude_cols = self._exclude_cols + list(exclude_cols)\n",
    "        \n",
    "        self._nunique_min = nunique_min\n",
    "        \n",
    "        self._suffix = \"_%dQCUT\" % len(self._labels)\n",
    "        \n",
    "        self._keep_old = keep_old\n",
    "        self._output_type = output_type\n",
    "    \n",
    "    def _isunique(self, x):\n",
    "        return len(np.unique(x)) == len(x)\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        \n",
    "        quantiles = np.linspace(0, 1, self._nbins + 1)\n",
    "        quantiles = quantiles[1: -1]\n",
    "        \n",
    "        sel_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        sel_cols = [col for col in sel_cols if col not in self._exclude_cols]\n",
    "        sel_cols = [col for col in sel_cols if df_train[col].nunique() >= self._nunique_min]\n",
    "        \n",
    "        self._bins = {}\n",
    "        for col in sel_cols:\n",
    "            #if df_train[col].isnull().any():\n",
    "            #    raise ValueError(col + \" has null values\")\n",
    "            \n",
    "            bins = df_train[col].quantile(quantiles).values\n",
    "            bins = np.array([-np.inf] + list(bins) + [np.inf])\n",
    "            \n",
    "            if self._isunique(bins):\n",
    "                self._bins[col] = bins\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        for col, bins in self._bins.items():\n",
    "            new_col_name = col + self._suffix\n",
    "            df[new_col_name] = pd.cut(df[col], bins, labels=self._labels)\n",
    "            df[new_col_name] = df[new_col_name].astype(self._output_type)\n",
    "            \n",
    "            new_cols.append(new_col_name)\n",
    "            \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_multiindex_cols(columns):\n",
    "    fat_cols = [\"_\".join([str(c) for c in flat_col]) for flat_col in columns.to_flat_index()]\n",
    "    return fat_cols\n",
    "\n",
    "\n",
    "def agg_num_cols(df, by_sers, stats):\n",
    "    assert type(by_sers) in [list, tuple], \"by_sers must be a list or tuple\"\n",
    "    assert type(stats) in [list, tuple], \"stats must be a list or tuple\"\n",
    "    \n",
    "    for ser in by_sers:\n",
    "        assert isinstance(ser, pd.Series), \"ser in by_sers must be Series\"\n",
    "        \n",
    "    cat_cols = df.select_dtypes([\"object\", \"category\"]).columns.to_list()\n",
    "    if len(cat_cols) > 0:\n",
    "        raise ValueError(\"There are non-number cols: \" + \", \".join(cat_cols))\n",
    "    \n",
    "    df_agg = df.groupby(by_sers).agg(stats)\n",
    "    df_agg.columns = flatten_multiindex_cols(df_agg.columns)\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "\n",
    "def agg_cat_cols(df, by_sers, stats):\n",
    "    assert type(by_sers) in [list, tuple], \"by_sers must be a list or tuple\"\n",
    "    assert type(stats) in [list, tuple], \"stats must be a list or tuple\"\n",
    "    \n",
    "    for ser in by_sers:\n",
    "        assert isinstance(ser, pd.Series), \"ser in by_sers must be Series\"\n",
    "        \n",
    "    num_cols = df.select_dtypes([\"number\"]).columns.to_list()\n",
    "    if len(num_cols) > 0:\n",
    "        raise ValueError(\"There are number cols: \" + \", \".join(num_cols))\n",
    "    \n",
    "    df_agg = df.groupby(by_sers).agg(stats)\n",
    "    df_agg.columns = flatten_multiindex_cols(df_agg.columns)\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "\n",
    "class Aggregator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, by_list_cols, \n",
    "                 num_stats, bool_stats, cat_stats, \n",
    "                 ohe_cat_stats=None,\n",
    "                 ohe_cat_max_class=None,\n",
    "                 iqr=False, minmax_range=False, mean_median_diff=False):\n",
    "        \"\"\"\n",
    "        :param by_list_cols: list of str, cols by which the dataframe is grouped\n",
    "        :param num_stats: list, aggregating functions for numerical columns\n",
    "        :param bool_stats: list, aggregating functions for bool columns\n",
    "        :param cat_stats: list, aggregating functions for category columns\n",
    "        :param ohe_cat_stats: list, aggregating functions for category columns after one-hot encoded\n",
    "        :param ohe_cat_max_class: int, category columns with at most ohe_cat_max_class classes \n",
    "                                 will be one-hot encoded before aggregating, \n",
    "                                 If None, no one-hot encoding will be done.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._by_list_cols = by_list_cols\n",
    "        \n",
    "        self._num_stats = num_stats\n",
    "        self._bool_stats = bool_stats\n",
    "        self._cat_stats = cat_stats\n",
    "        self._ohe_cat_stats = ohe_cat_stats\n",
    "        \n",
    "        if ohe_cat_max_class is None:\n",
    "            self._ohe_cat_max_class = [\"mean\", \"sum\"]\n",
    "        else:\n",
    "            self._ohe_cat_max_class = ohe_cat_max_class\n",
    "        \n",
    "        self._iqr = iqr\n",
    "        self._minmax_range = minmax_range\n",
    "        self._mean_median_diff = mean_median_diff\n",
    "    \n",
    "    def _num_agg(self, df, by_sers):\n",
    "        agg_df = agg_num_cols(df, by_sers, stats=self._num_stats)\n",
    "        return agg_df\n",
    "    \n",
    "    def _bool_agg(self, df, by_sers):\n",
    "        agg_df = agg_num_cols(df, by_sers, stats=self._bool_stats)\n",
    "        return agg_df\n",
    "    \n",
    "    def _cat_agg(self, df, by_sers):\n",
    "        agg_df =  agg_cat_cols(df, by_sers, stats=self._cat_stats)\n",
    "        return agg_df\n",
    "    \n",
    "    def _ohe_cat_agg(self, df, by_sers):\n",
    "        agg_df = agg_num_cols(df, by_sers, stats=self._ohe_cat_stats)\n",
    "        return agg_df\n",
    "    \n",
    "    \n",
    "    def _iqr_agg(self, num_df, by_sers):\n",
    "        grouped = num_df.groupby(by_sers)\n",
    "        iqr_df = grouped.quantile(0.75) - grouped.quantile(0.25)\n",
    "        iqr_df.columns = [col + \"_iqr\" for col in iqr_df.columns]\n",
    "        return iqr_df\n",
    "    \n",
    "    def _range_agg(self, num_df, by_sers):\n",
    "        grouped = num_df.groupby(by_sers)\n",
    "        range_df = grouped.max() - grouped.min()\n",
    "        range_df.columns = [col + \"_range\" for col in range_df.columns]\n",
    "        return range_df\n",
    "    \n",
    "    def _mm_diff_agg(self, num_df, by_sers):\n",
    "        grouped = num_df.groupby(by_sers)\n",
    "        diff_df = grouped.mean() - grouped.median()\n",
    "        diff_df.columns = [col + \"_mm_diff\" for col in diff_df.columns]\n",
    "        return diff_df\n",
    "    \n",
    "    def _cat_cols_to_ohe(self, df_train):\n",
    "        cat_cols = []\n",
    "        if self._ohe_cat_max_class is None:\n",
    "            return cat_cols\n",
    "        \n",
    "        for col in self._cat_cols:\n",
    "            if df_train[col].nunique() <=  self._ohe_cat_max_class:\n",
    "                for cl in df_train[col].unique():\n",
    "                    cat_cols.append(col + \"_\" + str(cl))\n",
    "        return cat_cols\n",
    "        \n",
    "    def fit(self, df_train):\n",
    "        df_train = df_train.drop(self._by_list_cols, axis=\"columns\")\n",
    "        \n",
    "        self._ohe = OneHotEncoder()\n",
    "        self._ohe.fit(df_train)\n",
    "        \n",
    "        self._bool_cols = df_train.select_dtypes([\"bool\"]).columns.to_list()\n",
    "        self._cat_cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        self._num_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        \n",
    "        # cat column names after being one-hot encoded\n",
    "        all_cat_ohe_cols = self._ohe.transform(df_train).columns.to_list()\n",
    "        self._cat_cols_ohe = []\n",
    "        if self._ohe_cat_max_class is not None:\n",
    "            for col in self._cat_cols:\n",
    "                if df_train[col].nunique() <=  self._ohe_cat_max_class:\n",
    "                    for cl in df_train[col].unique():\n",
    "                        ohe_col = col + \"_\" + str(cl)\n",
    "                        \n",
    "                        if ohe_col in all_cat_ohe_cols:\n",
    "                            self._cat_cols_ohe.append(ohe_col)\n",
    "                        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        by_sers = [df[col] for col in self._by_list_cols]\n",
    "        df = df.drop(self._by_list_cols, axis=\"columns\")\n",
    "        \n",
    "        all_cols = df.columns.to_list()\n",
    "        for col in self._bool_cols + self._cat_cols + self._num_cols:\n",
    "            if col not in all_cols:\n",
    "                raise ValueError(col + \" exists in train but not in test\")\n",
    "        \n",
    "        dfs = []\n",
    "        \n",
    "        # bool cols\n",
    "        if len(self._bool_cols) > 0:\n",
    "            df_bool = df[self._bool_cols]\n",
    "            print(\"Aggregating bool df with shape:\", df_bool.shape)\n",
    "            df_bool = self._bool_agg(df_bool, by_sers)\n",
    "            \n",
    "            for col in df_bool.columns:\n",
    "                if col.endswith(\"_mean\") or col.endswith(\"_sum\") or col.endswith(\"_entropy\"):\n",
    "                    df_bool[col] = df_bool[col].astype(\"float32\")\n",
    "                \n",
    "                if col.endswith(\"_mode\"):\n",
    "                    df_bool[col] = df_bool[col].astype(\"category\")\n",
    "            dfs.append(df_bool)\n",
    "        \n",
    "        # categorical cols\n",
    "        if len(self._cat_cols) > 0:\n",
    "            df_cat = df[self._cat_cols]\n",
    "            print(\"Aggregating cat df with shape:\", df_cat.shape)\n",
    "            df_cat = self._cat_agg(df_cat, by_sers)\n",
    "            \n",
    "            for col in df_cat.columns:\n",
    "                if col.endswith(\"_mean\") or col.endswith(\"_entropy\"):\n",
    "                    df_cat[col] = df_cat[col].astype(\"float32\")\n",
    "                \n",
    "                if col.endswith(\"_mode\"):\n",
    "                    df_cat[col] = df_cat[col].astype(\"category\")\n",
    "            \n",
    "            dfs.append(df_cat)\n",
    "        \n",
    "        # number cols\n",
    "        df_num = df[self._num_cols]\n",
    "        if df_num.shape[1] > 0:\n",
    "            print(\"Aggregating num df with shape:\", df_num.shape)\n",
    "            df_num = self._num_agg(df_num, by_sers)\n",
    "            dfs.append(df_num)\n",
    "        \n",
    "        # ohe cat cols\n",
    "        if len(self._cat_cols_ohe) > 0:\n",
    "            df_ohe = self._ohe.transform(df)\n",
    "            for col in self._cat_cols_ohe:\n",
    "                if col not in df_ohe.columns:\n",
    "                    raise ValueError(col + \" is not in cols of df_ohe\")\n",
    "                    \n",
    "            df_ohe = df_ohe[self._cat_cols_ohe]\n",
    "            print(\"Aggregating ohe cat df with shape:\", df_ohe.shape)\n",
    "            \n",
    "            df_ohe = self._ohe_cat_agg(df_ohe, by_sers)\n",
    "            dfs.append(df_ohe)\n",
    "        \n",
    "        # aggregate num cols with iqr, range and mean-median difference\n",
    "        df_num = df.select_dtypes([\"number\"])\n",
    "        print(\"df_num.shape for iqr, mimmax_range, mean_median_diff\", df_num.shape)\n",
    "            \n",
    "        if self._iqr and df_num.shape[1] > 0:\n",
    "            print(\"Aggregating num df with iqr\")\n",
    "            df_iqr = self._iqr_agg(df_num, by_sers)\n",
    "            dfs.append(df_iqr)\n",
    "        \n",
    "        if self._minmax_range and df_num.shape[1] > 0:\n",
    "            print(\"Aggregating num df with range\")\n",
    "            df_range = self._range_agg(df_num, by_sers)\n",
    "            print(\"df_range.shape\", df_range.shape)\n",
    "            dfs.append(df_range)\n",
    "        \n",
    "        if self._mean_median_diff and df_num.shape[1] > 0:\n",
    "            print(\"Aggregating num df with mean-median difference\")\n",
    "            df_diff = self._mm_diff_agg(df_num, by_sers)\n",
    "            dfs.append(df_diff)\n",
    "        \n",
    "        return pd.concat(dfs, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_partition(df, matching_key, train_id_ser):\n",
    "    is_train = df[matching_key].isin(train_id_ser.values)\n",
    "    \n",
    "    train = df.loc[is_train, :]\n",
    "    test = df.loc[~is_train, :]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(ser):\n",
    "    return ser.mode().values[0]\n",
    "\n",
    "\n",
    "def entropy(ser):\n",
    "    pk = ser.value_counts(normalize=True)\n",
    "    return stats.entropy(pk)\n",
    "\n",
    "\n",
    "def hh_index(ser):\n",
    "    pk = ser.value_counts(normalize=True)\n",
    "    return (pk * pk).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from `application_[train|test]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplImputer(Imputer):\n",
    "    def __init__(self):\n",
    "        self._regex_strings = [\"^APARTMENTS_\", \"^BASEMENTAREA_\", \"^YEARS_B\", \"^COMMONAREA_\", \n",
    "                               \"^ELEVATORS_\", \"^ENTRANCES_\", \"^FLOORS\", \"^LANDAREA_\", \"^LIVING\", \n",
    "                               \"^NONLIVING\", \"AMT_REQ_CREDIT_BUREAU_\"]\n",
    "        self._spec_impt_regex_val_num = -1.\n",
    "        \n",
    "        self._spec_impt_vals_num = {\"OWN_CAR_AGE\": -1.,\n",
    "                                    \"EXT_SOURCE_1\": 0.,\n",
    "                                    \"EXT_SOURCE_3\": 0.,\n",
    "                                    \"TOTALAREA_MODE\": -1.}\n",
    "        self._default_imput_vals_num = \"median\"\n",
    "        \n",
    "        self._spec_impt_vals_cat = None\n",
    "        self._default_imput_vals_cat = \"missing_value\"\n",
    "        \n",
    "\n",
    "class ApplNewColsAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df_train):\n",
    "        credit_to_income = df_train[\"AMT_CREDIT\"] / df_train[\"AMT_INCOME_TOTAL\"]\n",
    "        self._cti_min = credit_to_income.replace(-np.inf, np.nan).min() / 10.\n",
    "        self._cti_max = credit_to_income.replace(np.inf, np.nan).max() * 10.\n",
    "        \n",
    "        credit_to_goods = df_train[\"AMT_CREDIT\"] / df_train[\"AMT_GOODS_PRICE\"]\n",
    "        self._ctg_min = credit_to_goods.replace(-np.inf, np.nan).min() / 10.\n",
    "        self._ctg_max = credit_to_goods.replace(np.inf, np.nan).max() * 10.\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_new = df.copy()\n",
    "        df_new[\"AMT_INCOME_TOTAL_LOG\"] = np.log(df_new[\"AMT_INCOME_TOTAL\"])\n",
    "        df_new[\"DAYS_EMPLOYED_POSITIVE\"] = df_new[\"DAYS_EMPLOYED\"] > 0\n",
    "        days_emp_max = df_new[\"DAYS_EMPLOYED\"].max()\n",
    "        if days_emp_max > 0:\n",
    "            df_new[\"DAYS_EMPLOYED\"] = df_new[\"DAYS_EMPLOYED\"].replace({days_emp_max: 100.})\n",
    "        \n",
    "        df_new[\"CREDIT_TO_INCOME\"] = df_new[\"AMT_CREDIT\"] / df_new[\"AMT_INCOME_TOTAL\"]\n",
    "        df_new[\"CREDIT_TO_INCOME\"] = df_new[\"CREDIT_TO_INCOME\"].replace(-np.inf, self._cti_min)\n",
    "        df_new[\"CREDIT_TO_INCOME\"] = df_new[\"CREDIT_TO_INCOME\"].replace(np.inf, self._cti_max)\n",
    "        \n",
    "        df_new[\"CREDIT_TO_GOODS\"] = df_new[\"AMT_CREDIT\"] / df_new[\"AMT_GOODS_PRICE\"]\n",
    "        df_new[\"CREDIT_TO_GOODS\"] = df_new[\"CREDIT_TO_GOODS\"].replace(-np.inf, self._ctg_min)\n",
    "        df_new[\"CREDIT_TO_GOODS\"] = df_new[\"CREDIT_TO_GOODS\"].replace(np.inf, self._ctg_max)\n",
    "        \n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = load_csv(\"data/download/application_train.csv\")\n",
    "application_test = load_csv(\"data/download/application_test.csv\")\n",
    "\n",
    "appl_train_key = application_train[\"SK_ID_CURR\"]\n",
    "appl_test_key = application_test[\"SK_ID_CURR\"]\n",
    "print(application_train.shape, application_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "appl_train = application_train.copy()\n",
    "appl_test = application_test.copy()\n",
    "print(\"appl_train.shape\", appl_train.shape)\n",
    "print(\"appl_test.shape\", appl_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(appl_train)\n",
    "appl_train = numcolsqcuter.transform(appl_train)\n",
    "appl_test = numcolsqcuter.transform(appl_test)\n",
    "print(\"appl_train.shape\", appl_train.shape)\n",
    "print(\"appl_test.shape\", appl_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute missing values\")\n",
    "imputer = ApplImputer()\n",
    "imputer.fit(appl_train)\n",
    "appl_train = imputer.transform(appl_train)\n",
    "appl_test = imputer.transform(appl_test)\n",
    "print(\"appl_train.isnull().sum().sum()\", appl_train.isnull().sum().sum())\n",
    "print(\"appl_test.isnull().sum().sum()\", appl_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95, col_regex=\"_ISNULL$\")\n",
    "remover.fit(appl_train)\n",
    "appl_train = remover.transform(appl_train)\n",
    "appl_test = remover.transform(appl_test)\n",
    "print(\"appl_train.shape\", appl_train.shape)\n",
    "print(\"appl_test.shape\", appl_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new columns\")\n",
    "adder = ApplNewColsAdder()\n",
    "adder.fit(appl_train)\n",
    "appl_train = adder.transform(appl_train)\n",
    "appl_test = adder.transform(appl_test)\n",
    "print(\"appl_train.shape\", appl_train.shape)\n",
    "print(\"appl_test.shape\", appl_test.shape)\n",
    "\n",
    "\n",
    "if True:\n",
    "    appl_train.to_csv(\"data/data_/application_train.csv\", index=False)\n",
    "    appl_test.to_csv(\"data/data_/application_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from `bureau` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `bureau.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BureauImputer(Imputer):\n",
    "    def __init__(self):\n",
    "        self._regex_strings = None\n",
    "        self._spec_impt_regex_val_num = None\n",
    "        \n",
    "        self._spec_impt_vals_num = {\"DAYS_ENDDATE_FACT\": 100.,\n",
    "                                    \"AMT_CREDIT_MAX_OVERDUE\": -1000.,\n",
    "                                    \"AMT_CREDIT_SUM_DEBT\": 0.,\n",
    "                                    \"AMT_CREDIT_SUM_LIMIT\": 0.,\n",
    "                                    \"AMT_ANNUITY\": -1000.}\n",
    "        self._default_imput_vals_num = \"median\"\n",
    "        \n",
    "        self._spec_impt_vals_cat = None\n",
    "        self._default_imput_vals_cat = \"missing_value\"\n",
    "\n",
    "\n",
    "def drop_cols_bureau(df):\n",
    "    # mostly zero\n",
    "    cols_to_drop = [\"CREDIT_DAY_OVERDUE\", \"CNT_CREDIT_PROLONG\", \"AMT_CREDIT_SUM_OVERDUE\"]\n",
    "    return df.drop(cols_to_drop, axis=\"columns\")\n",
    "\n",
    "\n",
    "def add_new_cols_bureau(df):\n",
    "    df[\"DAYS_CREDIT_ENDDATE_ISPOSITIVE\"] = df[\"DAYS_CREDIT_ENDDATE\"] > 0\n",
    "\n",
    "    df[\"AMT_CREDIT_MAX_OVERDUE_ISPOSITIVE\"] = df[\"AMT_CREDIT_MAX_OVERDUE\"] > 0\n",
    "    df[\"AMT_CREDIT_SUM_DEBT_ISPOSITIVE\"] = df[\"AMT_CREDIT_SUM_DEBT\"] > 0\n",
    "    df[\"AMT_CREDIT_SUM_LIMIT_ISPOSITIVE\"] = df[\"AMT_CREDIT_SUM_LIMIT\"] > 0\n",
    "    df[\"AMT_ANNUITY_ISPOSITIVE\"] =  df[\"AMT_ANNUITY\"] > 0\n",
    "    \n",
    "    amt_credt_sum = df[\"AMT_CREDIT_SUM\"] + 1\n",
    "    df[\"AMT_CREDIT_MAX_OVERDUE_TO_SUM\"] = df[\"AMT_CREDIT_MAX_OVERDUE\"] / amt_credt_sum\n",
    "    df[\"AMT_CREDIT_SUM_DEBT_TO_SUM\"] = df[\"AMT_CREDIT_SUM_DEBT\"] / amt_credt_sum\n",
    "    df[\"AMT_CREDIT_SUM_LIMIT_TO_SUM\"] = df[\"AMT_CREDIT_SUM_LIMIT\"] / amt_credt_sum\n",
    "    return df\n",
    "\n",
    "\n",
    "def bu_nearest_status(df):\n",
    "    return df.sort_values(by=[\"DAYS_CREDIT\"], ascending=False)[\"CREDIT_ACTIVE\"].iloc[0]\n",
    "\n",
    "def bu_mode_status_three_nearest(df):\n",
    "    statuses = df.sort_values(by=[\"DAYS_CREDIT\"], ascending=False)[\"CREDIT_ACTIVE\"].iloc[: 3]\n",
    "    return statuses.mode().values[0]\n",
    "\n",
    "def bu_mode_status_six_nearest(df):\n",
    "    statuses = df.sort_values(by=[\"DAYS_CREDIT\"], ascending=False)[\"CREDIT_ACTIVE\"].iloc[: 6]\n",
    "    return statuses.mode().values[0]\n",
    "\n",
    "\n",
    "def add_new_agg_cols_bu(df):\n",
    "    results = {}\n",
    "    results[\"NEAREST_CREDIT_ACTIVE\"] = df.groupby(\"SK_ID_CURR\").apply(bu_nearest_status)\n",
    "    results[\"MODE_CREDIT_ACTIVE_THREE\"] = df.groupby(\"SK_ID_CURR\").apply(bu_mode_status_three_nearest)\n",
    "    results[\"MODE_CREDIT_ACTIVE_SIX\"] = df.groupby(\"SK_ID_CURR\").apply(bu_mode_status_six_nearest)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = load_csv(\"data/download/bureau.csv\")\n",
    "print(\"bureau.shape\", bureau.shape)\n",
    "\n",
    "bureau_train, bureau_test = train_test_partition(bureau, \"SK_ID_CURR\", appl_train_key)\n",
    "\n",
    "print(\"bureau_train.shape\", bureau_train.shape)\n",
    "print(\"bureau_test.shape\", bureau_test.shape)\n",
    "\n",
    "bureau_train_keys = bureau_train[[\"SK_ID_CURR\", \"SK_ID_BUREAU\"]]\n",
    "bureau_test_keys = bureau_test[[\"SK_ID_CURR\", \"SK_ID_BUREAU\"]]\n",
    "\n",
    "bureau_train = bureau_train.drop([\"SK_ID_BUREAU\"], axis=\"columns\")\n",
    "bureau_test = bureau_test.drop([\"SK_ID_BUREAU\"], axis=\"columns\")\n",
    "\n",
    "bureau_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "bureau_agg_train = bureau_train.copy()\n",
    "bureau_agg_test = bureau_test.copy()\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Drop some columns\")\n",
    "bureau_agg_train = drop_cols_bureau(bureau_agg_train)\n",
    "bureau_agg_test = drop_cols_bureau(bureau_agg_test)\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(bureau_agg_train)\n",
    "bureau_agg_train = numcolsqcuter.transform(bureau_agg_train)\n",
    "bureau_agg_test = numcolsqcuter.transform(bureau_agg_test)\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute missing values\")\n",
    "imputer = BureauImputer()\n",
    "imputer.fit(bureau_agg_train)\n",
    "bureau_agg_train = imputer.transform(bureau_agg_train)\n",
    "bureau_agg_test = imputer.transform(bureau_agg_test)\n",
    "print(\"bureau_agg_train.isnull().sum().sum()\", bureau_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_agg_test.isnull().sum().sum()\", bureau_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add some cols\")\n",
    "bureau_agg_train = add_new_cols_bureau(bureau_agg_train)\n",
    "bureau_agg_test = add_new_cols_bureau(bureau_agg_test)\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"New agg cols\")\n",
    "new_agg_cols_train = add_new_agg_cols_bu(bureau_agg_train)\n",
    "new_agg_cols_test = add_new_agg_cols_bu(bureau_agg_test)\n",
    "\n",
    "\n",
    "print(\"aggregate over SK_ID_CURR\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_CURR\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "aggregator.fit(bureau_agg_train)\n",
    "bureau_agg_train = aggregator.transform(bureau_agg_train)\n",
    "bureau_agg_test = aggregator.transform(bureau_agg_test)\n",
    "print(\"bureau_agg_train.isnull().sum().sum()\", bureau_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_agg_test.isnull().sum().sum()\", bureau_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new agg cols\")\n",
    "for col in new_agg_cols_train:\n",
    "    bureau_agg_train[col] = new_agg_cols_train[col]\n",
    "\n",
    "for col in new_agg_cols_test:\n",
    "    bureau_agg_test[col] = new_agg_cols_test[col]\n",
    "\n",
    "print(\"bureau_agg_train.isnull().sum().sum()\", bureau_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_agg_test.isnull().sum().sum()\", bureau_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(bureau_agg_train)\n",
    "bureau_agg_train = imputer.transform(bureau_agg_train)\n",
    "bureau_agg_test = imputer.transform(bureau_agg_test)\n",
    "print(\"bureau_agg_train.isnull().sum().sum()\", bureau_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_agg_test.isnull().sum().sum()\", bureau_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(bureau_agg_train)\n",
    "bureau_agg_train = remover.transform(bureau_agg_train)\n",
    "bureau_agg_test = remover.transform(bureau_agg_test)\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(bureau_agg_train)\n",
    "bureau_agg_train = remover.transform(bureau_agg_train)\n",
    "bureau_agg_test = remover.transform(bureau_agg_test)\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "bureau_agg_train = bureau_agg_train.reset_index()\n",
    "bureau_agg_test = bureau_agg_test.reset_index()\n",
    "print(\"bureau_agg_train.shape\", bureau_agg_train.shape)\n",
    "print(\"bureau_agg_test.shape\", bureau_agg_test.shape)\n",
    "\n",
    "\n",
    "if True:\n",
    "    bureau_agg_train.to_csv(\"data/data_/bureau_agg_train.csv\", index=False)\n",
    "    bureau_agg_test.to_csv(\"data/data_/bureau_agg_test.csv\", index=False)\n",
    "\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `bureau_balance.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_nearest_status(df):\n",
    "    return df.sort_values(by=[\"MONTHS_BALANCE\"], ascending=False)[\"STATUS\"].iloc[0]\n",
    "\n",
    "def bb_mode_status_three_nearest(df):\n",
    "    statuses = df.sort_values(by=[\"MONTHS_BALANCE\"], ascending=False)[\"STATUS\"].iloc[: 3]\n",
    "    return statuses.mode().values[0]\n",
    "\n",
    "def bb_mode_status_six_nearest(df):\n",
    "    statuses = df.sort_values(by=[\"MONTHS_BALANCE\"], ascending=False)[\"STATUS\"].iloc[: 6]\n",
    "    return statuses.mode().values[0]\n",
    "\n",
    "\n",
    "def add_new_agg_cols_bb(df):\n",
    "    results = {}\n",
    "    results[\"NEAREST_STATUS\"] = df.groupby(\"SK_ID_BUREAU\").apply(bb_nearest_status)\n",
    "    results[\"MODE_STATUS_THREE_NEAREST\"] = df.groupby(\"SK_ID_BUREAU\").apply(bb_mode_status_three_nearest)\n",
    "    results[\"MODE_STATUS_SIX_NEAREST\"] = df.groupby(\"SK_ID_BUREAU\").apply(bb_mode_status_six_nearest)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = load_csv(\"data/download/bureau_balance.csv\")\n",
    "print(\"bureau_balance.shape\", bureau_balance.shape)\n",
    "\n",
    "bureau_balance = bureau_balance.merge(bureau[[\"SK_ID_CURR\", \"SK_ID_BUREAU\"]], how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "bureau_balance = bureau_balance.dropna(subset=[\"SK_ID_CURR\"])\n",
    "bureau_balance[\"SK_ID_CURR\"] = bureau_balance[\"SK_ID_CURR\"].astype(\"int32\")\n",
    "print(\"bureau_balance.shape\", bureau_balance.shape)\n",
    "\n",
    "bureau_balance_train, bureau_balance_test = train_test_partition(bureau_balance, \"SK_ID_CURR\", appl_train_key)\n",
    "bureau_balance_train = bureau_balance_train.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "bureau_balance_test = bureau_balance_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"bureau_balance_train.shape:\", bureau_balance_train.shape)\n",
    "print(\"bureau_balance_test.shape:\", bureau_balance_test.shape)\n",
    "\n",
    "bureau_balance_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "bureau_balance_agg_train = bureau_balance_train.copy()\n",
    "bureau_balance_agg_test = bureau_balance_test.copy()\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = numcolsqcuter.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = numcolsqcuter.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"New agg cols\")\n",
    "new_agg_cols_train = add_new_agg_cols_bb(bureau_balance_agg_train)\n",
    "new_agg_cols_test = add_new_agg_cols_bb(bureau_balance_agg_test)\n",
    "\n",
    "\n",
    "print(\"Aggregate over SK_ID_BUREAU\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_BUREAU\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = aggregator.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = aggregator.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new aggs cols\")\n",
    "for col in new_agg_cols_train:\n",
    "    bureau_balance_agg_train[col] = new_agg_cols_train[col]\n",
    "\n",
    "for col in new_agg_cols_test:\n",
    "    bureau_balance_agg_test[col] = new_agg_cols_test[col]\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = imputer.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = imputer.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = remover.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = remover.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = remover.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = remover.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "bureau_balance_agg_train = bureau_balance_agg_train.reset_index()\n",
    "bureau_balance_agg_test = bureau_balance_agg_test.reset_index()\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "if True:\n",
    "    bureau_balance_agg_train.to_csv(\"data/data_/bureau_balance_agg_train_tmp.csv\", index=False)\n",
    "    bureau_balance_agg_test.to_csv(\"data/data_/bureau_balance_agg_test_tmp.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate over \"SK_ID_CURR\"\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "bureau_balance_agg_train = load_csv(\"data/data_/bureau_balance_agg_train_tmp.csv\")\n",
    "bureau_balance_agg_test = load_csv(\"data/data_/bureau_balance_agg_test_tmp.csv\")\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "bureau_balance_agg_train = bureau_balance_agg_train.merge(bureau_train_keys, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "bureau_balance_agg_test = bureau_balance_agg_test.merge(bureau_test_keys, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "bureau_balance_agg_train = bureau_balance_agg_train.drop([\"SK_ID_BUREAU\"], axis=\"columns\")\n",
    "bureau_balance_agg_test = bureau_balance_agg_test.drop([\"SK_ID_BUREAU\"], axis=\"columns\")\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Aggregate\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_CURR\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = aggregator.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = aggregator.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = imputer.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = imputer.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.isnull().sum().sum():\", bureau_balance_agg_train.isnull().sum().sum())\n",
    "print(\"bureau_balance_agg_test.isnull().sum().sum():\", bureau_balance_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = remover.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = remover.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(bureau_balance_agg_train)\n",
    "bureau_balance_agg_train = remover.transform(bureau_balance_agg_train)\n",
    "bureau_balance_agg_test = remover.transform(bureau_balance_agg_test)\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "\n",
    "bureau_balance_agg_train = bureau_balance_agg_train.reset_index()\n",
    "bureau_balance_agg_test = bureau_balance_agg_test.reset_index()\n",
    "print(\"bureau_balance_agg_train.shape\", bureau_balance_agg_train.shape)\n",
    "print(\"bureau_balance_agg_test.shape\", bureau_balance_agg_test.shape)\n",
    "\n",
    "if True:\n",
    "    bureau_balance_agg_train.to_csv(\"data/data_/bureau_balance_agg_train.csv\", index=False)\n",
    "    bureau_balance_agg_test.to_csv(\"data/data_/bureau_balance_agg_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from `previous application` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `previous_application.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrevApplImputer(Imputer):\n",
    "    def __init__(self):\n",
    "        self._regex_strings = None\n",
    "        self._spec_impt_regex_val_num = None\n",
    "        \n",
    "        self._spec_impt_vals_num = {\"RATE_DOWN_PAYMENT\": -1.,\n",
    "                                   \"CNT_PAYMENT\": -10.,\n",
    "                                   \"DAYS_FIRST_DRAWING\": 0., \n",
    "                                   \"DAYS_FIRST_DUE\": 0.,\n",
    "                                   \"DAYS_LAST_DUE_1ST_VERSION\": 0.,\n",
    "                                   \"DAYS_LAST_DUE\": 0.,\n",
    "                                   \"DAYS_TERMINATION\": 0.}\n",
    "        self._default_imput_vals_num = \"median\"\n",
    "        \n",
    "        self._spec_impt_vals_cat = {\"NAME_TYPE_SUITE\": \"missing_value\",\n",
    "                                    \"NFLAG_INSURED_ON_APPROVAL\": \"missing_value\"}\n",
    "        self._default_imput_vals_cat = \"missing_value\"\n",
    "    \n",
    "\n",
    "def hour_period_bin(hours):\n",
    "    hours = hours.values\n",
    "    hour_bin = np.array([\"evening\"] * len(hours), dtype=\"object\")\n",
    "    morning_mask = (hours > 5) & (hours < 12)\n",
    "    afternoon_mask = (hours >= 12) & (hours < 18)\n",
    "    \n",
    "    hour_bin[morning_mask] = \"morning\"\n",
    "    hour_bin[afternoon_mask] = \"afternoon\"\n",
    "    return hour_bin\n",
    "\n",
    "\n",
    "def add_new_cols_prev_appl(df):\n",
    "    # add to bool cols to identify if values are non-negative\n",
    "    cols_is_nonneg = [\"DAYS_FIRST_DRAWING\", \"DAYS_FIRST_DUE\", \n",
    "                      \"DAYS_LAST_DUE_1ST_VERSION\", \n",
    "                      \"DAYS_LAST_DUE\", \"DAYS_TERMINATION\"]\n",
    "    for col in cols_is_nonneg:\n",
    "        df[col + \"_IS_NONNEG\"] = df[col] >= 0\n",
    "        \n",
    "        df[\"PERIOD_APPR_PROCESS_START\"] = hour_period_bin(df[\"HOUR_APPR_PROCESS_START\"])\n",
    "        df[\"PERIOD_APPR_PROCESS_START\"] = df[\"PERIOD_APPR_PROCESS_START\"].astype(\"category\")\n",
    "    \n",
    "    df[\"AMT_APPLICATION_TO_CREDIT\"] = df[\"AMT_APPLICATION\"] / (df[\"AMT_CREDIT\"] + 1)\n",
    "    df[\"AMT_DOWN_PAY_TO_CREDIT\"] = df[\"AMT_DOWN_PAYMENT\"] / (df[\"AMT_CREDIT\"] + 1)\n",
    "    df[\"AMT_GOODS_PRICE_TO_CREDIT\"] = df[\"AMT_GOODS_PRICE\"] / (df[\"AMT_CREDIT\"] + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def mean_n_nearest(df, sort_by, n, col):\n",
    "    ser = df.sort_values(by=sort_by, ascending=False)[col].iloc[: n]\n",
    "    return ser.mean()\n",
    "\n",
    "def min_n_nearest(df, sort_by, n, col):\n",
    "    ser = df.sort_values(by=sort_by, ascending=False)[col].iloc[: n]\n",
    "    return ser.min()\n",
    "\n",
    "def max_n_nearest(df, sort_by, n, col):\n",
    "    ser = df.sort_values(by=sort_by, ascending=False)[col].iloc[: n]\n",
    "    return ser.max()\n",
    "\n",
    "\n",
    "def add_new_agg_cols_prev_appl(df):\n",
    "    sort_by = [\"DAYS_DECISION\"]\n",
    "    orig_cols = [\"AMT_APPLICATION_TO_CREDIT\", \"AMT_DOWN_PAY_TO_CREDIT\", \"AMT_GOODS_PRICE_TO_CREDIT\"]\n",
    "    number_nn_entries = [3, 6]\n",
    "    \n",
    "    results = {}\n",
    "    for col in orig_cols:\n",
    "        for n in number_nn_entries:\n",
    "            new_col = \"MEAN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest mean for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_CURR\").apply(lambda df: mean_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MIN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest min for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_CURR\").apply(lambda df: min_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MAX_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest max for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_CURR\").apply(lambda df: max_n_nearest(df, sort_by, n, col))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application = load_csv(\"data/download/previous_application.csv\")\n",
    "print(\"previous_application.shape\", previous_application.shape)\n",
    "\n",
    "prev_appl_train, prev_appl_test = train_test_partition(previous_application, \"SK_ID_CURR\", appl_train_key)\n",
    "\n",
    "print(\"prev_appl_train.shape\", prev_appl_train.shape)\n",
    "print(\"prev_appl_test.shape\", prev_appl_test.shape)\n",
    "\n",
    "\n",
    "prev_appl_train_keys = prev_appl_train[[\"SK_ID_CURR\", \"SK_ID_PREV\"]]\n",
    "prev_appl_test_keys = prev_appl_test[[\"SK_ID_CURR\", \"SK_ID_PREV\"]]\n",
    "\n",
    "prev_appl_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "prev_appl_agg_train = prev_appl_train.copy()\n",
    "prev_appl_agg_test = prev_appl_test.copy()\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "prev_appl_agg_train = prev_appl_agg_train.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "prev_appl_agg_test = prev_appl_agg_test.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "# drop cols with high percentage of null\n",
    "cols_to_drop = [\"RATE_INTEREST_PRIMARY\", \"RATE_INTEREST_PRIVILEGED\"]\n",
    "prev_appl_agg_train = prev_appl_agg_train.drop(cols_to_drop, axis=\"columns\")\n",
    "prev_appl_agg_test = prev_appl_agg_test.drop(cols_to_drop, axis=\"columns\")\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(prev_appl_agg_train)\n",
    "prev_appl_agg_train = numcolsqcuter.transform(prev_appl_agg_train)\n",
    "prev_appl_agg_test = numcolsqcuter.transform(prev_appl_agg_test)\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute missing values\")\n",
    "imputer = PrevApplImputer()\n",
    "imputer.fit(prev_appl_agg_train)\n",
    "prev_appl_agg_train = imputer.transform(prev_appl_agg_train)\n",
    "prev_appl_agg_test = imputer.transform(prev_appl_agg_test)\n",
    "print(\"prev_appl_agg_train.isnull().sum().sum()\", prev_appl_agg_train.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_test.isnull().sum().sum()\", prev_appl_agg_test.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new cols\")\n",
    "prev_appl_agg_train = add_new_cols_prev_appl(prev_appl_agg_train)\n",
    "prev_appl_agg_test = add_new_cols_prev_appl(prev_appl_agg_test)\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"New agg cols\")\n",
    "new_agg_cols_train = add_new_agg_cols_prev_appl(prev_appl_agg_train)\n",
    "new_agg_cols_test = add_new_agg_cols_prev_appl(prev_appl_agg_test)\n",
    "\n",
    "\n",
    "print(\"Aggregate over SK_ID_CURR\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_CURR\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(prev_appl_agg_train)\n",
    "prev_appl_agg_train = aggregator.transform(prev_appl_agg_train)\n",
    "prev_appl_agg_test = aggregator.transform(prev_appl_agg_test)\n",
    "\n",
    "print(\"prev_appl_agg_train.isnull().sum().sum()\", prev_appl_agg_train.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_test.isnull().sum().sum()\", prev_appl_agg_test.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new agg cols\")\n",
    "for col in new_agg_cols_train:\n",
    "    prev_appl_agg_train[col] = new_agg_cols_train[col]\n",
    "\n",
    "for col in new_agg_cols_test:\n",
    "    prev_appl_agg_test[col] = new_agg_cols_test[col]\n",
    "\n",
    "print(\"prev_appl_agg_train.isnull().sum().sum()\", prev_appl_agg_train.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_test.isnull().sum().sum()\", prev_appl_agg_test.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(prev_appl_agg_train)\n",
    "prev_appl_agg_train = imputer.transform(prev_appl_agg_train)\n",
    "prev_appl_agg_test = imputer.transform(prev_appl_agg_test)\n",
    "print(\"prev_appl_agg_train.isnull().sum().sum()\", prev_appl_agg_train.isnull().sum().sum())\n",
    "print(\"prev_appl_agg_test.isnull().sum().sum()\", prev_appl_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(prev_appl_agg_train)\n",
    "prev_appl_agg_train = remover.transform(prev_appl_agg_train)\n",
    "prev_appl_agg_test = remover.transform(prev_appl_agg_test)\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(prev_appl_agg_train)\n",
    "prev_appl_agg_train = remover.transform(prev_appl_agg_train)\n",
    "prev_appl_agg_test = remover.transform(prev_appl_agg_test)\n",
    "print(\"prev_appl_agg_train.shape\", prev_appl_agg_train.shape)\n",
    "print(\"prev_appl_agg_test.shape\", prev_appl_agg_test.shape)\n",
    "\n",
    "\n",
    "prev_appl_agg_train = prev_appl_agg_train.reset_index()\n",
    "prev_appl_agg_test = prev_appl_agg_test.reset_index()\n",
    "\n",
    "if True:\n",
    "    prev_appl_agg_train.to_csv(\"data/data_/previous_application_agg_train.csv\", index=False)\n",
    "    prev_appl_agg_test.to_csv(\"data/data_/previous_application_agg_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `POS_CASH_balance.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCBalImputer(Imputer):\n",
    "    def __init__(self):\n",
    "        self._regex_strings = None\n",
    "        self._spec_impt_regex_val_num = None\n",
    "        \n",
    "        self._spec_impt_vals_num = {\"CNT_INSTALMENT\": -1.,\n",
    "                                   \"CNT_INSTALMENT_FUTURE\": -1.,\n",
    "                                   }\n",
    "        self._default_imput_vals_num = \"median\"\n",
    "        \n",
    "        self._spec_impt_vals_cat = None\n",
    "        self._default_imput_vals_cat = \"missing_value\"\n",
    "\n",
    "\n",
    "def add_new_agg_cols_pc_bal(df):\n",
    "    sort_by = [\"MONTHS_BALANCE\"]\n",
    "    orig_cols = [\"CNT_INSTALMENT\", \"CNT_INSTALMENT_FUTURE\", \"SK_DPD\", \"SK_DPD_DEF\"]\n",
    "    number_nn_entries = [3, 6]\n",
    "    \n",
    "    results = {}\n",
    "    for col in orig_cols:\n",
    "        for n in number_nn_entries:\n",
    "            new_col = \"MEAN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest mean for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: mean_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MIN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest min for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: min_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MAX_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest max for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: max_n_nearest(df, sort_by, n, col))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_CASH_balance = load_csv(\"data/download/POS_CASH_balance.csv\")\n",
    "print(\"POS_CASH_balance.shape\", POS_CASH_balance.shape)\n",
    "\n",
    "POS_CASH_balance = POS_CASH_balance.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "POS_CASH_balance = POS_CASH_balance.merge(previous_application[[\"SK_ID_PREV\", \"SK_ID_CURR\"]], \n",
    "                                          how=\"left\", on=\"SK_ID_PREV\")\n",
    "print(\"POS_CASH_balance.shape\", POS_CASH_balance.shape)\n",
    "\n",
    "# drop rows that does not have \"SK_ID_PREV\" in previous_application\n",
    "POS_CASH_balance = POS_CASH_balance.dropna(subset=[\"SK_ID_CURR\"])\n",
    "POS_CASH_balance[\"SK_ID_CURR\"] = POS_CASH_balance[\"SK_ID_CURR\"].astype(\"int32\")\n",
    "print(\"POS_CASH_balance.shape\", POS_CASH_balance.shape)\n",
    "\n",
    "PC_bal_train, PC_bal_test = train_test_partition(POS_CASH_balance, \"SK_ID_CURR\", appl_train_key)\n",
    "PC_bal_train = PC_bal_train.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "PC_bal_test = PC_bal_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"PC_bal_train.shape:\", PC_bal_train.shape)\n",
    "print(\"PC_bal_test.shape:\", PC_bal_test.shape)\n",
    "\n",
    "PC_bal_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "PC_bal_agg_train = PC_bal_train.copy()\n",
    "PC_bal_agg_test = PC_bal_test.copy()\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = numcolsqcuter.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = numcolsqcuter.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute missing values\")\n",
    "imputer = PCBalImputer()\n",
    "imputer.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = imputer.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = imputer.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "print(\"PC_bal_agg_train.isnull().sum().sum()\", PC_bal_agg_train.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_test.isnull().sum().sum()\", PC_bal_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"New agg cols\")\n",
    "new_agg_cols_train = add_new_agg_cols_pc_bal(PC_bal_agg_train)\n",
    "new_agg_cols_test = add_new_agg_cols_pc_bal(PC_bal_agg_test)\n",
    "\n",
    "PC_bal_agg_train = PC_bal_agg_train.drop([\"MONTHS_BALANCE\"], axis=\"columns\")\n",
    "PC_bal_agg_test = PC_bal_agg_test.drop([\"MONTHS_BALANCE\"], axis=\"columns\")\n",
    "\n",
    "\n",
    "print(\"Aggregate over SK_ID_PREV\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_PREV\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = aggregator.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = aggregator.transform(PC_bal_agg_test)\n",
    "\n",
    "print(\"PC_bal_agg_train.isnull().sum().sum()\", PC_bal_agg_train.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_test.isnull().sum().sum()\", PC_bal_agg_test.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new agg cols\")\n",
    "for col in new_agg_cols_train:\n",
    "    PC_bal_agg_train[col] = new_agg_cols_train[col]\n",
    "\n",
    "for col in new_agg_cols_test:\n",
    "    PC_bal_agg_test[col] = new_agg_cols_test[col]\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = imputer.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = imputer.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.isnull().sum().sum()\", PC_bal_agg_train.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_test.isnull().sum().sum()\", PC_bal_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = remover.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = remover.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = remover.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = remover.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "PC_bal_agg_train = PC_bal_agg_train.reset_index()\n",
    "PC_bal_agg_test = PC_bal_agg_test.reset_index()\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "if True:\n",
    "    PC_bal_agg_train.to_csv(\"data/data_/POS_CASH_balance_agg_train_tmp.csv\", index=False)\n",
    "    PC_bal_agg_test.to_csv(\"data/data_/POS_CASH_balance_agg_test_tmp.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate over SK_ID_CURR\n",
    "time_start = time.time()\n",
    "\n",
    "# this turns [0, 1] into bool\n",
    "PC_bal_agg_train = load_csv(\"data/data_/POS_CASH_balance_agg_train_tmp.csv\")\n",
    "PC_bal_agg_test = load_csv(\"data/data_/POS_CASH_balance_agg_test_tmp.csv\")\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "PC_bal_agg_train = PC_bal_agg_train.merge(prev_appl_train_keys, how=\"left\", on=\"SK_ID_PREV\")\n",
    "PC_bal_agg_test = PC_bal_agg_test.merge(prev_appl_test_keys, how=\"left\", on=\"SK_ID_PREV\")\n",
    "print(\"PC_bal_agg_train.isnull().sum().sum()\", PC_bal_agg_train.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_test.isnull().sum().sum()\", PC_bal_agg_test.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "PC_bal_agg_train = PC_bal_agg_train.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "PC_bal_agg_test = PC_bal_agg_test.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Aggregate\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_CURR\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = aggregator.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = aggregator.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.isnull().sum().sum()\", PC_bal_agg_train.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_test.isnull().sum().sum()\", PC_bal_agg_test.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = imputer.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = imputer.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.isnull().sum().sum()\", PC_bal_agg_train.isnull().sum().sum())\n",
    "print(\"PC_bal_agg_test.isnull().sum().sum()\", PC_bal_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = remover.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = remover.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(PC_bal_agg_train)\n",
    "PC_bal_agg_train = remover.transform(PC_bal_agg_train)\n",
    "PC_bal_agg_test = remover.transform(PC_bal_agg_test)\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "PC_bal_agg_train = PC_bal_agg_train.reset_index()\n",
    "PC_bal_agg_test = PC_bal_agg_test.reset_index()\n",
    "print(\"PC_bal_agg_train.shape:\", PC_bal_agg_train.shape)\n",
    "print(\"PC_bal_agg_test.shape:\", PC_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "if True:\n",
    "    PC_bal_agg_train.to_csv(\"data/data_/POS_CASH_balance_agg_train.csv\", index=False)\n",
    "    PC_bal_agg_test.to_csv(\"data/data_/POS_CASH_balance_agg_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `installments_payments.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstalPayImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        self._days_entry_payment_impute = df_train[\"DAYS_ENTRY_PAYMENT\"].min() - 10\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df[\"DAYS_ENTRY_PAYMENT\"] = df[\"DAYS_ENTRY_PAYMENT\"].fillna(self._days_entry_payment_impute)\n",
    "        df[\"AMT_PAYMENT\"] = df[\"AMT_PAYMENT\"].fillna(0.)\n",
    "        return df\n",
    "\n",
    "\n",
    "def add_new_cols_inst_pay(df):\n",
    "    df[\"DAYS_INSTAL_PAY_DIFF\"] = df[\"DAYS_ENTRY_PAYMENT\"] - df[\"DAYS_INSTALMENT\"]\n",
    "    df[\"DAYS_INSTAL_PAY_DIFF_ISPOSITIVE\"] = df[\"DAYS_INSTAL_PAY_DIFF\"] > 0\n",
    "    \n",
    "    df[\"AMT_INSTAL_PAY_DIFF\"] = df[\"AMT_PAYMENT\"] - df[\"AMT_INSTALMENT\"]\n",
    "    df[\"AMT_INSTAL_PAY_DIFF_ISPOSITIVE\"] = df[\"AMT_INSTAL_PAY_DIFF\"] > 0\n",
    "    \n",
    "    df[\"AMT_PAY_INSTAL_RATIO\"] = np.clip((df[\"AMT_PAYMENT\"] + 1) / (df[\"AMT_INSTALMENT\"] + 1), 0., 10.)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_new_agg_cols_inst_pay(df):\n",
    "    sort_by = [\"DAYS_INSTALMENT\"]\n",
    "    orig_cols = [\"DAYS_INSTAL_PAY_DIFF\", \"AMT_INSTAL_PAY_DIFF\", \"AMT_PAY_INSTAL_RATIO\"]\n",
    "    number_nn_entries = [3, 6]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for col in orig_cols:\n",
    "        for n in number_nn_entries:\n",
    "            new_col = \"MEAN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest mean for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: mean_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MIN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest min for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: min_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MAX_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest max for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: max_n_nearest(df, sort_by, n, col))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments = load_csv(\"data/download/installments_payments.csv\")\n",
    "print(\"installments_payments.shape\", installments_payments.shape)\n",
    "\n",
    "installments_payments = installments_payments.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "installments_payments = installments_payments.merge(previous_application[[\"SK_ID_PREV\", \"SK_ID_CURR\"]],\n",
    "                                                   how=\"left\", on=\"SK_ID_PREV\")\n",
    "\n",
    "# drop rows that does not have \"SK_ID_PREV\" in previous_application\n",
    "installments_payments = installments_payments.dropna(subset=[\"SK_ID_CURR\"])\n",
    "installments_payments[\"SK_ID_CURR\"] = installments_payments[\"SK_ID_CURR\"].astype(\"int32\")\n",
    "print(\"installments_payments.shape\", installments_payments.shape)\n",
    "\n",
    "inst_pay_train, inst_pay_test = train_test_partition(installments_payments, \"SK_ID_CURR\", appl_train_key)\n",
    "inst_pay_train = inst_pay_train.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "inst_pay_test = inst_pay_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"inst_pay_train.shape:\", inst_pay_train.shape)\n",
    "print(\"inst_pay_test.shape:\", inst_pay_test.shape)\n",
    "\n",
    "inst_pay_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "inst_pay_agg_train = inst_pay_train.copy()\n",
    "inst_pay_agg_test = inst_pay_test.copy()\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = numcolsqcuter.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = numcolsqcuter.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute\")\n",
    "imputer = InstalPayImputer()\n",
    "imputer.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = imputer.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = imputer.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum()\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum()\", inst_pay_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"default imputer\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = imputer.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = imputer.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum()\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum()\", inst_pay_agg_test.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add some more cols\")\n",
    "inst_pay_agg_train = add_new_cols_inst_pay(inst_pay_agg_train)\n",
    "inst_pay_agg_test = add_new_cols_inst_pay(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"New agg cols\")\n",
    "new_agg_cols_train = add_new_agg_cols_inst_pay(inst_pay_agg_train)\n",
    "new_agg_cols_test = add_new_agg_cols_inst_pay(inst_pay_agg_test)\n",
    "\n",
    "inst_pay_agg_train = inst_pay_agg_train.drop([\"DAYS_INSTALMENT\"], axis=\"columns\")\n",
    "inst_pay_agg_test = inst_pay_agg_test.drop([\"DAYS_INSTALMENT\"], axis=\"columns\")\n",
    "\n",
    "\n",
    "print(\"Aggregate over SK_ID_PREV\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_PREV\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = aggregator.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = aggregator.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum():\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum():\", inst_pay_agg_test.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new agg cols\")\n",
    "for col in new_agg_cols_train:\n",
    "    inst_pay_agg_train[col] = new_agg_cols_train[col]\n",
    "    \n",
    "for col in new_agg_cols_test:\n",
    "    inst_pay_agg_test[col] = new_agg_cols_test[col]\n",
    "\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Just in case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = imputer.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = imputer.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum()\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum()\", inst_pay_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = remover.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = remover.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = remover.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = remover.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "inst_pay_agg_train = inst_pay_agg_train.reset_index()\n",
    "inst_pay_agg_test = inst_pay_agg_test.reset_index()\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "if True:\n",
    "    inst_pay_agg_train.to_csv(\"data/data_/installments_payments_agg_train_tmp.csv\", index=False)\n",
    "    inst_pay_agg_test.to_csv(\"data/data_/installments_payments_agg_test_tmp.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate over \"SK_ID_CURR\"\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "inst_pay_agg_train = load_csv(\"data/data_/installments_payments_agg_train_tmp.csv\")\n",
    "inst_pay_agg_test = load_csv(\"data/data_/installments_payments_agg_test_tmp.csv\")\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "inst_pay_agg_train = inst_pay_agg_train.merge(prev_appl_train_keys, how=\"left\", on=\"SK_ID_PREV\")\n",
    "inst_pay_agg_test = inst_pay_agg_test.merge(prev_appl_test_keys, how=\"left\", on=\"SK_ID_PREV\")\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum():\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum():\", inst_pay_agg_test.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "inst_pay_agg_train = inst_pay_agg_train.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "inst_pay_agg_test = inst_pay_agg_test.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Aggregate\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_CURR\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = aggregator.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = aggregator.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum():\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum():\", inst_pay_agg_test.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Just in case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = imputer.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = imputer.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.isnull().sum().sum()\", inst_pay_agg_train.isnull().sum().sum())\n",
    "print(\"inst_pay_agg_test.isnull().sum().sum()\", inst_pay_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = remover.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = remover.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(inst_pay_agg_train)\n",
    "inst_pay_agg_train = remover.transform(inst_pay_agg_train)\n",
    "inst_pay_agg_test = remover.transform(inst_pay_agg_test)\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "inst_pay_agg_train = inst_pay_agg_train.reset_index()\n",
    "inst_pay_agg_test = inst_pay_agg_test.reset_index()\n",
    "print(\"inst_pay_agg_train.shape:\", inst_pay_agg_train.shape)\n",
    "print(\"inst_pay_agg_test.shape:\", inst_pay_agg_test.shape)\n",
    "\n",
    "if True:\n",
    "    inst_pay_agg_train.to_csv(\"data/data_/installments_payments_agg_train.csv\", index=False)\n",
    "    inst_pay_agg_test.to_csv(\"data/data_/installments_payments_agg_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `credit_card_balance.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCBalImputer(Imputer):\n",
    "    def __init__(self):\n",
    "        self._regex_strings = None\n",
    "        self._spec_impt_regex_val_num = None\n",
    "        \n",
    "        self._spec_impt_vals_num = {\"AMT_DRAWINGS_ATM_CURRENT\": 0.,\n",
    "                                   \"AMT_DRAWINGS_OTHER_CURRENT\": 0., \n",
    "                                    \"AMT_DRAWINGS_POS_CURRENT\": 0.,\n",
    "                                    \"AMT_INST_MIN_REGULARITY\": 0.,\n",
    "                                    \"AMT_PAYMENT_CURRENT\": 0.,\n",
    "                                    \"CNT_DRAWINGS_ATM_CURRENT\": 0.,\n",
    "                                    \"CNT_DRAWINGS_OTHER_CURRENT\": 0.,\n",
    "                                    \"CNT_DRAWINGS_POS_CURRENT\": 0.,\n",
    "                                    \"CNT_INSTALMENT_MATURE_CUM\": 0.,\n",
    "                                    \n",
    "                                   }\n",
    "        self._default_imput_vals_num = 0.\n",
    "        \n",
    "        self._spec_impt_vals_cat = None\n",
    "        self._default_imput_vals_cat = \"missing_value\"\n",
    "        \n",
    "\n",
    "def add_new_cols_cc_bal(df):\n",
    "    df[\"AMT_PAYMENT_TO_BALANCE\"] = df[\"AMT_PAYMENT_TOTAL_CURRENT\"] / df[\"AMT_BALANCE\"].replace(0., 1.)\n",
    "    df[\"AMT_BALANCE_TO_CREDIT_LIMIT\"] = (df[\"AMT_BALANCE\"] + 1) / (df[\"AMT_CREDIT_LIMIT_ACTUAL\"] + 1)\n",
    "    df[\"AMT_DRAWING_TOTAL\"] = (df[\"AMT_DRAWINGS_ATM_CURRENT\"] + df[\"AMT_DRAWINGS_CURRENT\"] + \n",
    "                              df[\"AMT_DRAWINGS_OTHER_CURRENT\"] + df[\"AMT_DRAWINGS_POS_CURRENT\"])\n",
    "    df[\"AMT_DRAWING_TOTAL_TO_CREDIT_LIMIT\"] = df[\"AMT_DRAWING_TOTAL\"] / (df[\"AMT_CREDIT_LIMIT_ACTUAL\"] + 1)\n",
    "    df[\"AMT_PAYMENT_TOTAL_TO_DRAWING_TOTAL\"] = (df[\"AMT_PAYMENT_TOTAL_CURRENT\"] / \n",
    "                                                df[\"AMT_DRAWING_TOTAL\"].replace(0., 1.))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_new_agg_cols_cc_bal(df):\n",
    "    sort_by = [\"MONTHS_BALANCE\"]\n",
    "    orig_cols = [\"AMT_PAYMENT_TO_BALANCE\", \"AMT_BALANCE_TO_CREDIT_LIMIT\", \n",
    "                 \"AMT_DRAWING_TOTAL_TO_CREDIT_LIMIT\", \"AMT_PAYMENT_TOTAL_TO_DRAWING_TOTAL\", \n",
    "                 \"SK_DPD\"]\n",
    "    number_nn_entries = [3, 6]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for col in orig_cols:\n",
    "        for n in number_nn_entries:\n",
    "            new_col = \"MEAN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest mean for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: mean_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MIN_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest min for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: min_n_nearest(df, sort_by, n, col))\n",
    "            \n",
    "            new_col = \"MAX_\" + col + \"_%d_NEAREST\" % n\n",
    "            print(\"Nearest max for \" + new_col)\n",
    "            results[new_col] = df.groupby(\"SK_ID_PREV\").apply(lambda df: max_n_nearest(df, sort_by, n, col))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance = load_csv(\"data/download/credit_card_balance.csv\")\n",
    "print(\"credit_card_balance.shape\", credit_card_balance.shape)\n",
    "\n",
    "credit_card_balance = credit_card_balance.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "credit_card_balance = credit_card_balance.merge(previous_application[[\"SK_ID_PREV\", \"SK_ID_CURR\"]],\n",
    "                                               how=\"left\", on=\"SK_ID_PREV\")\n",
    "\n",
    "credit_card_balance = credit_card_balance.dropna(subset=[\"SK_ID_CURR\"])\n",
    "credit_card_balance[\"SK_ID_CURR\"] = credit_card_balance[\"SK_ID_CURR\"].astype(\"int32\")\n",
    "print(\"credit_card_balance.shape\", credit_card_balance.shape)\n",
    "\n",
    "cc_bal_train, cc_bal_test = train_test_partition(credit_card_balance, \"SK_ID_CURR\", appl_train_key)\n",
    "cc_bal_train = cc_bal_train.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "cc_bal_test = cc_bal_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "\n",
    "print(\"cc_bal_train.shape:\", cc_bal_train.shape)\n",
    "print(\"cc_bal_test.shape:\", cc_bal_test.shape)\n",
    "\n",
    "cc_bal_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "cc_bal_agg_train = cc_bal_train.copy()\n",
    "cc_bal_agg_test = cc_bal_test.copy()\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Bin numerical columns\")\n",
    "numcolsqcuter = NumColsQCuter()\n",
    "numcolsqcuter.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = numcolsqcuter.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = numcolsqcuter.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute missing values\")\n",
    "imputer = CCBalImputer()\n",
    "imputer.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = imputer.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = imputer.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.isnull().sum().sum():\", cc_bal_agg_train.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_test.isnull().sum().sum():\", cc_bal_agg_test.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new cols\")\n",
    "cc_bal_agg_train = add_new_cols_cc_bal(cc_bal_agg_train)\n",
    "cc_bal_agg_test = add_new_cols_cc_bal(cc_bal_agg_test)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = remover.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = remover.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"New agg cols\")\n",
    "new_agg_cols_train = add_new_agg_cols_cc_bal(cc_bal_agg_train)\n",
    "new_agg_cols_test = add_new_agg_cols_cc_bal(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Aggregate over SK_ID_PREV\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_PREV\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = aggregator.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = aggregator.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.isnull().sum().sum():\", cc_bal_agg_train.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_test.isnull().sum().sum():\", cc_bal_agg_test.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Add new agg cols\")\n",
    "for col in new_agg_cols_train:\n",
    "    cc_bal_agg_train[col] = new_agg_cols_train[col]\n",
    "\n",
    "for col in new_agg_cols_test:\n",
    "    cc_bal_agg_test[col] = new_agg_cols_test[col]\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Just in case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = imputer.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = imputer.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.isnull().sum().sum():\", cc_bal_agg_train.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_test.isnull().sum().sum():\", cc_bal_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = remover.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = remover.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = remover.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = remover.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "cc_bal_agg_train = cc_bal_agg_train.reset_index()\n",
    "cc_bal_agg_test = cc_bal_agg_test.reset_index()\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "if True:\n",
    "    cc_bal_agg_train.to_csv(\"data/data_/credit_card_balance_agg_train_tmp.csv\", index=False)\n",
    "    cc_bal_agg_test.to_csv(\"data/data_/credit_card_balance_agg_test_tmp.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate over \"SK_ID_CURR\"\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "cc_bal_agg_train = load_csv(\"data/data_/credit_card_balance_agg_train_tmp.csv\")\n",
    "cc_bal_agg_test = load_csv(\"data/data_/credit_card_balance_agg_test_tmp.csv\")\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "cc_bal_agg_train = cc_bal_agg_train.merge(prev_appl_train_keys, how=\"left\", on=\"SK_ID_PREV\")\n",
    "cc_bal_agg_test = cc_bal_agg_test.merge(prev_appl_test_keys, how=\"left\", on=\"SK_ID_PREV\")\n",
    "print(\"cc_bal_agg_train.isnull().sum().sum():\", cc_bal_agg_train.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_test.isnull().sum().sum():\", cc_bal_agg_test.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "cc_bal_agg_train = cc_bal_agg_train.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "cc_bal_agg_test = cc_bal_agg_test.drop([\"SK_ID_PREV\"], axis=\"columns\")\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Aggregate\")\n",
    "num_stats = [\"sum\", \"mean\", \"median\", \"min\", \"max\", \"var\"]\n",
    "bool_stats = [\"sum\", \"mean\", mode, entropy, hh_index]\n",
    "cat_stats = [\"count\", \"nunique\", mode, entropy, hh_index]\n",
    "ohe_cat_stats = [\"sum\", \"mean\", \"var\"]\n",
    "\n",
    "by_list_cols = [\"SK_ID_CURR\"]\n",
    "\n",
    "aggregator = Aggregator(by_list_cols, num_stats, bool_stats, cat_stats,\n",
    "                        ohe_cat_stats=ohe_cat_stats,\n",
    "                        ohe_cat_max_class=10,\n",
    "                        iqr=True, minmax_range=True, mean_median_diff=True)\n",
    "\n",
    "aggregator.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = aggregator.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = aggregator.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.isnull().sum().sum():\", cc_bal_agg_train.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_test.isnull().sum().sum():\", cc_bal_agg_test.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"In case\")\n",
    "imputer = DefaultImputer()\n",
    "imputer.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = imputer.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = imputer.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.isnull().sum().sum():\", cc_bal_agg_train.isnull().sum().sum())\n",
    "print(\"cc_bal_agg_test.isnull().sum().sum():\", cc_bal_agg_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"Remove constant columns\")\n",
    "remover = ConstantColumnsRemover()\n",
    "remover.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = remover.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = remover.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "print(\"Remove collinear columns\")\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(cc_bal_agg_train)\n",
    "cc_bal_agg_train = remover.transform(cc_bal_agg_train)\n",
    "cc_bal_agg_test = remover.transform(cc_bal_agg_test)\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "\n",
    "# reset index\n",
    "cc_bal_agg_train = cc_bal_agg_train.reset_index()\n",
    "cc_bal_agg_test = cc_bal_agg_test.reset_index()\n",
    "print(\"cc_bal_agg_train.shape\", cc_bal_agg_train.shape)\n",
    "print(\"cc_bal_agg_test.shape\", cc_bal_agg_test.shape)\n",
    "\n",
    "if True:\n",
    "    cc_bal_agg_train.to_csv(\"data/data_/credit_card_balance_agg_train.csv\", index=False)\n",
    "    cc_bal_agg_test.to_csv(\"data/data_/credit_card_balance_agg_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_col_align(df_train, df_test, exclude_cols=None):\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    cols_train = df_train.columns.to_list()\n",
    "    \n",
    "    for col in exclude_cols:\n",
    "        assert col in cols_train, col + \" is not in df_train\"\n",
    "        \n",
    "    test_cols = [col for col in cols_train if col not in exclude_cols]\n",
    "    return df_train[test_cols + exclude_cols], df_test[test_cols]\n",
    "\n",
    "\n",
    "def add_prefix_to_cols(df, prefix, exclude_cols=None):\n",
    "    df = df.copy()\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "        \n",
    "    cols = df.columns.to_list()\n",
    "    for i, col in enumerate(cols):\n",
    "        if col not in exclude_cols:\n",
    "            cols[i] = prefix + col\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_dataframes(df_left, dfs_right, \n",
    "                     left_prefix, right_prefixes, \n",
    "                     on_col=\"SK_ID_CURR\"):\n",
    "    assert isinstance(dfs_right, list), \"dfs_right must be a list\"\n",
    "    assert isinstance(right_prefixes, list), \"right_prefixes must be a list\"\n",
    "    assert len(dfs_right) == len(right_prefixes), \"dfs_right and right_prefixes must have the same len\"\n",
    "    \n",
    "    result = df_left\n",
    "    result = add_prefix_to_cols(result, left_prefix, exclude_cols=[on_col])\n",
    "    \n",
    "    for df, prefix in zip(dfs_right, right_prefixes):\n",
    "        print(\"Merging with \" + prefix)\n",
    "        df = add_prefix_to_cols(df, prefix, exclude_cols=[on_col])\n",
    "        result = result.merge(df, how=\"left\", on=on_col)\n",
    "        \n",
    "        df_cols = [col for col in result.columns if col.startswith(prefix)]\n",
    "        # add mask column to tell which rows in df are missing\n",
    "        result[prefix + \"MISSING_ROW\"] = result[df_cols[0]].isnull()\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "class MergeMissingImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        cols = df_train.columns.to_list()\n",
    "        cols_num = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        cols_cat = [col for col in cols if col not in cols_num]\n",
    "        \n",
    "        self._impute_values = {}\n",
    "        for col in cols_num:\n",
    "            if df_train[col].isnull().sum() > 0:\n",
    "                self._impute_values[col] = df_train[col].median()\n",
    "        \n",
    "        for col in cols_cat:\n",
    "            if df_train[col].isnull().sum() > 0:\n",
    "                self._impute_values[col] = mode(df_train[col])\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        for col, val in self._impute_values.items():\n",
    "            try:\n",
    "                df[col] = df[col].fillna(val)\n",
    "            except AttributeError:\n",
    "                print(\"problem with \" + col)\n",
    "                raise AttributeError()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = load_csv(\"data/data_/application_train.csv\")\n",
    "application_test = load_csv(\"data/data_/application_test.csv\")\n",
    "\n",
    "print(\"application_train.shape:\", application_train.shape)\n",
    "print(\"application_test.shape:\", application_test.shape)\n",
    "\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.99)\n",
    "remover.fit(application_train)\n",
    "application_train = remover.transform(application_train)\n",
    "application_test = remover.transform(application_test)\n",
    "print(\"application_train.shape:\", application_train.shape)\n",
    "print(\"application_test.shape:\", application_test.shape)\n",
    "\n",
    "\n",
    "application_train, application_test = train_test_col_align(application_train, application_test, \n",
    "                                                           exclude_cols=[\"TARGET\"])\n",
    "print(\"application_train.shape:\", application_train.shape)\n",
    "print(\"application_test.shape:\", application_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `bureau`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_train = load_csv(\"data/data_/bureau_agg_train.csv\")\n",
    "bureau_test = load_csv(\"data/data_/bureau_agg_test.csv\")\n",
    "print(\"bureau_train.shape:\", bureau_train.shape)\n",
    "print(\"bureau_test.shape:\", bureau_test.shape)\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.95)\n",
    "remover.fit(bureau_train)\n",
    "bureau_train = remover.transform(bureau_train)\n",
    "bureau_test = remover.transform(bureau_test)\n",
    "print(\"bureau_train.shape:\", bureau_train.shape)\n",
    "print(\"bureau_test.shape:\", bureau_test.shape)\n",
    "\n",
    "bureau_train, bureau_test = train_test_col_align(bureau_train, bureau_test)\n",
    "print(\"bureau_train.shape:\", bureau_train.shape)\n",
    "print(\"bureau_test.shape:\", bureau_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `bureau_balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_train = load_csv(\"data/data_/bureau_balance_agg_train.csv\")\n",
    "bureau_balance_test = load_csv(\"data/data_/bureau_balance_agg_test.csv\")\n",
    "print(\"bureau_balance_train.shape\", bureau_balance_train.shape)\n",
    "print(\"bureau_balance_test.shape\", bureau_balance_test.shape)\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.90)\n",
    "remover.fit(bureau_balance_train)\n",
    "bureau_balance_train = remover.transform(bureau_balance_train)\n",
    "bureau_balance_test = remover.transform(bureau_balance_test)\n",
    "print(\"bureau_balance_train.shape\", bureau_balance_train.shape)\n",
    "print(\"bureau_balance_test.shape\", bureau_balance_test.shape)\n",
    "\n",
    "bureau_balance_train, bureau_balance_test = train_test_col_align(bureau_balance_train, bureau_balance_test)\n",
    "print(\"bureau_balance_train.shape\", bureau_balance_train.shape)\n",
    "print(\"bureau_balance_test.shape\", bureau_balance_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `previous_application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application_train = load_csv(\"data/data_/previous_application_agg_train.csv\")\n",
    "previous_application_test = load_csv(\"data/data_/previous_application_agg_test.csv\")\n",
    "print(\"previous_application_train.shape\", previous_application_train.shape)\n",
    "print(\"previous_application_test.shape\", previous_application_test.shape)\n",
    "\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.95)\n",
    "remover.fit(previous_application_train)\n",
    "previous_application_train = remover.transform(previous_application_train)\n",
    "previous_application_test = remover.transform(previous_application_test)\n",
    "print(\"previous_application_train.shape\", previous_application_train.shape)\n",
    "print(\"previous_application_test.shape\", previous_application_test.shape)\n",
    "\n",
    "\n",
    "previous_application_train, previous_application_test = train_test_col_align(previous_application_train, \n",
    "                                                                             previous_application_test)\n",
    "\n",
    "print(\"previous_application_train.shape\", previous_application_train.shape)\n",
    "print(\"previous_application_test.shape\", previous_application_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `POS_CASH_balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_CASH_balance_train = load_csv(\"data/data_/POS_CASH_balance_agg_train.csv\")\n",
    "POS_CASH_balance_test = load_csv(\"data/data_/POS_CASH_balance_agg_test.csv\")\n",
    "print(\"POS_CASH_balance_train.shape\", POS_CASH_balance_train.shape)\n",
    "print(\"POS_CASH_balance_test.shape\", POS_CASH_balance_test.shape)\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.90)\n",
    "remover.fit(POS_CASH_balance_train)\n",
    "POS_CASH_balance_train = remover.transform(POS_CASH_balance_train)\n",
    "POS_CASH_balance_test = remover.transform(POS_CASH_balance_test)\n",
    "print(\"POS_CASH_balance_train.shape\", POS_CASH_balance_train.shape)\n",
    "print(\"POS_CASH_balance_test.shape\", POS_CASH_balance_test.shape)\n",
    "\n",
    "\n",
    "POS_CASH_balance_train, POS_CASH_balance_test = train_test_col_align(POS_CASH_balance_train, POS_CASH_balance_test)\n",
    "print(\"POS_CASH_balance_train.shape\", POS_CASH_balance_train.shape)\n",
    "print(\"POS_CASH_balance_test.shape\", POS_CASH_balance_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `installments_payments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments_train = load_csv(\"data/data_/installments_payments_agg_train.csv\")\n",
    "installments_payments_test = load_csv(\"data/data_/installments_payments_agg_test.csv\")\n",
    "print(\"installments_payments_train.shape\", installments_payments_train.shape)\n",
    "print(\"installments_payments_test.shape\", installments_payments_test.shape)\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.90)\n",
    "remover.fit(installments_payments_train)\n",
    "installments_payments_train = remover.transform(installments_payments_train)\n",
    "installments_payments_test = remover.transform(installments_payments_test)\n",
    "print(\"installments_payments_train.shape\", installments_payments_train.shape)\n",
    "print(\"installments_payments_test.shape\", installments_payments_test.shape)\n",
    "\n",
    "\n",
    "installments_payments_train, installments_payments_test = train_test_col_align(installments_payments_train, \n",
    "                                                                               installments_payments_test)\n",
    "print(\"installments_payments_train.shape\", installments_payments_train.shape)\n",
    "print(\"installments_payments_test.shape\", installments_payments_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `credit_card_balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance_train = load_csv(\"data/data_/credit_card_balance_agg_train.csv\")\n",
    "credit_card_balance_test = load_csv(\"data/data_/credit_card_balance_agg_test.csv\")\n",
    "print(\"credit_card_balance_train.shape\", credit_card_balance_train.shape)\n",
    "print(\"credit_card_balance_test.shape\", credit_card_balance_test.shape)\n",
    "\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.90)\n",
    "remover.fit(credit_card_balance_train)\n",
    "credit_card_balance_train = remover.transform(credit_card_balance_train)\n",
    "credit_card_balance_test = remover.transform(credit_card_balance_test)\n",
    "print(\"credit_card_balance_train.shape\", credit_card_balance_train.shape)\n",
    "print(\"credit_card_balance_test.shape\", credit_card_balance_test.shape)\n",
    "\n",
    "\n",
    "credit_card_balance_train, credit_card_balance_test = train_test_col_align(credit_card_balance_train, \n",
    "                                                                           credit_card_balance_test)\n",
    "print(\"credit_card_balance_train.shape\", credit_card_balance_train.shape)\n",
    "print(\"credit_card_balance_test.shape\", credit_card_balance_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_train = merge_dataframes(application_train, \n",
    "                               [bureau_train, bureau_balance_train, \n",
    "                                previous_application_train, POS_CASH_balance_train,\n",
    "                                installments_payments_train, credit_card_balance_train], \n",
    "                               \"APPL_\", [\"BURE_\", \"BUBA_\", \"PRAP_\", \"POBA_\", \"INPA_\", \"CCBA_\"])\n",
    "\n",
    "merge_test = merge_dataframes(application_test, \n",
    "                              [bureau_test, bureau_balance_test, \n",
    "                               previous_application_test, POS_CASH_balance_test,\n",
    "                               installments_payments_test, credit_card_balance_test], \n",
    "                              \"APPL_\", [\"BURE_\", \"BUBA_\", \"PRAP_\", \"POBA_\", \"INPA_\", \"CCBA_\"])\n",
    "\n",
    "print(\"merge_train.shape\", merge_train.shape)\n",
    "print(\"merge_test.shape\", merge_test.shape)\n",
    "\n",
    "print(\"merge_train.isnull().sum().sum()\", merge_train.isnull().sum().sum())\n",
    "print(\"merge_test.isnull().sum().sum()\", merge_test.isnull().sum().sum())\n",
    "\n",
    "imputer = MergeMissingImputer()\n",
    "imputer.fit(merge_train)\n",
    "merge_train = imputer.transform(merge_train)\n",
    "merge_test = imputer.transform(merge_test)\n",
    "\n",
    "print(\"merge_train.isnull().sum().sum()\", merge_train.isnull().sum().sum())\n",
    "print(\"merge_test.isnull().sum().sum()\", merge_test.isnull().sum().sum())\n",
    "print(\"merge_train.shape\", merge_train.shape)\n",
    "print(\"merge_test.shape\", merge_test.shape)\n",
    "\n",
    "\n",
    "remover = SameCatColsRemover(threshold=0.95)\n",
    "remover.fit(merge_train)\n",
    "merge_train = remover.transform(merge_train)\n",
    "merge_test = remover.transform(merge_test)\n",
    "print(\"merge_train.shape\", merge_train.shape)\n",
    "print(\"merge_test.shape\", merge_test.shape)\n",
    "\n",
    "\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(merge_train)\n",
    "merge_train = remover.transform(merge_train)\n",
    "merge_test = remover.transform(merge_test)\n",
    "print(\"merge_train.shape\", merge_train.shape)\n",
    "print(\"merge_test.shape\", merge_test.shape)\n",
    "\n",
    "\n",
    "merge_train, merge_test = train_test_col_align(merge_train, merge_test, exclude_cols=[\"APPL_TARGET\"])\n",
    "print(\"merge_train.shape\", merge_train.shape)\n",
    "print(\"merge_test.shape\", merge_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_train.to_csv(\"data/data_/X_y_train.csv\", index=False)\n",
    "merge_test.to_csv(\"data/data_/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del application_train, application_test\n",
    "del bureau_train, bureau_test\n",
    "del bureau_balance_train, bureau_balance_test\n",
    "del previous_application_train, previous_application_test\n",
    "del POS_CASH_balance_train, POS_CASH_balance_test\n",
    "del installments_payments_train, installments_payments_test\n",
    "del credit_card_balance_train, credit_card_balance_test\n",
    "del merge_train, merge_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportantFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator, threshold):\n",
    "        self._fea_impt = estimator.feature_importances_\n",
    "        self._total_features = len(self._fea_impt)\n",
    "        \n",
    "        if isinstance(threshold, int):\n",
    "            self._n_sel_features = threshold\n",
    "        elif isinstance(threshold, float) and (0 <= threshold <= 1):\n",
    "            self._n_sel_features = int(np.ceil(self._total_features * threshold))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown value of threshold\" + str(threshold))\n",
    "    \n",
    "    def _fit_df(self, df_train):\n",
    "        features = df_train.columns.to_list()\n",
    "        assert len(features) == self._total_features\n",
    "        \n",
    "        feature_imp = pd.DataFrame({\"feature\": features, \"importance\": self._fea_impt})\n",
    "        feature_imp = feature_imp.sort_values(by=[\"importance\"], ascending=False)\n",
    "        \n",
    "        self._sel_cols = feature_imp[\"feature\"][: self._n_sel_features].values\n",
    "        self._sel_cols = list(self._sel_cols)\n",
    "        return self\n",
    "    \n",
    "    def _fit_array(self, df_train):\n",
    "        features = list(range(df_train.shape[-1]))\n",
    "        assert len(features) == self._total_features\n",
    "        \n",
    "        feature_imp = pd.DataFrame({\"feature\": features, \"importance\": self._fea_impt})\n",
    "        feature_imp = feature_imp.sort_values(by=[\"importance\"], ascending=False)\n",
    "        \n",
    "        self._sel_cols = feature_imp[\"feature\"][: self._n_sel_features].values\n",
    "        self._sel_cols = list(self._sel_cols)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        if isinstance(df_train, pd.DataFrame):\n",
    "            self._dtype = \"dataframe\"\n",
    "            self._fit_df(df_train)\n",
    "            \n",
    "        elif isinstance(df_train, np.ndarray):\n",
    "            self._dtype = \"array\"\n",
    "            self._fit_array(df_train)\n",
    "        else:\n",
    "            raise TypeError(\"Unknown df type\")\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if self._dtype == \"dataframe\":\n",
    "            return df.loc[:, self._sel_cols]\n",
    "        \n",
    "        elif self._dtype == \"array\":\n",
    "            return df[:, self._sel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(estimator, X_eval, y_eval):\n",
    "    \"\"\"\n",
    "    :param estimator: sklearn estimator that have predict_proba() method\n",
    "    :param X_eval: test features\n",
    "    :param y_eval: test target\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    proba = estimator.predict_proba(X_eval)\n",
    "    return roc_auc_score(y_eval, proba[:, 1])\n",
    "\n",
    "\n",
    "def feature_importance_df(estimator, features):\n",
    "    \"\"\"\n",
    "    :param estimator: an estimator object that has feature_importances_ attribute\n",
    "    :param features: list of str, list of feature names\n",
    "    :return: feature_imp, dataframe\n",
    "    \"\"\"\n",
    "    feature_imp = pd.DataFrame({\"feature\": features, \"importance\": estimator.feature_importances_})\n",
    "    feature_imp = feature_imp.sort_values(by=[\"importance\"], ascending=False)\n",
    "    return feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_train = load_csv(\"data/data_/X_y_train.csv\")\n",
    "X_test = load_csv(\"data/data_/X_test.csv\")\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_train.isnull().sum().sum:\", X_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_train = X_train[\"APPL_TARGET\"].values\n",
    "X_train = X_train.drop([\"SK_ID_CURR\", \"APPL_TARGET\"], axis=\"columns\")\n",
    "\n",
    "sk_id_test = X_test[[\"SK_ID_CURR\"]]\n",
    "X_test = X_test.drop([\"SK_ID_CURR\"], axis=\"columns\")\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "sk_id_test.to_csv(\"data/data_/sk_id_test.csv\", index=False)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "# make sure that columns in train and test are aligned\n",
    "X_train, X_test = train_test_col_align(X_train, X_test)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "features = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"APPL_TARGET\"] = y_train\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "X_train.to_csv(\"data/data_/X_y_ohe_train.csv\", index=False)\n",
    "X_test.to_csv(\"data/data_/X_ohe_test.csv\", index=False)\n",
    "\n",
    "X_train = X_train.drop([\"APPL_TARGET\"], axis=\"columns\")\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 8006.05 MB\n",
      "Memory usage after changing types 4008.41 MB\n",
      "Memory usage before changing types 1268.66 MB\n",
      "Memory usage after changing types 635.18 MB\n",
      "X_train.shape (307511, 3285)\n",
      "X_test.shape (48744, 3284)\n",
      "X_train.isnull().sum().sum: 0\n",
      "X_test.isnull().sum().sum: 0\n",
      "X_train.shape (307511, 3284)\n",
      "X_test.shape (48744, 3284)\n",
      "Memory usage before changing types 0.39 MB\n",
      "Memory usage after changing types 0.20 MB\n",
      "Elapsed Time 3482.8907935619354\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_train = load_csv(\"data/data_/X_y_ohe_train.csv\")\n",
    "X_test = load_csv(\"data/data_/X_ohe_test.csv\")\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"X_train.isnull().sum().sum:\", X_train.isnull().sum().sum())\n",
    "print(\"X_test.isnull().sum().sum:\", X_test.isnull().sum().sum())\n",
    "\n",
    "y_train = X_train[\"APPL_TARGET\"].values\n",
    "X_train = X_train.drop([\"APPL_TARGET\"], axis=\"columns\")\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "\n",
    "sk_id_test = load_csv(\"data/data_/sk_id_test.csv\")\n",
    "features = list(X_train.columns)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Elapsed Time\", time_elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (307511, 3284)\n",
      "X_test.shape (48744, 3284)\n"
     ]
    }
   ],
   "source": [
    "scaler = Standardizer(to_array=True)\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use feature importance from Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Random Forest model on the train set: 0.81806\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=200, n_jobs=20, random_state=42239)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "auc_rf_train = roc_auc(rf, X_train, y_train)\n",
    "print(\"AUC of Random Forest model on the train set: %0.5f\" % auc_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>APPL_EXT_SOURCE_2</td>\n",
       "      <td>0.051172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>APPL_EXT_SOURCE_3</td>\n",
       "      <td>0.035224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>APPL_EXT_SOURCE_2_4QCUT_Q4</td>\n",
       "      <td>0.016060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>APPL_EXT_SOURCE_1</td>\n",
       "      <td>0.012209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>APPL_CREDIT_TO_GOODS</td>\n",
       "      <td>0.009822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>APPL_DAYS_BIRTH</td>\n",
       "      <td>0.009421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>BURE_DAYS_CREDIT_mean</td>\n",
       "      <td>0.007912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>CCBA_MAX_AMT_BALANCE_TO_CREDIT_LIMIT_3_NEAREST...</td>\n",
       "      <td>0.007574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>BURE_DAYS_ENDDATE_FACT_mean</td>\n",
       "      <td>0.006308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_sum</td>\n",
       "      <td>0.006236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>BURE_DAYS_CREDIT_4QCUT_Q4_mean</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BURE_DAYS_ENDDATE_FACT_median</td>\n",
       "      <td>0.005283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>BURE_DAYS_CREDIT_UPDATE_median</td>\n",
       "      <td>0.005096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>PRAP_NAME_CONTRACT_STATUS_Refused_mean</td>\n",
       "      <td>0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>BURE_DAYS_CREDIT_max</td>\n",
       "      <td>0.004809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BURE_DAYS_ENDDATE_FACT_ISNULL_mean</td>\n",
       "      <td>0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_mean</td>\n",
       "      <td>0.004490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>BURE_DAYS_CREDIT_UPDATE_mean</td>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_iqr</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>PRAP_CODE_REJECT_REASON_XAP_mean</td>\n",
       "      <td>0.004312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature  importance\n",
       "39                                    APPL_EXT_SOURCE_2    0.051172\n",
       "40                                    APPL_EXT_SOURCE_3    0.035224\n",
       "2986                         APPL_EXT_SOURCE_2_4QCUT_Q4    0.016060\n",
       "38                                    APPL_EXT_SOURCE_1    0.012209\n",
       "72                                 APPL_CREDIT_TO_GOODS    0.009822\n",
       "18                                      APPL_DAYS_BIRTH    0.009421\n",
       "122                               BURE_DAYS_CREDIT_mean    0.007912\n",
       "2679  CCBA_MAX_AMT_BALANCE_TO_CREDIT_LIMIT_3_NEAREST...    0.007574\n",
       "133                         BURE_DAYS_ENDDATE_FACT_mean    0.006308\n",
       "176                 BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_sum    0.006236\n",
       "205                      BURE_DAYS_CREDIT_4QCUT_Q4_mean    0.005327\n",
       "134                       BURE_DAYS_ENDDATE_FACT_median    0.005283\n",
       "161                      BURE_DAYS_CREDIT_UPDATE_median    0.005096\n",
       "767              PRAP_NAME_CONTRACT_STATUS_Refused_mean    0.004879\n",
       "124                                BURE_DAYS_CREDIT_max    0.004809\n",
       "74                   BURE_DAYS_ENDDATE_FACT_ISNULL_mean    0.004537\n",
       "177                BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_mean    0.004490\n",
       "160                        BURE_DAYS_CREDIT_UPDATE_mean    0.004377\n",
       "270                 BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_iqr    0.004349\n",
       "785                    PRAP_CODE_REJECT_REASON_XAP_mean    0.004312"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = feature_importance_df(rf, features)\n",
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative feature importance')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance[\"importance_cumsum\"] = feature_importance[\"importance\"].cumsum()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "ax.plot(np.arange(feature_importance.shape[0]) + 1, feature_importance[\"importance_cumsum\"].values, lw=\"2.\")\n",
    "ax.set_xlabel(\"# of features\")\n",
    "ax.set_ylabel(\"Cumulative feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783    0.967816\n",
       "2956    0.967911\n",
       "158     0.968006\n",
       "941     0.968101\n",
       "331     0.968195\n",
       "          ...   \n",
       "1366    0.999491\n",
       "3180    0.999497\n",
       "1148    0.999502\n",
       "2848    0.999508\n",
       "2316    0.999514\n",
       "Name: importance_cumsum, Length: 750, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[\"importance_cumsum\"].iloc[1500:2250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sel_train.shape (307511, 2250)\n",
      "X_sel_test.shape (48744, 2250)\n"
     ]
    }
   ],
   "source": [
    "selector = ImportantFeatureSelector(rf, threshold=2250)\n",
    "selector.fit(X_train)\n",
    "X_sel_train = selector.transform(X_train)\n",
    "X_sel_test = selector.transform(X_test)\n",
    "\n",
    "print(\"X_sel_train.shape\", X_sel_train.shape)\n",
    "print(\"X_sel_test.shape\", X_sel_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sel_train.shape (307511, 2250)\n",
      "X_sel_test.shape (48744, 2250)\n"
     ]
    }
   ],
   "source": [
    "sel_features = [features[i] for i in selector._sel_cols]\n",
    "X_sel_train = pd.DataFrame(X_sel_train, columns=sel_features)\n",
    "X_sel_test = pd.DataFrame(X_sel_test, columns=sel_features)\n",
    "\n",
    "print(\"X_sel_train.shape\", X_sel_train.shape)\n",
    "print(\"X_sel_test.shape\", X_sel_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train[\"APPL_TARGET\"] = y_train\n",
    "\n",
    "X_sel_train.to_csv(\"data/data_/X_y_sel_rf_train.csv\", index=False)\n",
    "X_sel_test.to_csv(\"data/data_/X_sel_rf_test.csv\", index=False)\n",
    "\n",
    "del X_sel_train, X_sel_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use feature importance from XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of XGBoost model on the train set: 0.86647\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=500, learning_rate=0.050, \n",
    "                    max_depth=8, min_child_weight=1, \n",
    "                    colsample_bytree=0.86, subsample=0.67,\n",
    "                    reg_lambda=450,\n",
    "                    n_jobs=20)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "auc_xgb_train = roc_auc(xgb, X_train, y_train)\n",
    "print(\"AUC of XGBoost model on the train set: %0.5f\" % auc_xgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>APPL_CODE_GENDER_M</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>APPL_NAME_INCOME_TYPE_Working</td>\n",
       "      <td>0.006330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>APPL_AMT_GOODS_PRICE_4QCUT_Q2</td>\n",
       "      <td>0.005653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>APPL_EXT_SOURCE_3</td>\n",
       "      <td>0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>APPL_EXT_SOURCE_2</td>\n",
       "      <td>0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>APPL_FLAG_OWN_CAR_Y</td>\n",
       "      <td>0.005084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>PRAP_NAME_CONTRACT_STATUS_mode_Refused</td>\n",
       "      <td>0.004590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>APPL_NAME_EDUCATION_TYPE_Secondary / secondary...</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>APPL_NAME_EDUCATION_TYPE_Higher education</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_max</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>POBA_MIN_SK_DPD_DEF_3_NEAREST_mm_diff</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>CCBA_MAX_AMT_BALANCE_TO_CREDIT_LIMIT_3_NEAREST...</td>\n",
       "      <td>0.003401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPL_OWN_CAR_AGE_ISNULL</td>\n",
       "      <td>0.003163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>POBA_MEAN_SK_DPD_DEF_6_NEAREST_min</td>\n",
       "      <td>0.002995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>APPL_EXT_SOURCE_1</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>PRAP_CODE_REJECT_REASON_SCOFR_sum</td>\n",
       "      <td>0.002807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>APPL_FLAG_DOCUMENT_3</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPL_EXT_SOURCE_3_ISNULL</td>\n",
       "      <td>0.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>APPL_CREDIT_TO_GOODS</td>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>PRAP_NAME_CONTRACT_STATUS_Refused_mean</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature  importance\n",
       "2825                                 APPL_CODE_GENDER_M    0.006439\n",
       "2842                      APPL_NAME_INCOME_TYPE_Working    0.006330\n",
       "2964                      APPL_AMT_GOODS_PRICE_4QCUT_Q2    0.005653\n",
       "40                                    APPL_EXT_SOURCE_3    0.005410\n",
       "39                                    APPL_EXT_SOURCE_2    0.005214\n",
       "2827                                APPL_FLAG_OWN_CAR_Y    0.005084\n",
       "3127             PRAP_NAME_CONTRACT_STATUS_mode_Refused    0.004590\n",
       "2846  APPL_NAME_EDUCATION_TYPE_Secondary / secondary...    0.004485\n",
       "2843          APPL_NAME_EDUCATION_TYPE_Higher education    0.004383\n",
       "180                 BURE_AMT_CREDIT_SUM_DEBT_TO_SUM_max    0.003858\n",
       "1471              POBA_MIN_SK_DPD_DEF_3_NEAREST_mm_diff    0.003465\n",
       "2679  CCBA_MAX_AMT_BALANCE_TO_CREDIT_LIMIT_3_NEAREST...    0.003401\n",
       "0                               APPL_OWN_CAR_AGE_ISNULL    0.003163\n",
       "1305                 POBA_MEAN_SK_DPD_DEF_6_NEAREST_min    0.002995\n",
       "38                                    APPL_EXT_SOURCE_1    0.002857\n",
       "793                   PRAP_CODE_REJECT_REASON_SCOFR_sum    0.002807\n",
       "47                                 APPL_FLAG_DOCUMENT_3    0.002700\n",
       "2                              APPL_EXT_SOURCE_3_ISNULL    0.002675\n",
       "72                                 APPL_CREDIT_TO_GOODS    0.002631\n",
       "767              PRAP_NAME_CONTRACT_STATUS_Refused_mean    0.002548"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = feature_importance_df(xgb, features)\n",
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative feature importance')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFzCAYAAAAuSjCuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2hklEQVR4nO3dd3xddf3H8dcnq2m60t3SvUspnSmr7FmWZQ9BBBRQREUExQUIKiKIoiJTNspSsUhZUrZQuvfe6UqbtknTNPvz++Oe1tBfmt60uTl3vJ+PRx6993tO7v2c3Dbvnu/5nu/X3B0RERFJPGlhFyAiIiL7RyEuIiKSoBTiIiIiCUohLiIikqAU4iIiIglKIS4iIpKgMsIuoKE6dOjgvXv3DrsMERGRJjFt2rTN7t6xrm0JF+K9e/dm6tSpYZchIiLSJMxs1d62qTtdREQkQSnERUREEpRCXEREJEEpxEVERBKUQlxERCRBKcRFREQSlEJcREQkQSnERUREEpRCXEREJEHFLMTN7AkzKzCzuXvZbmb2BzNbamazzWxUrGoRERFJRrE8E38KGFfP9tOBAcHXtcBDMaxFREQk6cRs7nR3/9DMetezy3jgGXd34DMzyzWzru6+PlY1iYgkCnenuKyK9UU72VBURtHOSorLqijeWcnOimpq3HHAHSKPJJ5cPbYPnVtnx/x9wlwApRuwptbz/KDt/4W4mV1L5Gydnj17NklxIiJNYWdFNUsLSlhSsJ0lBSUsLShh5eYdrC8qo6S8KuzyZD+NH94t6UM8au7+KPAoQF5env7LKSIJqabGWVG4gxmrtzFj9VZmrN7Goo3bqa6p+9daTlY6B+U2p2ubbNo0z6R180xaZWeQk5lBehqYGQBmYFhTHorsQ6fWzZrkfcIM8bVAj1rPuwdtIiJJwd1ZWVjKJ0s38+myQj5dXsiWHRVf2Cc9zRjQqSUDO7eif6eWDOjckj4dWtA9N4fWzTN2B7VIXcIM8QnADWb2AnA4UKTr4SKS6LaXVfLRks28t7CA/y4rZO22nV/Y3qlVM0b1bMvInrmM7NmWQ7u1oXlWekjVSqKLWYib2d+A44EOZpYP3A5kArj7w8BE4AxgKVAKXBWrWkREYmnNllLeXbCRdxcW8NnyQiqr/9c93jYnkyP7teeofh0Y278Dvdvn6OxaGk0sR6dfuo/tDnwrVu8vIhJLa7aUMmHWOv49ez0L1hfvbk8zyOvVlpMO7swxAzowpGtr0tIU2hIbCTGwTUQkHmwoKuP1Oet5bdY6Zq7Ztru9ZbMMjh3YgZMGd+aEwZ1o1yIrvCIlpSjERUTqUVJexeuz1/GP6Wv5fOUWPOgpz8lK59QhnTl7+EEcPaADzTJ0XVuankJcRGQP7s7kFVt4eWo+E+esZ2dlNQBZGWmcOKgTZw8/iBMHd9KANAmdQlxEJLBu207+Pi2fV6bns6qwdHf74X3accHo7owb2oVW2ZkhVijyRQpxEUlpNTXOR0s38+ynq5i0cCO75l3p2iabC0Z354LR3enVvkW4RYrshUJcRFLSttIKXp6az3OTV+0+685KT+OUQzpzcV4PxvbvQLpGlUucU4iLSEqZnb+NZz9dxYRZ6yivqgGgW25zvnx4Ty4e04MOLZtmukyRxqAQF5GkV1ZZzWuz1vHcZ6uYlV+0u/3YgR254ohenDC4k866JSEpxEUkaW0uKee5z1bx3Ger2FwSmbO8TfNMLsrrzmWH96J3B13rlsSmEBeRpLNow3b+8vFyXp25joqgy/zgrq256qjenD38IN0aJklDIS4iSaGmxvlgySae+HgFHy3ZDESW6Dz54E587ei+HNG3neYsl6SjEBeRhFZeVc0/pq/l8Y+Ws2zTDgCaZ6ZzYV53rhrbhz7qMpckphAXkYS0vaySv05ezV8+XkHB9nIAurTO5sqxvbl0TE/a5GhSFkl+CnERSSibS8p58pMVPPPpKraXVQGR693fOK4vZxzalcz0tJArFGk6CnERSQhrtpTy2EfLeXHKmt33dx/Wpx3XH9+P4wZ21PVuSUkKcRGJa4s3bufP7y3ltdnrqQ7mRD354M588/i+jO7VLuTqRMKlEBeRuLRwQzF/eHcJE+dsACA9zThvZDeuO64fg7q0Crk6kfigEBeRuDJ/XSS835wXCe+sjDQuGdODa47pS492OSFXJxJfFOIiEhfmri3iD+8u4e35G4FIeH/5sJ5847h+dGmTHXJ1IvFJIS4ioZqTX8QD7y7hPwsi4d0sI43LDu/FN47rS6fWCm+R+ijERSQU89cVc/87i/jPggIAsjPTuPzwXlx7XF86tVJ4i0RDIS4iTWrF5h3c/85iXpu1DojMrvaVI3txzTF96dhKy4CKNIRCXESaxPqinfzh3SW8NDWf6honKz2Ny4/oxfUn9NMa3iL7SSEuIjFVWFLOQ+8v45nPVlFRVUOawcV5PfjOyQPolts87PJEEppCXERiYntZJY9/tILHP1rOjopqAM4c1pWbThlIv44tQ65OJDkoxEWkUZVVVvPMpyt56P1lbC2tBOD4QR25+dRBDO3WJuTqRJKLQlxEGkV1jfOP6fn89u3FbCguA2BM77bcctpgDuuj6VFFYkEhLiIH7KMlm/jVxIUsWF8MwJCurbll3CCO18IkIjGlEBeR/bZgfTF3v7GQDxdvAuCgNtncfNogzhnRjbQ0hbdIrCnERaTBNhSV8du3F/HK9HzcoVWzDK4/oT9Xje1NdmZ62OWJpAyFuIhEraS8ikc+WMZjHy2nrLKGjDTj8iN78Z2TBtCuRVbY5YmkHIW4iOxTdY3z4pQ13P/OIjaXVABw+tAu/GDcYPp0aBFydSKpSyEuIvX677LN3PnafBZu2A7AqJ65/OTMgxndSyPORcKmEBeROq0uLOVXExfsXte7W25zfnTGYM48tKtGnIvECYW4iHxBSXkVD763lL98tIKK6hqaZ6Zz/fH9uObYvhq0JhJnFOIiAkBNjfPK9HzufWsRm7aXA3DeyG78YNxgurTR0qAi8UghLiJMWbmFO1+bz5y1RQCM7JnLbWcNYWTPtiFXJiL1UYiLpLB123byq4kL+Pfs9QB0aZ3NracP5kvDD9JkLSIJQCEukoLKq6p5/KMV/GnSUnZWVtMsI43rjuvHN47rS06Wfi2IJAr9axVJMR8s3sTPJ8xj+eYdAJxxaBd+fMbBdG+bE3JlItJQCnGRFJG/tZS7/j2ft+ZtBKBvxxb8/EuHcMyAjiFXJiL7SyEukuTKKqt57MPlPPj+Usoqa8jJSuc7Jw3g6rF9yMpIC7s8ETkACnGRJPbewgLueG0eqwpLAThrWFd+cubBdG3TPOTKRKQxKMRFktCaLaX8/LX5/GdBpOt8QKeW/Hz8IRzVr0PIlYlIY1KIiySRyuoanvxkBb97Zwk7K6tpkZXOjScP5MqxvclMV9e5SLJRiIskiRmrt/Ljf85lwfpiINJ1/rOzhtC5tWZbE0lWCnGRBFdcVsl9by3i2c9W4Q7d2zbnrnOGcsKgTmGXJiIxphAXSVDuzhtzN3DHhHkUbC8nPc245ti+fPekATTP0kIlIqlAIS6SgPK3lnLbv+YxaWEBEJnr/FfnHsrBXVuHXJmINCWFuEgCqaqu4clPVnL/O4vZWVlNq+wMfjhuMF8+rKfmOhdJQQpxkQQxd20RP3hlNvODgWtnDuvK7WcNoZMGromkrJiGuJmNAx4A0oHH3f3Xe2zvCTwN5Ab73OruE2NZk0iiKaus5oF3l/Doh8uprvHIwLXxQzlhsAauiaS6mIW4maUDDwKnAPnAFDOb4O7za+32U+Ald3/IzIYAE4HesapJJNFMXbmFH/x9Nss37cAMrh7bh5tPG6iVxkQEiO2Z+GHAUndfDmBmLwDjgdoh7sCukThtgHUxrEckYewor+Letxbx9KcrcYf+nVpyz/nDGN2rbdiliUgciWWIdwPW1HqeDxy+xz53AG+b2beBFsDJdb2QmV0LXAvQs2fPRi9UJJ58tGQTt/59Dmu37SQ9zfjm8f244cT+ZGfqtjER+aKw++QuBZ5y99+a2ZHAs2Y21N1rau/k7o8CjwLk5eV5CHWKxFxRaSW/eH0+L0/LB+CQg1rzmwuGcchBbUKuTETiVSxDfC3Qo9bz7kFbbV8DxgG4+6dmlg10AApiWJdI3Hlr3gZ+9upcCraXk5WRxo0nD+CaY/pqvnMRqVcsQ3wKMMDM+hAJ70uAL++xz2rgJOApMzsYyAY2xbAmkbhSWFLObRPm8frs9QDk9WrLr88fRv9OLUOuTEQSQcxC3N2rzOwG4C0it4894e7zzOxOYKq7TwC+DzxmZt8jMsjtSndXd7mkhDfnrucn/5xL4Y4KcrLS+cFpg7jiyN6atEVEohbTa+LBPd8T92i7rdbj+cDYWNYgEm+2lVZw+4R5/Gtm5GaMo/q1557zh9GjXU7IlYlIogl7YJtISpm0cCO3/n0OBdvLaZ6Zzo/OGMzlh/fS2beI7BeFuEgTKC6r5K7X/jfyfEzvttx7wXB6d2gRcmUiksgU4iIx9tGSTfzwldmsKyojKyONH5w2iKvG9iFdZ98icoAU4iIxsqO8irvfWMBzn60GYHj3Nvz2ouH079Qq5MpEJFkoxEViYPLyQm55ZTart5SSmW7cePJArju2Lxm671tEGpFCXKQRlVdV89u3F/PYR8txhyFdW/Pbi4ZzcNfW+/5mEZEG2meIm1kOkfu5e7r7NWY2ABjk7v+OeXUiCWTxxu1894WZLFhfTHqa8a0T+nHDiQPIytDZt4jERjRn4k8C04Ajg+drgZcBhbgI4O48/d+V3P3GQsqraujVPoffXTyCUT214piIxFY0Id7P3S82s0sB3L3UzDSsVgQoKC7j5ldm8+HiyGzBF+f14GdnD6FlM12pEpHYi+Y3TYWZNScyLSpm1g8oj2lVIgngrXkbuPXvs9laWkluTia/Pu9Qxg3tGnZZIpJCognx24E3gR5m9jyRaVKvjGVRIvFsR3kVd/17Pi9MWQPAMQM6cN+Fw+ncOjvkykQk1ewzxN39HTObDhwBGPBdd98c88pE4tDMNdu48YUZrCwsJSsjjVvHDebKo7RoiYiEI5rR6ecCk9z99eB5rpmd4+6vxro4kXhRXeM8/MEy7n9nMdU1zuAurfj9JSMY3EW3jolIeKLqTnf3f+564u7bzOx24NWYVSUSRwqKy/jeSzP5ZGkhAF87ug+3nDaI7Mz0kCsTkVQXTYjXdZOrht5KSnh/UQHff2kWhTsqaN8ii/suGs4JgzqFXZaICBBdGE81s/uBB4Pn3yJy37hI0qqoquG+txfx6IfLARjbvz2/u2gEnTR4TUTiSDQh/m3gZ8CLwfN3iAS5SFJaXVjKt/82nVn5RaSnGTedMpBvHNdPq46JSNyJZnT6DuDWJqhFJHQTZq3jx/+YQ0l5Fd1ym/OHS0cwule7sMsSEalTNKPTBwI3A71r7+/uJ8auLJGmVVpRxR0T5vHS1HwAxh3ShXvOH0abnMyQKxMR2btoutNfBh4GHgeqY1uOSNNbtGE71z8/jWWbdpCVkcbPzhrC5Yf3RLMLi0i8iybEq9z9oZhXIhKCl6eu4Wf/mktZZQ39O7Xkj5eO1LKhIpIwognx18zseuCf1Joz3d23xKwqkRjbWVHN7RPm7u4+P39Ud+465xBysnT3pIgkjmh+Y301+POWWm0O9G38ckRib/mmEq5/fjoLN2ynWUYad40fykVjeoRdlohIg0UzOr1PUxQi0hT+PXsdP3xlNjsqqunToQV/vmyUus9FJGFF1XdoZkOBIcDumS7c/ZlYFSXS2MqrqvnV6wt4+tNVAJx5aFd+ff6htMrW6HMRSVzR3GJ2O3A8kRCfCJwOfAwoxCUhrNlSyg1/jUzekplu/PTMIVxxZC+NPheRhBfNmfgFwHBghrtfZWadgediW5ZI45i0cCM3vjCT4rLI5C1/vmwUw3vkhl2WiEijiCbEd7p7jZlVmVlroADQKCCJazU1zgPvLuGBd5cAcPLBnbjvwuHk5mSFXJmISOOJdgGUXOAxIguflACfxrIokQNRVFrJjS/O4L1Fm0gz+P6pg/jmcf1I09znIpJkohmdfn3w8GEzexNo7e6zY1uWyP6Zv66Ybzw3jdVbSsnNyeSPl47kmAEdwy5LRCQmohnY9q67nwTg7iv3bBOJF6/OWMut/5hNWWUNQ7u15qHLRtOjXU7YZYmIxMxeQ9zMsoEcoIOZtQV29UW2Bro1QW0iUamsruGXry/gqf+uBOCC0d35xTlDyc5MD7cwEZEYq+9M/DrgRuAgItfCd4V4MfCn2JYlEp2C4jK+9dfpTFm5lcx04/azD+EyLV4iIiliryHu7g+Y2Z+AH7v7XU1Yk0hUpq3awjefm07B9nI6t27GQ5ePZlTPtmGXJSLSZNLq2+ju1cB5TVSLSNSe/WwVFz/yGQXbyzmsTzv+/e1jFOAiknKiucXsXTM7H/iHu3usCxKpT0VVDT9/bR7PT14NwNeO7sOtpw8mM73e/4+KiCSlaEL8OuAmoNrMdhK5Nu7urlUjpEkVlpRz/fPTmbxiC1kZadxz/qGcO7J72GWJiIQmmvvEWzVFISL1WbC+mGuemUr+1p10atWMR6/IY4SmTxWRFBftKmZfAo4Nnr7v7v+OXUkiX/Tm3A3c9NJMSiuqGd69DY98JY8ubbL3/Y0iIkkumslefg2MAZ4Pmr5rZmPd/UcxrUxSnrvzx0lLuf+dxQCcM+Igfn3+MN3/LSISiOZM/AxghLvXAJjZ08AMQCEuMbOzopqbX57F63PWYwY/HDeY647tq/u/RURqiao7HcgFtgSP28SmFJGIgu1lXPP0VGblF9GyWQZ/uHQEJw7uHHZZIiJxJ5oQvxuYYWbvERmZfixwa0yrkpS1eON2rnpyCmu37aR72+Y8eeUYBnTW2EoRkbpEMzr9b2b2PpHr4g780N03xLowST0fLdnE9c9NZ3t5FSN65PLYFXl0bNUs7LJEROJWtN3pRwJHEwnxDOCfMatIUtLfPl/NT1+dS3WNc8ahXbj/ohEawCYisg/RjE7/M9Af+FvQdJ2Znezu34ppZZISamqce95ayCMfLAfgm8f345ZTB5GWpgFsIiL7Es2Z+InAwbumXA1Gp8+LaVWSEnZWVHPTSzN5Y+4GMtKMX5wzlEsO6xl2WSIiCSOaEF8K9ARWBc97BG0i+62wpJyrn57KrDXbaNUsg4cuH83RAzqEXZaISEKJJsRbAQvM7PPg+RhgqplNAHD3L8WqOElOqwtLueKJyawsLKVbbnOevGoMAzUCXUSkwaIJ8dtiXoWkjLlri7jyySlsLilnSNfWPHX1GDq10hSqIiL7I5pbzD4AMLPWtfd39y17/aaAmY0DHgDSgcfd/dd17HMRcAeRke+z3P3L0RYvieWjJZv4xrPT2FFRzdj+7Xn48tG0ys4MuywRkYQVzej0a4E7gTKghmApUqDvPr4vHXgQOAXIB6aY2QR3n19rnwFEpm8d6+5bzazT/h6IxLdXZ6zl5pdnUVXjjB9xEPdeMJysDK0BLiJyIKLpTr8FGOrumxv42ocBS919OYCZvQCMB+bX2uca4EF33wrg7gUNfA9JAI99uJxfTlwAwDXH9OFHpx+sW8hERBpBNCG+DCjdj9fuBqyp9TwfOHyPfQYCmNknRLrc73D3N/fjvSQO1dQ4v5y4gL98vAKAn555MF8/pt4OHBERaYBoQvxHwH/NbDJQvqvR3b/TSO8/ADge6A58aGaHuvu22jsFXfrXAvTsqfuIE0FldQ23vDyLV2euIzPduO/C4Ywf0S3sskREkko0If4IMAmYQ+SaeLTWErmnfJfuQVtt+cBkd68EVpjZYiKhPqX2Tu7+KPAoQF5enjegBglBWWU1N/x1Ov9ZUECLrHQevSKPsf11D7iISGOLJsQz3f2m/XjtKcAAM+tDJLwvAfYcef4qcCnwpJl1INK9vnw/3kvixPaySr7+9FQmr9hCbk4mT111GCN65IZdlohIUoomxN8IurNf44vd6fXeYubuVWZ2A/AWkevdT7j7PDO7E5jq7hOCbaea2XygGrjF3Qv381gkZFt2VPDVJz5nztoiOrduxrNfO1yTuIiIxJAFU6LvfQezFXU0u7uHMkIpLy/Pp06dGsZbSz3WF+3k8scns2zTDnq2y+H5rx9Oj3Y5YZclIpLwzGyau+fVtS2ayV76NH5JkkxWbN7B5Y9PZu22nQzq3Ipnv3YYnVprFjYRkVjba4ib2YnuPsnMzqtru7v/I3ZlSaJYuKGYyx//nM0l5YzsmcuTV44hNycr7LJERFJCfWfixxEZlX52HdscUIinuHnrirj88clsLa3k6P4deOQro2nRLJphFiIi0hj2+hvX3W8P/ryq6cqRRDEnv4jL/zKZop2VnDCoIw9dPprszPSwyxIRSSk6bZIGm7F6K1c88Tnby6o4ZUhn/vTlkTTLUICLiDQ1hbg0yLRVW/jqE1MoKa/i9KFdeOCSkVrIREQkJApxidrk5YVc/dQUdlRUc9awrvzu4hFkpivARUTCss/fwGaWY2Y/M7PHgucDzOys2Jcm8eS/yzZz5ZORAD93ZDd+rwAXEQldNL+FnyQyU9uRwfO1wC9iVpHEnV1n4Dsrq7lgdHfuu3A4GQpwEZHQRfObuJ+7/waoBHD3UkCLQaeIaau2cvVTUyirrOHC0d35zfnDSNda4CIicSGaEK8ws+ZE7g3HzPpRaw51SV6z87dx5ROfs6OimnNGHMSvzx9GmgJcRCRuRDOw7XbgTaCHmT0PjAWujGVREr7564r5yl8+Z3t5FWcc2oX7LhyuM3ARkThTb4ibWRrQFjgPOIJIN/p33X1zE9QmIVmycfvuiVxOPrgzD1wyUtfARUTiUL0h7u41ZvYDd38JeL2JapIQLd9Uwpcfn8yWHRUcN7AjD142UqPQRUTiVDS/nf9jZjebWQ8za7frK+aVSZNbu20nlz0+mU3byzmyb3se+cpozcQmIhLHorkmfnHw57dqtTkQynriEhuFJeV85fHJrC8qI69XW/5yZZ7mQhcRiXNaT1woKa/iyiensHzzDgZ3acVfrhxDTpYm8xMRiXf7/E1tZlfU1e7uzzR+OdLUyiqrufaZqcxZW0TPdjk8c/VhtGmeGXZZIiIShWhOt8bUepwNnARMBxTiCa66xrnxhZn8d1khHVs147mvHU6n1tlhlyUiIlGKpjv927Wfm1ku8EKsCpKm4e785J9zeHPeBlplZ/DM1YfRs31O2GWJiEgD7M+9QzsAXSdPcPe9vYgXpqyhWUYaT1w5hoO7tg67JBERaaBorom/RjDlKpHQHwK8HMuiJLaen7yKB99bRnqa8efLRjGmt+4YFBFJRNFcE7+v1uMqYJW758eoHomxdxds5GevzgXgV+cO5aSDO4dckYiI7K9outPPcPcPgq9P3D3fzO6JeWXS6Gbnb+OGv86gxuE7J/bn4jE9wy5JREQOQDQhfkodbac3diESW2u2lO5eE/z8Ud353ikDwy5JREQO0F67083sm8D1QF8zm11rUyvgk1gXJo1n644Kvvrk52wuqeDo/h24+7xDMdOKZCIiia6+a+J/Bd4A7gZurdW+3d23xLQqaTRlldVc++xUlm+KzMb20OWjyMrQgiYiIslgryHu7kVAEXApgJl1IjLZS0sza+nuq5umRNlf7s4P/z6bKSu30rVNNk9ddRitsjUbm4hIstjnKZmZnW1mS4AVwAfASiJn6BLnHnxvKf+auY4WWek8ceUYurTRbGwiIskkmn7VXwBHAIuDxVBOAj6LaVVywN6Ys5773l6MGTxwyUhN5iIikoSiCfFKdy8E0swszd3fA/JiXJccgLlri7jppVkA3DpuMCcP0b3gIiLJKJrJXraZWUvgI+B5MysgMvWqxKGC4jK+/vRUdlZWc8Ho7lx7rJZ9FxFJVtGciY8HSoEbgTeBZcDZMaxJ9lNZZTXXPDuNDcVljOndll+eO1S3komIJLFoVjHbYWa9gAHu/rSZ5QDpsS9NGur2f81j1pptdMttzsOXj6ZZhj4mEZFkFs3o9GuAV4BHgqZuwKsxrEn2w98+X82LUyOrkj3yldG0b9ks7JJERCTGoulO/xYwFigGcPclQKdYFiUNM3PNNm7/1zwA7j7vUIZ2axNyRSIi0hSiCfFyd6/Y9cTMMvjf0qQSss0l5XzzuWlUVNdwxZG9OG9U97BLEhGRJhJNiH9gZj8GmpvZKUTWEn8ttmVJNKqqa/j2X2ewvqiM0b3a8tMzh4RdkoiINKFoQvxWYBMwB7gOmAj8NJZFSXTufWsRny4vpEPLZvz5Ms2JLiKSaupbxexddz8JuNvdfwg81nRlyb68M38jj3y4nIw048+XjaJza02pKiKSauq7xayrmR0FfMnMXgC+cMOxu0+PaWWyV2u37eTmlyMzsv1g3CAO69Mu5IpERCQM9YX4bcDPgO7A/Xtsc+DEWBUle1dZXcN3/jaDop2VnDi4E18/WjOyiYikqvqWIn0FeMXMfubudzVhTVKP+99ZzLRVW+nSOpv7LhxOWppmZBMRSVX7HAmlAI8fHyzexEPvLyPN4A+XjqRdi6ywSxIRkRBpOHOC2Fhcxk0vzgTgplMG6jq4iIgoxBNBTY3z/ZdmUbijgmMGdOD64/uHXZKIiMSBqELczI42s6uCxx3NrE9sy5Lanvl0JR8v3Uy7Fln89iJdBxcRkYhoFkC5Hfgh8KOgKRN4LpZFyf8sLdjO3W8sBOBX5x5Kp1a6H1xERCKiORM/F/gSsAPA3dcBrWJZlERUVtfwvRdnUV5VwwWjuzNuaJewSxIRkTgSTYhXuLsTLHpiZi1iW5Ls8sd3lzBnbRHdcptz+9maF11ERL4omhB/ycweAXKDtcX/g6Zgjbnpq7fyp/eWYgb3XzScVtmZYZckIiJxJpr7xO8DXgH+DgwCbnP3P0bz4mY2zswWmdlSM7u1nv3ONzM3s7xoC09m5VXV/OCV2dQ4XHtMXw7v2z7skkREJA7VN+0qAGZ2E/Ciu7/TkBc2s3TgQeAUIB+YYmYT3H3+Hvu1Ar4LTG7I6yezByctZWlBCX07tuB7pwwMuxwREYlT0XSntwLeNrOPzOwGM+sc5WsfBix19+XuXgG8AIyvY7+7gHuAsihfN6ktWF/Mn99fBsA95w8jOzM95IpERCReRdOd/nN3PwT4FtAV+MDM/hPFa3cD1tR6nh+07WZmo4Ae7v569CUnr6rqGn7499lU1ThXHNmLMb01K5uIiOxdQ2ZsKwA2AIVApwN9YzNLI7I62vej2PdaM5tqZlM3bdp0oG8dt574ZAWz84s4qE02Pxg3OOxyREQkzkUz2cv1ZvY+8C7QHrjG3YdF8dprgR61nncP2nZpBQwF3jezlcARwIS6Bre5+6PunufueR07dozirRPP6sJS7n9nMQC/PO9QWjbb53AFERFJcdEkRQ/gRnef2cDXngIMCKZoXQtcAnx510Z3LwI67Hoe/EfhZnef2sD3SXjuzu0T5lJWWcM5Iw7ihEEH3NEhIiIpYK8hbmat3b0YuDd4/oULtO6+pb4XdvcqM7sBeAtIB55w93lmdicw1d0nHHD1SeI/Cwp4b9EmWjXL4CdnalIXERGJTn1n4n8FzgKmEZmtrfaqGw703deLu/tEYOIebbftZd/j9/V6yWhnRTV3TJgHwPdPHUjHVs1CrkhERBLFXkPc3c8K/tSKZTH00PtLWbttJwd3bc3lR/QKuxwREUkg0QxsezeaNmm4NVtKefiD5QDcNf4QMtK1vLuIiESvvmvi2UAO0MHM2vK/7vTW7HG/t+yfe99aREV1DeeO7Eae7gkXEZEGqu+a+HXAjcBBRK6L7wrxYuBPsS0r+c3O38aEWevIykjj+6dqalUREWm4+q6JPwA8YGbfjnbBE4mOu/OriQsAuOqo3nRvmxNyRSIikoj2eZ+4u//RzIYCQ4DsWu3PxLKwZPbeogI+W76FNs0zuf74/mGXIyIiCSqaVcxuB44nEuITgdOBjwGF+H6oqq7h7okLAfj2if1pk6N1wkVEZP9EMxz6AuAkYIO7XwUMB9rEtKok9sq0fJYUlNC9bXO+cqRuKRMRkf0XTYjvdPcaoMrMWhNZCKXHPr5H6rCzonr3/Oi3nDaIZhlaZlRERPZfNHOnTzWzXOAxIqPUS4BPY1lUsnr2s5UUbC9naLfWnD3soLDLERGRBBfNwLbrg4cPm9mbQGt3nx3bspJPSXnV7oldvn/KINLSbB/fISIiUr/6JnsZVd82d58em5KS09P/XcmWHRWM6pnL8YOSczlVERFpWvWdif+2nm0OnNjItSSt4rJKHv0wOAs/dRBmOgsXEZEDV99kLyc0ZSHJ7ImPV1C0s5LD+7TjqH7twy5HRESSRDT3iV9RV7sme4lOSXkVT36yEoCbThmos3AREWk00YxOH1PrcTaRe8ano8leovK3yasp2llJXq+2HN5XZ+EiItJ4ohmd/u3az4PbzV6IVUHJpLyqmsc/jlwLv/6EfiFXIyIiyWZ/FrDeAfRp7EKS0asz1rKxuJxBnVtxwqBOYZcjIiJJJppr4q8RGY0OkdAfArwUy6KSQXWN774v/JvH99O1cBERaXTRXBO/r9bjKmCVu+fHqJ6k8da8DazYvIPubZtz1rCuYZcjIiJJKJpr4h8ABPOmZwSP27n7lhjXlrDcnYc/WAbAdcf2JSN9f65aiIiI1C+a7vRrgTuBMqAGMCLd631jW1rimrpqK7Pzi2jXIosL87RWjIiIxEY03em3AEPdfXOsi0kWT36yAoAvH9aT7EytVCYiIrERTT/vMqA01oUki/ytpbw5dwMZaab1wkVEJKaiORP/EfBfM5sMlO9qdPfvxKyqBPbsp6uocTh7eFc6t84OuxwREUli0YT4I8AkYA6Ra+KyFzsrqvnb56sBuGqsbqUXEZHYiibEM939pphXkgQmzllPcVkVw3vkMqJHbtjliIhIkovmmvgbZnatmXU1s3a7vmJeWQJ6ccoaAC4doxHpIiISe9GciV8a/PmjWm26xWwPyzeV8PnKLeRkpXPW8IPCLkdERFJANJO96OJuFF6cGjkLP2tYV1o2i+b/RiIiIgdG64k3gsrqGv4+LTIT7cVjeoZcjYiIpAqtJ94IJi0sYHNJBf07tWRUz9ywyxERkRSh9cQbwa4BbRfn9dBqZSIi0mS0nvgB2lBUxvuLCshMN84d1S3sckREJIVoPfED9OrMtdQ4nDq4Mx1aNgu7HBERSSFaT/wAvTpjLQDnj+4eciUiIpJq9hriZtYf6LxrPfFa7WPNrJm7L4t5dXFuwfpiFm7YTm5OJscN7Bh2OSIikmLquyb+e6C4jvbiYFvK23UWftawrmRl7M/wAhERkf1XX/J0dvc5ezYGbb1jVlGCqK5x/jVzHQDnjtSANhERaXr1hXhuPduaN3IdCWfy8kI2FJfRo11zRvVsG3Y5IiKSguoL8almds2ejWb2dWBa7EpKDP8MutLPHdFN94aLiEgo6hudfiPwTzO7jP+Fdh6QBZwb47riWlllNW/M3QDAeHWli4hISPYa4u6+ETjKzE4AhgbNr7v7pCapLI5NWlhASXkVw7q3oV/HlmGXIyIiKSqaaVffA95rgloSxq6z8LOGdQ25EhERSWW6L6qByiqrmbRgIwCnD1WIi4hIeBTiDfTRks3sqKjmkINa06NdTtjliIhIClOIN9Abc9cDcPrQLiFXIiIiqU4h3gAVVTX8Z36kK32cutJFRCRkCvEG+HR5IcVlVQzo1JL+nTQqXUREwqUQb4A31ZUuIiJxRCEepZoa5x11pYuISByJaYib2TgzW2RmS83s1jq232Rm881stpm9a2a9YlnPgZi9tojNJRV0y23OwV1bhV2OiIhI7ELczNKBB4HTgSHApWY2ZI/dZgB57j4MeAX4TazqOVCTFhYAcMLgjporXURE4kIsz8QPA5a6+3J3rwBeAMbX3sHd33P30uDpZ0D3GNZzQN4LQvzEwZ1CrkRERCQiliHeDVhT63l+0LY3XwPeqGuDmV1rZlPNbOqmTZsascToFBSXMWdtEc0y0jiyb4cmf38REZG6xMXANjO7nMgKaffWtd3dH3X3PHfP69ixY9MWB7y/KPIfh6P6tad5VnqTv7+IiEhd9rkAygFYC/So9bx70PYFZnYy8BPgOHcvj2E9+22SutJFRCQOxfJMfAowwMz6mFkWcAkwofYOZjYSeAT4krsXxLCW/VZRVcPHSzcDcIJCXERE4kjMQtzdq4AbgLeABcBL7j7PzO40sy8Fu90LtAReNrOZZjZhLy8Xmikrt1BSXsXAzi3p3lYLnoiISPyIZXc67j4RmLhH2221Hp8cy/dvDB8uiVwPP36QzsJFRCS+xMXAtnj2SdCVfnR/jUoXEZH4ohCvx5YdFcxbV0xWehpjercLuxwREZEvUIjX49NlhbhDXu+2urVMRETijkK8HrtGpY9VV7qIiMQhhXg9Pl4aGdSm6+EiIhKPFOJ7sbqwlDVbdtKmeSZDu7UJuxwREZH/RyG+F7u60o/q1570NK1aJiIi8Uchvhef6Hq4iIjEOYV4HdydySsKgciZuIiISDxSiNdh2aYdbC6poGOrZvTp0CLsckREROqkEK/DrrPww/q0w0zXw0VEJD4pxOswefkWAI7oo1naREQkfinE91D7evjhfXU9XERE4pdCfA+rt5Sysbicdi2yGNCpZdjliIiI7JVCfA+TV0S60sf0bqvr4SIiEtcU4nuYsXobAHm9dD1cRETim0J8D7PWbANgeI/cUOsQERHZF4V4LWWV1SzauJ00g6HdWoddjoiISL0U4rXMW1dEdY0zsHMrcrIywi5HRESkXgrxWmauKQJgePfccAsRERGJgkK8ltn52wBdDxcRkcSgEK9lztrImfiw7lo/XERE4p9CPFBWWc3KzTtITzP6a5IXERFJAArxwNKCEmocerfPITszPexyRERE9kkhHli0YTsAg7vo1jIREUkMCvHAoo2REB/YuVXIlYiIiERHIR5YGJyJD+qiEBcRkcSgEA8s3t2drhAXEZHEoBAHikor2VBcRnZmGj3a5YRdjoiISFQU4sDCDcVA5Hp4epqWHxURkcSgEAcWF5QAGtQmIiKJRSEOrNi0A4B+HTXJi4iIJA6FOLBic+RMvE8HXQ8XEZHEoRAHVhaWAtCng87ERUQkcaR8iFdV17BmSyTEe7XXmbiIiCSOlA/x/K07qapxDmqTrTnTRUQkoaR8iK8sjAxq692hRciViIiINEzKh/iGojIAurZpHnIlIiIiDaMQL46EeJc2zUKuREREpGFSPsQ37grx1tkhVyIiItIwKR/iu7rTOyvERUQkwSjEi8sB6NJGIS4iIokl5UN80/ZIiOtMXEREEk1Kh7i7s7W0AoC2OVkhVyMiItIwKR3ixWVVVNc4LZtlkJWR0j8KERFJQCmdXFt3BGfhLTJDrkRERKThUjvEg670dupKFxGRBKQQB9q2UIiLiEjiSekQ37KjEtCgNhERSUwpHeK7r4krxEVEJAHFNMTNbJyZLTKzpWZ2ax3bm5nZi8H2yWbWO5b17Gn3NXENbBMRkQQUsxA3s3TgQeB0YAhwqZkN2WO3rwFb3b0/8DvgnljVUxddExcRkUQWyzPxw4Cl7r7c3SuAF4Dxe+wzHng6ePwKcJKZWQxr+oLKaic9zTQ6XUREElJGDF+7G7Cm1vN84PC97ePuVWZWBLQHNsewrt3uu3A4914wjBpvincTERFpXAkxsM3MrjWzqWY2ddOmTY392qSnNdnJv4iISKOJZYivBXrUet49aKtzHzPLANoAhXu+kLs/6u557p7XsWPHGJUrIiKSWGIZ4lOAAWbWx8yygEuACXvsMwH4avD4AmCSu6tzW0REJAoxuyYeXOO+AXgLSAeecPd5ZnYnMNXdJwB/AZ41s6XAFiJBLyIiIlGI5cA23H0iMHGPtttqPS4DLoxlDSIiIskqIQa2iYiIyP+nEBcREUlQCnEREZEEpRAXERFJUApxERGRBKUQFxERSVAKcRERkQSlEBcREUlQlmiznJrZJmBVI75kB5po1bQ4o+NOLal43Kl4zKDjTka93L3OhUMSLsQbm5lNdfe8sOtoajru1JKKx52Kxww67rDraGrqThcREUlQCnEREZEEpRCHR8MuICQ67tSSisediscMOu6UkvLXxEVERBKVzsRFREQSVEqHuJmNM7NFZrbUzG4Nu57GZGYrzWyOmc00s6lBWzsze8fMlgR/tg3azcz+EPwcZpvZqHCrj56ZPWFmBWY2t1Zbg4/TzL4a7L/EzL4axrE0xF6O+w4zWxt85jPN7Ixa234UHPciMzutVntC/Rswsx5m9p6ZzTezeWb23aA9aT/zeo45qT9vM8s2s8/NbFZw3D8P2vuY2eTgGF40s6ygvVnwfGmwvXet16rz55EU3D0lv4B0YBnQF8gCZgFDwq6rEY9vJdBhj7bfALcGj28F7gkenwG8ARhwBDA57PobcJzHAqOAuft7nEA7YHnwZ9vgcduwj20/jvsO4OY69h0S/P1uBvQJ/t6nJ+K/AaArMCp43ApYHBxf0n7m9RxzUn/ewWfWMnicCUwOPsOXgEuC9oeBbwaPrwceDh5fArxY388j7ONrrK9UPhM/DFjq7svdvQJ4ARgfck2xNh54Onj8NHBOrfZnPOIzINfMuoZQX4O5+4fAlj2aG3qcpwHvuPsWd98KvAOMi3nxB2Avx70344EX3L3c3VcAS4n8/U+4fwPuvt7dpwePtwMLgG4k8WdezzHvTVJ83sFnVhI8zQy+HDgReCVo3/Oz3vV34BXgJDMz9v7zSAqpHOLdgDW1nudT/z+MROPA22Y2zcyuDdo6u/v64PEGoHPwONl+Fg09zmQ6/huCbuMndnUpk6THHXSXjiRyhpYSn/kexwxJ/nmbWbqZzQQKiPxHaxmwzd2rgl1qH8Pu4wu2FwHtScDjbohUDvFkd7S7jwJOB75lZsfW3uiRfqakvzUhVY4z8BDQDxgBrAd+G2o1MWRmLYG/Aze6e3Htbcn6mddxzEn/ebt7tbuPALoTOXseHG5F8SeVQ3wt0KPW8+5BW1Jw97XBnwXAP4n8A9i4q5s8+LMg2D3ZfhYNPc6kOH533xj80qsBHuN/XYZJddxmlkkkzJ53938EzUn9mdd1zKnyeQO4+zbgPeBIIpdEMoJNtY9h9/EF29sAhSTwcUcjlUN8CjAgGOmYRWQgxISQa2oUZtbCzFrtegycCswlcny7RuF+FfhX8HgCcEUwkvcIoKhW12QiauhxvgWcamZtgy7JU4O2hLLHOIZziXzmEDnuS4LRu32AAcDnJOC/geAa51+ABe5+f61NSfuZ7+2Yk/3zNrOOZpYbPG4OnEJkPMB7wAXBbnt+1rv+DlwATAp6Zfb280gOYY+sC/OLyMjVxUSus/wk7Hoa8bj6EhmNOQuYt+vYiFwfehdYAvwHaBe0G/Bg8HOYA+SFfQwNONa/EelKrCRyretr+3OcwNVEBrwsBa4K+7j287ifDY5rNpFfXF1r7f+T4LgXAafXak+ofwPA0US6ymcDM4OvM5L5M6/nmJP68waGATOC45sL3Ba09yUSwkuBl4FmQXt28HxpsL3vvn4eyfClGdtEREQSVCp3p4uIiCQ0hbiIiEiCUoiLiIgkKIW4iIhIglKIi4iIJCiFuEiCMbO7zewEMzvHzH7UwO/tGKzwNMPMjtlj2zHBalEzg/tyG1rXjxv6PSJyYBTiIonncOAz4DjgwwZ+70nAHHcf6e4f7bHtMuBudx/h7jv3o64Gh3itmbdEZD8oxEUShJnda2azgTHAp8DXgYfM7LY69u1tZpOCxTHeNbOeZjaCyJKd4/c82zazrwMXAXeZ2fNB2y1mNiV4jZ/X2vfVYGGdebsW1zGzXwPNg9d9Pnj/2mud32xmdwSP3zez31tknfvvmtloM/sgeM23ak2f+h2LrKE928xeaNyfpkhy0GQvIgnEzMYAVwA3Ae+7+9i97Pca8Iq7P21mVwNfcvdzzOxKIrOW3VDH9zwF/NvdXzGzU4lMXXkdkVnPJgC/cfcPzaydu28J/hMwBTjO3QvNrMTdWwav1Tt4raHB85uJrA19h5m9D8x39+uDOcE/AMa7+yYzuxg4zd2vNrN1QB93LzezXI/Mny0itagrSySxjCIyne5gIvNI782RwHnB42eJnIE3xKnB14zgeUsic05/CHzHzM4N2nsE7YUNfP0Xgz8HAUOBdyJThJNOZDpZiEy3+byZvQq82sDXF0kJCnGRBBB0hT9FZAWmzUBOpNlmAkfu5zXset+SyPXxR/ao43jg5OA9S4Oz6uw6vr+KL16u23OfHbXeZ567H1nHa5wJHAucDfzEzA71/60jLSLomrhIQnD3mR5ZV3kxMASYRKTbeW+D0P5LZJUqiAxY23MQ2768BVxtkTWsMbNuZtaJyPKOW4MAHwwcUet7KoPucYCNQCcza29mzYCz9vI+i4COZnZk8D6ZZnaImaUBPdz9PeCHwfu2bOAxiCQ9nYmLJAgz60gkQGvMbLC7z69n928DT5rZLcAm4KqGvJe7v21mBwOfBt3cJcDlwJvAN8xsAZEA/qzWtz0KzDaz6e5+mZndSWQ1qbXAwr28T4WZXQD8wczaEPmd9Hsi/1l5Lmgz4A+6Ji7y/2lgm4iISIJSd7qIiEiCUoiLiIgkKIW4iIhIglKIi4iIJCiFuIiISIJSiIuIiCQohbiIiEiCUoiLiIgkqP8DbdBa/plHDkoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance[\"importance_cumsum\"] = feature_importance[\"importance\"].cumsum()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "ax.plot(np.arange(feature_importance.shape[0]) + 1, feature_importance[\"importance_cumsum\"].values, lw=\"2.\")\n",
    "ax.set_xlabel(\"# of features\")\n",
    "ax.set_ylabel(\"Cumulative feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>importance_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>APPL_CODE_GENDER_M</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>APPL_NAME_INCOME_TYPE_Working</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.012769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>APPL_AMT_GOODS_PRICE_4QCUT_Q2</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>0.018422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>APPL_EXT_SOURCE_3</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.023831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>APPL_EXT_SOURCE_2</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.029046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>PRAP_DAYS_TERMINATION_4QCUT_mode_Q4</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>INPA_AMT_INSTAL_PAY_DIFF_ISPOSITIVE_sum_mm_diff</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>INPA_AMT_INSTAL_PAY_DIFF_ISPOSITIVE_entropy_me...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>POBA_NAME_CONTRACT_STATUS_Completed_sum_min</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>PRAP_AMT_GOODS_PRICE_4QCUT_mode_Q4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2455 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature  importance  \\\n",
       "2825                                 APPL_CODE_GENDER_M    0.006439   \n",
       "2842                      APPL_NAME_INCOME_TYPE_Working    0.006330   \n",
       "2964                      APPL_AMT_GOODS_PRICE_4QCUT_Q2    0.005653   \n",
       "40                                    APPL_EXT_SOURCE_3    0.005410   \n",
       "39                                    APPL_EXT_SOURCE_2    0.005214   \n",
       "...                                                 ...         ...   \n",
       "3261                PRAP_DAYS_TERMINATION_4QCUT_mode_Q4    0.000004   \n",
       "2274    INPA_AMT_INSTAL_PAY_DIFF_ISPOSITIVE_sum_mm_diff    0.000004   \n",
       "1519  INPA_AMT_INSTAL_PAY_DIFF_ISPOSITIVE_entropy_me...    0.000003   \n",
       "1158        POBA_NAME_CONTRACT_STATUS_Completed_sum_min    0.000002   \n",
       "3235                 PRAP_AMT_GOODS_PRICE_4QCUT_mode_Q4    0.000001   \n",
       "\n",
       "      importance_cumsum  \n",
       "2825           0.006439  \n",
       "2842           0.012769  \n",
       "2964           0.018422  \n",
       "40             0.023831  \n",
       "39             0.029046  \n",
       "...                 ...  \n",
       "3261           0.999990  \n",
       "2274           0.999993  \n",
       "1519           0.999997  \n",
       "1158           0.999999  \n",
       "3235           1.000000  \n",
       "\n",
       "[2455 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.iloc[:2455]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sel_train.shape (307511, 2455)\n",
      "X_sel_test.shape (48744, 2455)\n"
     ]
    }
   ],
   "source": [
    "selector = ImportantFeatureSelector(xgb, threshold=2455)\n",
    "selector.fit(X_train)\n",
    "X_sel_train = selector.transform(X_train)\n",
    "X_sel_test = selector.transform(X_test)\n",
    "\n",
    "print(\"X_sel_train.shape\", X_sel_train.shape)\n",
    "print(\"X_sel_test.shape\", X_sel_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sel_train.shape (307511, 2455)\n",
      "X_sel_test.shape (48744, 2455)\n"
     ]
    }
   ],
   "source": [
    "sel_features = [features[i] for i in selector._sel_cols]\n",
    "X_sel_train = pd.DataFrame(X_sel_train, columns=sel_features)\n",
    "X_sel_test = pd.DataFrame(X_sel_test, columns=sel_features)\n",
    "\n",
    "print(\"X_sel_train.shape\", X_sel_train.shape)\n",
    "print(\"X_sel_test.shape\", X_sel_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train[\"APPL_TARGET\"] = y_train\n",
    "\n",
    "X_sel_train.to_csv(\"data/data_/X_y_sel_xgb_train.csv\", index=False)\n",
    "X_sel_test.to_csv(\"data/data_/X_sel_xgb_test.csv\", index=False)\n",
    "\n",
    "del X_sel_train, X_sel_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
