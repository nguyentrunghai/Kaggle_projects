{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtypes(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (df[col].dtype == \"object\") and (df[col].nunique() < df.shape[0]):\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "        elif df[col].dtype == float:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "\n",
    "        elif df[col].dtype == int:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtypes(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(dfs):\n",
    "    \"\"\"assume that indices match\"\"\"\n",
    "    print(\"Shape of dfs\")\n",
    "    for df in dfs:\n",
    "        print(df.shape)\n",
    "        \n",
    "    df_concat = pd.concat(dfs, axis=\"columns\")\n",
    "    print(\"shape of concatenated df\", df_concat.shape)\n",
    "    print(\"Number of nulls:\", df_concat.isnull().sum().sum())\n",
    "    \n",
    "    features = df_concat.columns.to_list()\n",
    "    return features, df_concat.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(estimator, X_eval, y_eval):\n",
    "    \"\"\"\n",
    "    :param estimator: sklearn estimator that have predict_proba() method\n",
    "    :param X_eval: test features\n",
    "    :param y_eval: test target\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    proba = estimator.predict_proba(X_eval)\n",
    "    return roc_auc_score(y_eval, proba[:, 1])\n",
    "\n",
    "\n",
    "def write_submit_csv(estimator, X_test, id_test, out):\n",
    "    \"\"\"\n",
    "    :param estimator: a sklearn estimator that has predict_proba() method\n",
    "    :param X_test: df or array\n",
    "    :param id_test: dataframe containing column \"SK_ID_CURR\"\n",
    "    :param out: str, csv output file name\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    prob_test = estimator.predict_proba(X_test)[:, 1]\n",
    "    submit = id_test\n",
    "    submit[\"TARGET\"] = prob_test\n",
    "    submit.to_csv(out, index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def feature_importance_df(estimator, features):\n",
    "    \"\"\"\n",
    "    :param estimator: an estimator object that has feature_importances_ attribute\n",
    "    :param features: list of str, list of feature names\n",
    "    :return: feature_imp, dataframe\n",
    "    \"\"\"\n",
    "    feature_imp = pd.DataFrame({\"feature\": features, \"importance\": estimator.feature_importances_})\n",
    "    feature_imp = feature_imp.sort_values(by=[\"importance\"], ascending=False)\n",
    "    \n",
    "    feature_imp[\"rank\"] = np.arange(feature_imp.shape[0]) + 1\n",
    "    return feature_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_to_int(a_dict):\n",
    "    new_dict = copy.deepcopy(a_dict)\n",
    "    for k, v in new_dict.items():\n",
    "        if np.isclose(np.round(v), v):\n",
    "            new_dict[k] = int(new_dict[k])\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def run_hyperopt(classifier,\n",
    "                 params_tuned, \n",
    "                 X_train, y_train,\n",
    "                 X_val, y_val,\n",
    "                 num_eval,\n",
    "                 params_fixed=None,\n",
    "                 rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective(params):\n",
    "        classifier.set_params(**params_fixed, **params)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        auc = roc_auc(classifier, X_val, y_val)\n",
    "        return {\"loss\": -auc, \"status\": STATUS_OK}\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "        \n",
    "    trials = Trials()\n",
    "    best_params = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    best_params = whole_to_int(best_params)\n",
    "    best_model = classifier.set_params(**params_fixed, **best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    \n",
    "    return trials, best_params, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_y_hat(submit_csv_files):\n",
    "    y_hats = [pd.read_csv(f) for f in submit_csv_files]\n",
    "    result = y_hats[0][[\"SK_ID_CURR\"]]\n",
    "    result[\"TARGET\"] = 0.\n",
    "    for y in y_hats:\n",
    "        result[\"TARGET\"] = result[\"TARGET\"] + y[\"TARGET\"]\n",
    "    \n",
    "    result[\"TARGET\"] = result[\"TARGET\"] / len(y_hats)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/data_\"\n",
    "SUB_DIR = \"data/submit_\"\n",
    "MODELS_DIR = \"data/models_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X_org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 320.00 MB\n",
      "Memory usage after changing types 160.00 MB\n",
      "Memory usage before changing types 320.00 MB\n",
      "Memory usage after changing types 160.00 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((200000, 200), (200000, 200))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_org_train = load_csv(os.path.join(INP_DIR, \"X_org_train.csv\"))\n",
    "X_org_test = load_csv(os.path.join(INP_DIR, \"X_org_test.csv\"))\n",
    "\n",
    "X_org_train.shape, X_org_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.522699</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.780300</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.430500</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.356001</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.604200</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.722200</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.034700</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.969700</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.287600</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.997400</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193    var_194  var_195  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.522699  -2.3978   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.430500   2.0339   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.604200   3.1417   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.034700  -1.2706   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.287600  -1.5121   \n",
       "\n",
       "   var_196  var_197    var_198  var_199  \n",
       "0   7.8784   8.5635  12.780300  -1.0914  \n",
       "1   8.1267   8.7889  18.356001   1.9518  \n",
       "2  -6.5213   8.2675  14.722200   0.3965  \n",
       "3  -2.9275  10.2922  17.969700  -8.9996  \n",
       "4   3.9267   9.5031  17.997400  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_org_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.267500</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.711200</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.472200</td>\n",
       "      <td>-8.719700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.631599</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.576500</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.129299</td>\n",
       "      <td>-20.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.253700</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.981300</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.895599</td>\n",
       "      <td>-23.179399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.566000</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.187400</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.016800</td>\n",
       "      <td>-4.210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.604800</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.554199</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.926000</td>\n",
       "      <td>-9.184600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6      var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.267500   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.631599   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.253700   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.566000   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.604800   \n",
       "\n",
       "    var_8   var_9  ...  var_190  var_191  var_192  var_193    var_194  \\\n",
       "0  2.1337  8.8100  ...  -2.1556  11.8495  -1.4300   2.4508  13.711200   \n",
       "1 -4.4131  5.9739  ...  10.6165   8.8349   0.9403  10.1282  15.576500   \n",
       "2  1.5233  8.3442  ...  -0.7484  10.9935   1.9803   2.1800  12.981300   \n",
       "3  3.3755  7.4578  ...   9.5702   9.0766   1.6580   3.5813  15.187400   \n",
       "4  2.9890  7.1437  ...   4.2259   9.1723   1.2835   3.3778  19.554199   \n",
       "\n",
       "   var_195  var_196  var_197    var_198    var_199  \n",
       "0   2.4669   4.3654  10.7200  15.472200  -8.719700  \n",
       "1   0.4773  -1.4852   9.8714  19.129299 -20.976000  \n",
       "2   2.1281  -7.1086   7.0618  19.895599 -23.179399  \n",
       "3   3.1656   3.9567   9.2295  13.016800  -4.210800  \n",
       "4  -0.2860  -5.1612   7.2882  13.926000  -9.184600  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_org_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X_q10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n",
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((200000, 199), (200000, 199))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q10_train = load_csv(os.path.join(INP_DIR, \"X_q10_train.csv\"))\n",
    "X_q10_test = load_csv(os.path.join(INP_DIR, \"X_q10_test.csv\"))\n",
    "\n",
    "X_q10_train.shape, X_q10_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_10QCUT</th>\n",
       "      <th>var_1_10QCUT</th>\n",
       "      <th>var_2_10QCUT</th>\n",
       "      <th>var_3_10QCUT</th>\n",
       "      <th>var_4_10QCUT</th>\n",
       "      <th>var_5_10QCUT</th>\n",
       "      <th>var_6_10QCUT</th>\n",
       "      <th>var_7_10QCUT</th>\n",
       "      <th>var_8_10QCUT</th>\n",
       "      <th>var_9_10QCUT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_10QCUT</th>\n",
       "      <th>var_191_10QCUT</th>\n",
       "      <th>var_192_10QCUT</th>\n",
       "      <th>var_193_10QCUT</th>\n",
       "      <th>var_194_10QCUT</th>\n",
       "      <th>var_195_10QCUT</th>\n",
       "      <th>var_196_10QCUT</th>\n",
       "      <th>var_197_10QCUT</th>\n",
       "      <th>var_198_10QCUT</th>\n",
       "      <th>var_199_10QCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_10QCUT  var_1_10QCUT  var_2_10QCUT  var_3_10QCUT  var_4_10QCUT  \\\n",
       "0             4             2             7             3             6   \n",
       "1             7             3             9             3             8   \n",
       "2             3             5             7             7             4   \n",
       "3             6             5             3             6             9   \n",
       "4             5             6             8             5             8   \n",
       "\n",
       "   var_5_10QCUT  var_6_10QCUT  var_7_10QCUT  var_8_10QCUT  var_9_10QCUT  ...  \\\n",
       "0             4             4             8             1             1  ...   \n",
       "1            10             6             6             8             7  ...   \n",
       "2             4            10             4             1             2  ...   \n",
       "3             7             7             4             1             7  ...   \n",
       "4             9             8             8            10             6  ...   \n",
       "\n",
       "   var_190_10QCUT  var_191_10QCUT  var_192_10QCUT  var_193_10QCUT  \\\n",
       "0               7               2               8               4   \n",
       "1               9               6               7              10   \n",
       "2               5               8               5               4   \n",
       "3               7               3               3               4   \n",
       "4               2               8               1              10   \n",
       "\n",
       "   var_194_10QCUT  var_195_10QCUT  var_196_10QCUT  var_197_10QCUT  \\\n",
       "0               6               1               9               4   \n",
       "1               3              10               9               5   \n",
       "2               9              10               1               3   \n",
       "3              10               3               3              10   \n",
       "4               1               2               6               8   \n",
       "\n",
       "   var_198_10QCUT  var_199_10QCUT  \n",
       "0               2               6  \n",
       "1               8               7  \n",
       "2               4               7  \n",
       "3               8               4  \n",
       "4               8               4  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q10_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_10QCUT</th>\n",
       "      <th>var_1_10QCUT</th>\n",
       "      <th>var_2_10QCUT</th>\n",
       "      <th>var_3_10QCUT</th>\n",
       "      <th>var_4_10QCUT</th>\n",
       "      <th>var_5_10QCUT</th>\n",
       "      <th>var_6_10QCUT</th>\n",
       "      <th>var_7_10QCUT</th>\n",
       "      <th>var_8_10QCUT</th>\n",
       "      <th>var_9_10QCUT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_10QCUT</th>\n",
       "      <th>var_191_10QCUT</th>\n",
       "      <th>var_192_10QCUT</th>\n",
       "      <th>var_193_10QCUT</th>\n",
       "      <th>var_194_10QCUT</th>\n",
       "      <th>var_195_10QCUT</th>\n",
       "      <th>var_196_10QCUT</th>\n",
       "      <th>var_197_10QCUT</th>\n",
       "      <th>var_198_10QCUT</th>\n",
       "      <th>var_199_10QCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_10QCUT  var_1_10QCUT  var_2_10QCUT  var_3_10QCUT  var_4_10QCUT  \\\n",
       "0             6            10             8             9             6   \n",
       "1             3             8             6             3             2   \n",
       "2             1             1             5             6             4   \n",
       "3             3             6             7             5             1   \n",
       "4             7             7             9             7             2   \n",
       "\n",
       "   var_5_10QCUT  var_6_10QCUT  var_7_10QCUT  var_8_10QCUT  var_9_10QCUT  ...  \\\n",
       "0             7             7             7             7             9  ...   \n",
       "1             6             8             8             1             2  ...   \n",
       "2            10             3             9             7             7  ...   \n",
       "3             9             4             9             8             5  ...   \n",
       "4             4            10             1             8             4  ...   \n",
       "\n",
       "   var_190_10QCUT  var_191_10QCUT  var_192_10QCUT  var_193_10QCUT  \\\n",
       "0               2              10               1               5   \n",
       "1              10               7               3              10   \n",
       "2               3               9               6               4   \n",
       "3              10               8               5               6   \n",
       "4               6               8               4               5   \n",
       "\n",
       "   var_194_10QCUT  var_195_10QCUT  var_196_10QCUT  var_197_10QCUT  \\\n",
       "0               1              10               7              10   \n",
       "1               3               7               3               9   \n",
       "2               1              10               1               1   \n",
       "3               3              10               6               7   \n",
       "4               7               5               1               1   \n",
       "\n",
       "   var_198_10QCUT  var_199_10QCUT  \n",
       "0               5               4  \n",
       "1               9               1  \n",
       "2              10               1  \n",
       "3               2               5  \n",
       "4               3               4  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q10_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X_valcount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n",
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((200000, 199), (200000, 199))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valcount_train = load_csv(os.path.join(INP_DIR, \"X_valcount_train.csv\"))\n",
    "X_valcount_test = load_csv(os.path.join(INP_DIR, \"X_valcount_test.csv\"))\n",
    "\n",
    "X_valcount_train.shape, X_valcount_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_VALCOUNT</th>\n",
       "      <th>var_1_VALCOUNT</th>\n",
       "      <th>var_2_VALCOUNT</th>\n",
       "      <th>var_3_VALCOUNT</th>\n",
       "      <th>var_4_VALCOUNT</th>\n",
       "      <th>var_5_VALCOUNT</th>\n",
       "      <th>var_6_VALCOUNT</th>\n",
       "      <th>var_7_VALCOUNT</th>\n",
       "      <th>var_8_VALCOUNT</th>\n",
       "      <th>var_9_VALCOUNT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_VALCOUNT</th>\n",
       "      <th>var_191_VALCOUNT</th>\n",
       "      <th>var_192_VALCOUNT</th>\n",
       "      <th>var_193_VALCOUNT</th>\n",
       "      <th>var_194_VALCOUNT</th>\n",
       "      <th>var_195_VALCOUNT</th>\n",
       "      <th>var_196_VALCOUNT</th>\n",
       "      <th>var_197_VALCOUNT</th>\n",
       "      <th>var_198_VALCOUNT</th>\n",
       "      <th>var_199_VALCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.017310</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.018030</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022535</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018230</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>0.023465</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>0.023160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026610</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.015245</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.022425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.025925</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.022360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>0.019985</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_VALCOUNT  var_1_VALCOUNT  var_2_VALCOUNT  var_3_VALCOUNT  \\\n",
       "0        0.023180        0.014420        0.020180        0.018425   \n",
       "1        0.022535        0.018725        0.011875        0.019795   \n",
       "2        0.023055        0.021240        0.020710        0.022340   \n",
       "3        0.023185        0.021860        0.023130        0.022530   \n",
       "4        0.025325        0.021790        0.017820        0.021800   \n",
       "\n",
       "   var_4_VALCOUNT  var_5_VALCOUNT  var_6_VALCOUNT  var_7_VALCOUNT  \\\n",
       "0        0.025530        0.018470        0.025020        0.020355   \n",
       "1        0.022620        0.007615        0.023985        0.021825   \n",
       "2        0.024285        0.019355        0.005935        0.022510   \n",
       "3        0.020200        0.021585        0.024920        0.022655   \n",
       "4        0.022620        0.019950        0.024220        0.018585   \n",
       "\n",
       "   var_8_VALCOUNT  var_9_VALCOUNT  ...  var_190_VALCOUNT  var_191_VALCOUNT  \\\n",
       "0        0.010525        0.009340  ...          0.027125          0.017310   \n",
       "1        0.020770        0.016915  ...          0.018230          0.022005   \n",
       "2        0.010525        0.011855  ...          0.026610          0.018380   \n",
       "3        0.005750        0.017435  ...          0.026240          0.020190   \n",
       "4        0.005105        0.022360  ...          0.018440          0.021150   \n",
       "\n",
       "   var_192_VALCOUNT  var_193_VALCOUNT  var_194_VALCOUNT  var_195_VALCOUNT  \\\n",
       "0          0.023575          0.026110          0.020655          0.008920   \n",
       "1          0.027595          0.004885          0.020115          0.007790   \n",
       "2          0.032310          0.026110          0.015245          0.005835   \n",
       "3          0.024865          0.025925          0.009340          0.020320   \n",
       "4          0.012755          0.012100          0.008540          0.019105   \n",
       "\n",
       "   var_196_VALCOUNT  var_197_VALCOUNT  var_198_VALCOUNT  var_199_VALCOUNT  \n",
       "0          0.018030          0.025010          0.014545          0.021400  \n",
       "1          0.017220          0.023465          0.020685          0.023160  \n",
       "2          0.009335          0.022070          0.024330          0.022425  \n",
       "3          0.016410          0.010905          0.020300          0.019065  \n",
       "4          0.019310          0.019985          0.020300          0.019065  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valcount_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_VALCOUNT</th>\n",
       "      <th>var_1_VALCOUNT</th>\n",
       "      <th>var_2_VALCOUNT</th>\n",
       "      <th>var_3_VALCOUNT</th>\n",
       "      <th>var_4_VALCOUNT</th>\n",
       "      <th>var_5_VALCOUNT</th>\n",
       "      <th>var_6_VALCOUNT</th>\n",
       "      <th>var_7_VALCOUNT</th>\n",
       "      <th>var_8_VALCOUNT</th>\n",
       "      <th>var_9_VALCOUNT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_VALCOUNT</th>\n",
       "      <th>var_191_VALCOUNT</th>\n",
       "      <th>var_192_VALCOUNT</th>\n",
       "      <th>var_193_VALCOUNT</th>\n",
       "      <th>var_194_VALCOUNT</th>\n",
       "      <th>var_195_VALCOUNT</th>\n",
       "      <th>var_196_VALCOUNT</th>\n",
       "      <th>var_197_VALCOUNT</th>\n",
       "      <th>var_198_VALCOUNT</th>\n",
       "      <th>var_199_VALCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.019705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015905</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.02347</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.016955</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.01703</td>\n",
       "      <td>0.008395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.023045</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>0.020705</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.01307</td>\n",
       "      <td>0.005505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.018980</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.01613</td>\n",
       "      <td>0.021035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022170</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.017970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.02091</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_VALCOUNT  var_1_VALCOUNT  var_2_VALCOUNT  var_3_VALCOUNT  \\\n",
       "0        0.023185        0.002985        0.017820        0.013280   \n",
       "1        0.022580        0.019700        0.020070        0.019175   \n",
       "2        0.006135        0.002035        0.023045        0.022010   \n",
       "3        0.022580        0.021790        0.020710        0.021800   \n",
       "4        0.022170        0.021175        0.011185        0.022225   \n",
       "\n",
       "   var_4_VALCOUNT  var_5_VALCOUNT  var_6_VALCOUNT  var_7_VALCOUNT  \\\n",
       "0        0.025870        0.021110        0.024920        0.021170   \n",
       "1        0.016155        0.020885        0.021290        0.020355   \n",
       "2        0.022120        0.003415        0.024355        0.016390   \n",
       "3        0.013615        0.018980        0.024275        0.014890   \n",
       "4        0.015815        0.019140        0.007030        0.007215   \n",
       "\n",
       "   var_8_VALCOUNT  var_9_VALCOUNT  ...  var_190_VALCOUNT  var_191_VALCOUNT  \\\n",
       "0        0.021070        0.019705  ...          0.015905          0.009195   \n",
       "1        0.012380        0.011855  ...          0.008525          0.023730   \n",
       "2        0.020705        0.018530  ...          0.021340          0.012415   \n",
       "3        0.019230        0.017765  ...          0.011155          0.023625   \n",
       "4        0.020765        0.017970  ...          0.027125          0.022430   \n",
       "\n",
       "   var_192_VALCOUNT  var_193_VALCOUNT  var_194_VALCOUNT  var_195_VALCOUNT  \\\n",
       "0          0.001740          0.027500          0.011735          0.004765   \n",
       "1          0.025480          0.008020          0.020115          0.024435   \n",
       "2          0.031905          0.027055          0.007435          0.006640   \n",
       "3          0.032310          0.027710          0.018975          0.005835   \n",
       "4          0.029515          0.028070          0.019650          0.024640   \n",
       "\n",
       "   var_196_VALCOUNT  var_197_VALCOUNT  var_198_VALCOUNT  var_199_VALCOUNT  \n",
       "0          0.019855          0.004135           0.02347          0.019065  \n",
       "1          0.016955          0.017140           0.01703          0.008395  \n",
       "2          0.006805          0.004040           0.01307          0.005505  \n",
       "3          0.019310          0.021705           0.01613          0.021035  \n",
       "4          0.012420          0.004870           0.02091          0.019065  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valcount_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X_target_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n",
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((200000, 199), (200000, 199))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target_mean_train = load_csv(os.path.join(INP_DIR, \"X_target_mean_train.csv\"))\n",
    "X_target_mean_test = load_csv(os.path.join(INP_DIR, \"X_target_mean_test.csv\"))\n",
    "\n",
    "X_target_mean_train.shape, X_target_mean_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_TARGETMEANNUM</th>\n",
       "      <th>var_1_TARGETMEANNUM</th>\n",
       "      <th>var_2_TARGETMEANNUM</th>\n",
       "      <th>var_3_TARGETMEANNUM</th>\n",
       "      <th>var_4_TARGETMEANNUM</th>\n",
       "      <th>var_5_TARGETMEANNUM</th>\n",
       "      <th>var_6_TARGETMEANNUM</th>\n",
       "      <th>var_7_TARGETMEANNUM</th>\n",
       "      <th>var_8_TARGETMEANNUM</th>\n",
       "      <th>var_9_TARGETMEANNUM</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_TARGETMEANNUM</th>\n",
       "      <th>var_191_TARGETMEANNUM</th>\n",
       "      <th>var_192_TARGETMEANNUM</th>\n",
       "      <th>var_193_TARGETMEANNUM</th>\n",
       "      <th>var_194_TARGETMEANNUM</th>\n",
       "      <th>var_195_TARGETMEANNUM</th>\n",
       "      <th>var_196_TARGETMEANNUM</th>\n",
       "      <th>var_197_TARGETMEANNUM</th>\n",
       "      <th>var_198_TARGETMEANNUM</th>\n",
       "      <th>var_199_TARGETMEANNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090655</td>\n",
       "      <td>0.088354</td>\n",
       "      <td>0.097395</td>\n",
       "      <td>0.099495</td>\n",
       "      <td>0.095990</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.085241</td>\n",
       "      <td>0.099345</td>\n",
       "      <td>0.089687</td>\n",
       "      <td>0.138179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.089546</td>\n",
       "      <td>0.082596</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.103895</td>\n",
       "      <td>0.09445</td>\n",
       "      <td>0.103350</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.108989</td>\n",
       "      <td>0.101650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091691</td>\n",
       "      <td>0.088396</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.099495</td>\n",
       "      <td>0.100155</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.088813</td>\n",
       "      <td>0.101345</td>\n",
       "      <td>0.100825</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112450</td>\n",
       "      <td>0.091986</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>0.09525</td>\n",
       "      <td>0.103105</td>\n",
       "      <td>0.12715</td>\n",
       "      <td>0.103350</td>\n",
       "      <td>0.099525</td>\n",
       "      <td>0.087559</td>\n",
       "      <td>0.099745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090545</td>\n",
       "      <td>0.099805</td>\n",
       "      <td>0.097395</td>\n",
       "      <td>0.100450</td>\n",
       "      <td>0.096860</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.097945</td>\n",
       "      <td>0.089687</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090945</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>0.12715</td>\n",
       "      <td>0.092950</td>\n",
       "      <td>0.099895</td>\n",
       "      <td>0.098195</td>\n",
       "      <td>0.099745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.099805</td>\n",
       "      <td>0.089713</td>\n",
       "      <td>0.103805</td>\n",
       "      <td>0.100555</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.106261</td>\n",
       "      <td>0.097945</td>\n",
       "      <td>0.089687</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.089654</td>\n",
       "      <td>0.108655</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.092850</td>\n",
       "      <td>0.09804</td>\n",
       "      <td>0.093791</td>\n",
       "      <td>0.089204</td>\n",
       "      <td>0.087559</td>\n",
       "      <td>0.099595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.103795</td>\n",
       "      <td>0.115706</td>\n",
       "      <td>0.098970</td>\n",
       "      <td>0.100155</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>0.099345</td>\n",
       "      <td>0.118512</td>\n",
       "      <td>0.111606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.127050</td>\n",
       "      <td>0.09525</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.09335</td>\n",
       "      <td>0.102860</td>\n",
       "      <td>0.094276</td>\n",
       "      <td>0.087559</td>\n",
       "      <td>0.099595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_TARGETMEANNUM  var_1_TARGETMEANNUM  var_2_TARGETMEANNUM  \\\n",
       "0             0.090655             0.088354             0.097395   \n",
       "1             0.091691             0.088396             0.110400   \n",
       "2             0.090545             0.099805             0.097395   \n",
       "3             0.092800             0.099805             0.089713   \n",
       "4             0.088200             0.103795             0.115706   \n",
       "\n",
       "   var_3_TARGETMEANNUM  var_4_TARGETMEANNUM  var_5_TARGETMEANNUM  \\\n",
       "0             0.099495             0.095990             0.093895   \n",
       "1             0.099495             0.100155             0.133000   \n",
       "2             0.100450             0.096860             0.093895   \n",
       "3             0.103805             0.100555             0.097550   \n",
       "4             0.098970             0.100155             0.100500   \n",
       "\n",
       "   var_6_TARGETMEANNUM  var_7_TARGETMEANNUM  var_8_TARGETMEANNUM  \\\n",
       "0             0.085241             0.099345             0.089687   \n",
       "1             0.088813             0.101345             0.100825   \n",
       "2             0.159100             0.097945             0.089687   \n",
       "3             0.106261             0.097945             0.089687   \n",
       "4             0.109167             0.099345             0.118512   \n",
       "\n",
       "   var_9_TARGETMEANNUM  ...  var_190_TARGETMEANNUM  var_191_TARGETMEANNUM  \\\n",
       "0             0.138179  ...               0.097300               0.089546   \n",
       "1             0.088596  ...               0.112450               0.091986   \n",
       "2             0.101355  ...               0.090945               0.105200   \n",
       "3             0.088596  ...               0.097300               0.089654   \n",
       "4             0.111606  ...               0.089904               0.105200   \n",
       "\n",
       "   var_192_TARGETMEANNUM  var_193_TARGETMEANNUM  var_194_TARGETMEANNUM  \\\n",
       "0               0.082596                0.10250               0.103895   \n",
       "1               0.089150                0.09525               0.103105   \n",
       "2               0.102200                0.10250               0.094919   \n",
       "3               0.108655                0.10250               0.092850   \n",
       "4               0.127050                0.09525               0.119500   \n",
       "\n",
       "   var_195_TARGETMEANNUM  var_196_TARGETMEANNUM  var_197_TARGETMEANNUM  \\\n",
       "0                0.09445               0.103350               0.102100   \n",
       "1                0.12715               0.103350               0.099525   \n",
       "2                0.12715               0.092950               0.099895   \n",
       "3                0.09804               0.093791               0.089204   \n",
       "4                0.09335               0.102860               0.094276   \n",
       "\n",
       "   var_198_TARGETMEANNUM  var_199_TARGETMEANNUM  \n",
       "0               0.108989               0.101650  \n",
       "1               0.087559               0.099745  \n",
       "2               0.098195               0.099745  \n",
       "3               0.087559               0.099595  \n",
       "4               0.087559               0.099595  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target_mean_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_TARGETMEANNUM</th>\n",
       "      <th>var_1_TARGETMEANNUM</th>\n",
       "      <th>var_2_TARGETMEANNUM</th>\n",
       "      <th>var_3_TARGETMEANNUM</th>\n",
       "      <th>var_4_TARGETMEANNUM</th>\n",
       "      <th>var_5_TARGETMEANNUM</th>\n",
       "      <th>var_6_TARGETMEANNUM</th>\n",
       "      <th>var_7_TARGETMEANNUM</th>\n",
       "      <th>var_8_TARGETMEANNUM</th>\n",
       "      <th>var_9_TARGETMEANNUM</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_TARGETMEANNUM</th>\n",
       "      <th>var_191_TARGETMEANNUM</th>\n",
       "      <th>var_192_TARGETMEANNUM</th>\n",
       "      <th>var_193_TARGETMEANNUM</th>\n",
       "      <th>var_194_TARGETMEANNUM</th>\n",
       "      <th>var_195_TARGETMEANNUM</th>\n",
       "      <th>var_196_TARGETMEANNUM</th>\n",
       "      <th>var_197_TARGETMEANNUM</th>\n",
       "      <th>var_198_TARGETMEANNUM</th>\n",
       "      <th>var_199_TARGETMEANNUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.143650</td>\n",
       "      <td>0.115706</td>\n",
       "      <td>0.099545</td>\n",
       "      <td>0.095990</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.106261</td>\n",
       "      <td>0.101910</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.086787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.127050</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.127150</td>\n",
       "      <td>0.098895</td>\n",
       "      <td>0.089204</td>\n",
       "      <td>0.093755</td>\n",
       "      <td>0.099595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090545</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.086663</td>\n",
       "      <td>0.099495</td>\n",
       "      <td>0.101795</td>\n",
       "      <td>0.103250</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>0.099345</td>\n",
       "      <td>0.089687</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.104505</td>\n",
       "      <td>0.108655</td>\n",
       "      <td>0.095250</td>\n",
       "      <td>0.103105</td>\n",
       "      <td>0.096157</td>\n",
       "      <td>0.093791</td>\n",
       "      <td>0.091218</td>\n",
       "      <td>0.089146</td>\n",
       "      <td>0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.083746</td>\n",
       "      <td>0.085791</td>\n",
       "      <td>0.103805</td>\n",
       "      <td>0.096860</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.095750</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.107411</td>\n",
       "      <td>0.094155</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.127150</td>\n",
       "      <td>0.092950</td>\n",
       "      <td>0.133637</td>\n",
       "      <td>0.091205</td>\n",
       "      <td>0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090545</td>\n",
       "      <td>0.103795</td>\n",
       "      <td>0.097395</td>\n",
       "      <td>0.098970</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.085241</td>\n",
       "      <td>0.095750</td>\n",
       "      <td>0.100825</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.098685</td>\n",
       "      <td>0.103105</td>\n",
       "      <td>0.127150</td>\n",
       "      <td>0.102860</td>\n",
       "      <td>0.092514</td>\n",
       "      <td>0.108989</td>\n",
       "      <td>0.101555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091691</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.100450</td>\n",
       "      <td>0.101795</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.102350</td>\n",
       "      <td>0.100825</td>\n",
       "      <td>0.099725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098705</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.108950</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.095450</td>\n",
       "      <td>0.095590</td>\n",
       "      <td>0.092950</td>\n",
       "      <td>0.133637</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.099595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_TARGETMEANNUM  var_1_TARGETMEANNUM  var_2_TARGETMEANNUM  \\\n",
       "0             0.092800             0.143650             0.115706   \n",
       "1             0.090545             0.101400             0.086663   \n",
       "2             0.090100             0.083746             0.085791   \n",
       "3             0.090545             0.103795             0.097395   \n",
       "4             0.091691             0.101355             0.110400   \n",
       "\n",
       "   var_3_TARGETMEANNUM  var_4_TARGETMEANNUM  var_5_TARGETMEANNUM  \\\n",
       "0             0.099545             0.095990             0.097550   \n",
       "1             0.099495             0.101795             0.103250   \n",
       "2             0.103805             0.096860             0.133000   \n",
       "3             0.098970             0.097400             0.100500   \n",
       "4             0.100450             0.101795             0.093895   \n",
       "\n",
       "   var_6_TARGETMEANNUM  var_7_TARGETMEANNUM  var_8_TARGETMEANNUM  \\\n",
       "0             0.106261             0.101910             0.097600   \n",
       "1             0.109167             0.099345             0.089687   \n",
       "2             0.086000             0.095750             0.097600   \n",
       "3             0.085241             0.095750             0.100825   \n",
       "4             0.159100             0.102350             0.100825   \n",
       "\n",
       "   var_9_TARGETMEANNUM  ...  var_190_TARGETMEANNUM  var_191_TARGETMEANNUM  \\\n",
       "0             0.086787  ...               0.089904               0.143000   \n",
       "1             0.101355  ...               0.151500               0.104505   \n",
       "2             0.088596  ...               0.085100               0.107411   \n",
       "3             0.106127  ...               0.151500               0.105200   \n",
       "4             0.099725  ...               0.098705               0.105200   \n",
       "\n",
       "   var_192_TARGETMEANNUM  var_193_TARGETMEANNUM  var_194_TARGETMEANNUM  \\\n",
       "0               0.127050               0.098000               0.119500   \n",
       "1               0.108655               0.095250               0.103105   \n",
       "2               0.094155               0.102500               0.119500   \n",
       "3               0.102200               0.098685               0.103105   \n",
       "4               0.108950               0.098000               0.095450   \n",
       "\n",
       "   var_195_TARGETMEANNUM  var_196_TARGETMEANNUM  var_197_TARGETMEANNUM  \\\n",
       "0               0.127150               0.098895               0.089204   \n",
       "1               0.096157               0.093791               0.091218   \n",
       "2               0.127150               0.092950               0.133637   \n",
       "3               0.127150               0.102860               0.092514   \n",
       "4               0.095590               0.092950               0.133637   \n",
       "\n",
       "   var_198_TARGETMEANNUM  var_199_TARGETMEANNUM  \n",
       "0               0.093755               0.099595  \n",
       "1               0.089146               0.086000  \n",
       "2               0.091205               0.086000  \n",
       "3               0.108989               0.101555  \n",
       "4               0.106061               0.099595  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target_mean_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X_woe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n",
      "Memory usage before changing types 318.40 MB\n",
      "Memory usage after changing types 159.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((200000, 199), (200000, 199))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_woe_train = load_csv(os.path.join(INP_DIR, \"X_woe_train.csv\"))\n",
    "X_woe_test = load_csv(os.path.join(INP_DIR, \"X_woe_test.csv\"))\n",
    "\n",
    "X_woe_train.shape, X_woe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_WOENUM</th>\n",
       "      <th>var_1_WOENUM</th>\n",
       "      <th>var_2_WOENUM</th>\n",
       "      <th>var_3_WOENUM</th>\n",
       "      <th>var_4_WOENUM</th>\n",
       "      <th>var_5_WOENUM</th>\n",
       "      <th>var_6_WOENUM</th>\n",
       "      <th>var_7_WOENUM</th>\n",
       "      <th>var_8_WOENUM</th>\n",
       "      <th>var_9_WOENUM</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_WOENUM</th>\n",
       "      <th>var_191_WOENUM</th>\n",
       "      <th>var_192_WOENUM</th>\n",
       "      <th>var_193_WOENUM</th>\n",
       "      <th>var_194_WOENUM</th>\n",
       "      <th>var_195_WOENUM</th>\n",
       "      <th>var_196_WOENUM</th>\n",
       "      <th>var_197_WOENUM</th>\n",
       "      <th>var_198_WOENUM</th>\n",
       "      <th>var_199_WOENUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.566910</td>\n",
       "      <td>233.389511</td>\n",
       "      <td>222.650864</td>\n",
       "      <td>220.284805</td>\n",
       "      <td>224.259186</td>\n",
       "      <td>226.697449</td>\n",
       "      <td>237.317200</td>\n",
       "      <td>220.452332</td>\n",
       "      <td>231.746826</td>\n",
       "      <td>183.049530</td>\n",
       "      <td>...</td>\n",
       "      <td>222.759125</td>\n",
       "      <td>231.919678</td>\n",
       "      <td>240.758835</td>\n",
       "      <td>216.975037</td>\n",
       "      <td>215.467896</td>\n",
       "      <td>226.047195</td>\n",
       "      <td>216.054428</td>\n",
       "      <td>217.410599</td>\n",
       "      <td>210.110870</td>\n",
       "      <td>217.902420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229.316238</td>\n",
       "      <td>233.338425</td>\n",
       "      <td>208.666183</td>\n",
       "      <td>220.284805</td>\n",
       "      <td>219.550339</td>\n",
       "      <td>187.468979</td>\n",
       "      <td>232.821106</td>\n",
       "      <td>218.236938</td>\n",
       "      <td>218.809357</td>\n",
       "      <td>233.090485</td>\n",
       "      <td>...</td>\n",
       "      <td>206.595612</td>\n",
       "      <td>228.962097</td>\n",
       "      <td>232.405792</td>\n",
       "      <td>225.115372</td>\n",
       "      <td>216.318924</td>\n",
       "      <td>192.639618</td>\n",
       "      <td>216.054428</td>\n",
       "      <td>220.251221</td>\n",
       "      <td>234.381363</td>\n",
       "      <td>220.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230.699280</td>\n",
       "      <td>219.939316</td>\n",
       "      <td>222.650864</td>\n",
       "      <td>219.223450</td>\n",
       "      <td>223.261459</td>\n",
       "      <td>226.697449</td>\n",
       "      <td>166.493988</td>\n",
       "      <td>222.026825</td>\n",
       "      <td>231.746826</td>\n",
       "      <td>218.225815</td>\n",
       "      <td>...</td>\n",
       "      <td>230.214523</td>\n",
       "      <td>214.073700</td>\n",
       "      <td>217.301559</td>\n",
       "      <td>216.975037</td>\n",
       "      <td>225.500076</td>\n",
       "      <td>192.639618</td>\n",
       "      <td>227.813583</td>\n",
       "      <td>219.839172</td>\n",
       "      <td>221.744202</td>\n",
       "      <td>220.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227.991623</td>\n",
       "      <td>219.939316</td>\n",
       "      <td>231.713867</td>\n",
       "      <td>215.564178</td>\n",
       "      <td>219.107269</td>\n",
       "      <td>222.474823</td>\n",
       "      <td>212.951935</td>\n",
       "      <td>222.026825</td>\n",
       "      <td>231.746826</td>\n",
       "      <td>233.090485</td>\n",
       "      <td>...</td>\n",
       "      <td>222.759125</td>\n",
       "      <td>231.786102</td>\n",
       "      <td>210.454941</td>\n",
       "      <td>216.975037</td>\n",
       "      <td>227.932251</td>\n",
       "      <td>221.919235</td>\n",
       "      <td>226.820557</td>\n",
       "      <td>232.338745</td>\n",
       "      <td>234.381363</td>\n",
       "      <td>220.173248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>233.581375</td>\n",
       "      <td>215.575348</td>\n",
       "      <td>203.373917</td>\n",
       "      <td>220.872406</td>\n",
       "      <td>219.550339</td>\n",
       "      <td>219.168137</td>\n",
       "      <td>209.927567</td>\n",
       "      <td>220.452332</td>\n",
       "      <td>200.659866</td>\n",
       "      <td>207.444473</td>\n",
       "      <td>...</td>\n",
       "      <td>231.480164</td>\n",
       "      <td>214.073700</td>\n",
       "      <td>192.729752</td>\n",
       "      <td>225.115372</td>\n",
       "      <td>199.717361</td>\n",
       "      <td>227.340057</td>\n",
       "      <td>216.584000</td>\n",
       "      <td>226.250290</td>\n",
       "      <td>234.381363</td>\n",
       "      <td>220.173248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_WOENUM  var_1_WOENUM  var_2_WOENUM  var_3_WOENUM  var_4_WOENUM  \\\n",
       "0    230.566910    233.389511    222.650864    220.284805    224.259186   \n",
       "1    229.316238    233.338425    208.666183    220.284805    219.550339   \n",
       "2    230.699280    219.939316    222.650864    219.223450    223.261459   \n",
       "3    227.991623    219.939316    231.713867    215.564178    219.107269   \n",
       "4    233.581375    215.575348    203.373917    220.872406    219.550339   \n",
       "\n",
       "   var_5_WOENUM  var_6_WOENUM  var_7_WOENUM  var_8_WOENUM  var_9_WOENUM  ...  \\\n",
       "0    226.697449    237.317200    220.452332    231.746826    183.049530  ...   \n",
       "1    187.468979    232.821106    218.236938    218.809357    233.090485  ...   \n",
       "2    226.697449    166.493988    222.026825    231.746826    218.225815  ...   \n",
       "3    222.474823    212.951935    222.026825    231.746826    233.090485  ...   \n",
       "4    219.168137    209.927567    220.452332    200.659866    207.444473  ...   \n",
       "\n",
       "   var_190_WOENUM  var_191_WOENUM  var_192_WOENUM  var_193_WOENUM  \\\n",
       "0      222.759125      231.919678      240.758835      216.975037   \n",
       "1      206.595612      228.962097      232.405792      225.115372   \n",
       "2      230.214523      214.073700      217.301559      216.975037   \n",
       "3      222.759125      231.786102      210.454941      216.975037   \n",
       "4      231.480164      214.073700      192.729752      225.115372   \n",
       "\n",
       "   var_194_WOENUM  var_195_WOENUM  var_196_WOENUM  var_197_WOENUM  \\\n",
       "0      215.467896      226.047195      216.054428      217.410599   \n",
       "1      216.318924      192.639618      216.054428      220.251221   \n",
       "2      225.500076      192.639618      227.813583      219.839172   \n",
       "3      227.932251      221.919235      226.820557      232.338745   \n",
       "4      199.717361      227.340057      216.584000      226.250290   \n",
       "\n",
       "   var_198_WOENUM  var_199_WOENUM  \n",
       "0      210.110870      217.902420  \n",
       "1      234.381363      220.006104  \n",
       "2      221.744202      220.006104  \n",
       "3      234.381363      220.173248  \n",
       "4      234.381363      220.173248  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_woe_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_WOENUM</th>\n",
       "      <th>var_1_WOENUM</th>\n",
       "      <th>var_2_WOENUM</th>\n",
       "      <th>var_3_WOENUM</th>\n",
       "      <th>var_4_WOENUM</th>\n",
       "      <th>var_5_WOENUM</th>\n",
       "      <th>var_6_WOENUM</th>\n",
       "      <th>var_7_WOENUM</th>\n",
       "      <th>var_8_WOENUM</th>\n",
       "      <th>var_9_WOENUM</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_WOENUM</th>\n",
       "      <th>var_191_WOENUM</th>\n",
       "      <th>var_192_WOENUM</th>\n",
       "      <th>var_193_WOENUM</th>\n",
       "      <th>var_194_WOENUM</th>\n",
       "      <th>var_195_WOENUM</th>\n",
       "      <th>var_196_WOENUM</th>\n",
       "      <th>var_197_WOENUM</th>\n",
       "      <th>var_198_WOENUM</th>\n",
       "      <th>var_199_WOENUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227.991623</td>\n",
       "      <td>178.529938</td>\n",
       "      <td>203.373917</td>\n",
       "      <td>220.229019</td>\n",
       "      <td>224.259186</td>\n",
       "      <td>222.474823</td>\n",
       "      <td>212.951935</td>\n",
       "      <td>217.617813</td>\n",
       "      <td>222.418045</td>\n",
       "      <td>235.351257</td>\n",
       "      <td>...</td>\n",
       "      <td>231.480164</td>\n",
       "      <td>179.059326</td>\n",
       "      <td>192.729752</td>\n",
       "      <td>221.964706</td>\n",
       "      <td>199.717361</td>\n",
       "      <td>192.639618</td>\n",
       "      <td>220.956253</td>\n",
       "      <td>232.338745</td>\n",
       "      <td>226.862839</td>\n",
       "      <td>220.173248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.699280</td>\n",
       "      <td>218.176483</td>\n",
       "      <td>235.507797</td>\n",
       "      <td>220.284805</td>\n",
       "      <td>217.743835</td>\n",
       "      <td>216.162384</td>\n",
       "      <td>209.927567</td>\n",
       "      <td>220.452332</td>\n",
       "      <td>231.746826</td>\n",
       "      <td>218.225815</td>\n",
       "      <td>...</td>\n",
       "      <td>172.288452</td>\n",
       "      <td>214.813934</td>\n",
       "      <td>210.454941</td>\n",
       "      <td>225.115372</td>\n",
       "      <td>216.318924</td>\n",
       "      <td>224.067657</td>\n",
       "      <td>226.820557</td>\n",
       "      <td>229.885010</td>\n",
       "      <td>232.411270</td>\n",
       "      <td>236.348328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231.241455</td>\n",
       "      <td>239.250763</td>\n",
       "      <td>236.613968</td>\n",
       "      <td>215.564178</td>\n",
       "      <td>223.261459</td>\n",
       "      <td>187.468979</td>\n",
       "      <td>236.348328</td>\n",
       "      <td>224.536530</td>\n",
       "      <td>222.418045</td>\n",
       "      <td>233.090485</td>\n",
       "      <td>...</td>\n",
       "      <td>237.498779</td>\n",
       "      <td>211.746628</td>\n",
       "      <td>226.392929</td>\n",
       "      <td>216.975037</td>\n",
       "      <td>199.717361</td>\n",
       "      <td>192.639618</td>\n",
       "      <td>227.813583</td>\n",
       "      <td>186.917999</td>\n",
       "      <td>229.901520</td>\n",
       "      <td>236.348328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230.699280</td>\n",
       "      <td>215.575348</td>\n",
       "      <td>222.650864</td>\n",
       "      <td>220.872406</td>\n",
       "      <td>222.645325</td>\n",
       "      <td>219.168137</td>\n",
       "      <td>237.317200</td>\n",
       "      <td>224.536530</td>\n",
       "      <td>218.809357</td>\n",
       "      <td>213.093216</td>\n",
       "      <td>...</td>\n",
       "      <td>172.288452</td>\n",
       "      <td>214.073700</td>\n",
       "      <td>217.301559</td>\n",
       "      <td>221.191956</td>\n",
       "      <td>216.318924</td>\n",
       "      <td>192.639618</td>\n",
       "      <td>216.584000</td>\n",
       "      <td>228.331955</td>\n",
       "      <td>210.110870</td>\n",
       "      <td>218.006409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>229.316238</td>\n",
       "      <td>218.225815</td>\n",
       "      <td>208.666183</td>\n",
       "      <td>219.223450</td>\n",
       "      <td>217.743835</td>\n",
       "      <td>226.697449</td>\n",
       "      <td>166.493988</td>\n",
       "      <td>217.138199</td>\n",
       "      <td>218.809357</td>\n",
       "      <td>220.028305</td>\n",
       "      <td>...</td>\n",
       "      <td>221.169769</td>\n",
       "      <td>214.073700</td>\n",
       "      <td>210.151154</td>\n",
       "      <td>221.964706</td>\n",
       "      <td>224.883499</td>\n",
       "      <td>224.720947</td>\n",
       "      <td>227.813583</td>\n",
       "      <td>186.917999</td>\n",
       "      <td>213.162735</td>\n",
       "      <td>220.173248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_WOENUM  var_1_WOENUM  var_2_WOENUM  var_3_WOENUM  var_4_WOENUM  \\\n",
       "0    227.991623    178.529938    203.373917    220.229019    224.259186   \n",
       "1    230.699280    218.176483    235.507797    220.284805    217.743835   \n",
       "2    231.241455    239.250763    236.613968    215.564178    223.261459   \n",
       "3    230.699280    215.575348    222.650864    220.872406    222.645325   \n",
       "4    229.316238    218.225815    208.666183    219.223450    217.743835   \n",
       "\n",
       "   var_5_WOENUM  var_6_WOENUM  var_7_WOENUM  var_8_WOENUM  var_9_WOENUM  ...  \\\n",
       "0    222.474823    212.951935    217.617813    222.418045    235.351257  ...   \n",
       "1    216.162384    209.927567    220.452332    231.746826    218.225815  ...   \n",
       "2    187.468979    236.348328    224.536530    222.418045    233.090485  ...   \n",
       "3    219.168137    237.317200    224.536530    218.809357    213.093216  ...   \n",
       "4    226.697449    166.493988    217.138199    218.809357    220.028305  ...   \n",
       "\n",
       "   var_190_WOENUM  var_191_WOENUM  var_192_WOENUM  var_193_WOENUM  \\\n",
       "0      231.480164      179.059326      192.729752      221.964706   \n",
       "1      172.288452      214.813934      210.454941      225.115372   \n",
       "2      237.498779      211.746628      226.392929      216.975037   \n",
       "3      172.288452      214.073700      217.301559      221.191956   \n",
       "4      221.169769      214.073700      210.151154      221.964706   \n",
       "\n",
       "   var_194_WOENUM  var_195_WOENUM  var_196_WOENUM  var_197_WOENUM  \\\n",
       "0      199.717361      192.639618      220.956253      232.338745   \n",
       "1      216.318924      224.067657      226.820557      229.885010   \n",
       "2      199.717361      192.639618      227.813583      186.917999   \n",
       "3      216.318924      192.639618      216.584000      228.331955   \n",
       "4      224.883499      224.720947      227.813583      186.917999   \n",
       "\n",
       "   var_198_WOENUM  var_199_WOENUM  \n",
       "0      226.862839      220.173248  \n",
       "1      232.411270      236.348328  \n",
       "2      229.901520      236.348328  \n",
       "3      210.110870      218.006409  \n",
       "4      213.162735      220.173248  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_woe_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 1.60 MB\n",
      "Memory usage after changing types 0.80 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_full_train = load_csv(os.path.join(INP_DIR, \"y_train.csv\"))\n",
    "y_full_train = y_full_train[\"target\"].values\n",
    "\n",
    "y_full_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `id_code_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 1.60 MB\n",
      "Memory usage after changing types 1.60 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200000, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_code_test = load_csv(os.path.join(INP_DIR, \"id_code_test.csv\"))\n",
    "id_code_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `LGBMClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `X_org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge train\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "shape of concatenated df (200000, 200)\n",
      "Number of nulls: 0\n",
      "after train-validatin split\n",
      "(160000, 200) (160000,) (40000, 200) (40000,)\n",
      "\n",
      "Merge test\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "shape of concatenated df (200000, 200)\n",
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Merge train\")\n",
    "\n",
    "dfs_train = [X_org_train]\n",
    "features, X_train = merge_dfs(dfs_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "print(\"after train-validatin split\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nMerge test\")\n",
    "dfs_test = [X_org_test]\n",
    "_, X_test = merge_dfs(dfs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of  the train set: 0.92498\n",
      "AUC of the validation set: 0.86636\n",
      "Time elapsed: 3.65565 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "lgbm = lgbm = LGBMClassifier(device=\"gpu\")\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "auc_train = roc_auc(lgbm, X_train, y_train)\n",
    "print(\"AUC of  the train set: %0.5f\" % auc_train)\n",
    "\n",
    "auc_val = roc_auc(lgbm, X_val, y_val)\n",
    "print(\"AUC of the validation set: %0.5f\" % auc_val)\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapse = time_end - time_start\n",
    "print(\"Time elapsed: %0.5f s\" % time_elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning using `hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [11:43<00:00,  7.03s/trial, best loss: -0.893388145431818]\n",
      "Time elapsed: 707.90110 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5731504313939707,\n",
       " 'learning_rate': 0.11792112591849245,\n",
       " 'max_depth': 7,\n",
       " 'min_child_samples': 210,\n",
       " 'num_leaves': 10,\n",
       " 'reg_lambda': 0.019709267367751634,\n",
       " 'subsample': 0.4817237141688642}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 5, 100, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 300, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "trials, best_params, best_model = run_hyperopt(lgbm, params, \n",
    "                                               X_train, y_train, X_val, y_val, \n",
    "                                               num_eval,\n",
    "                                               params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the train set: 0.93973\n",
      "AUC of the evaluation set: 0.89339\n"
     ]
    }
   ],
   "source": [
    "auc_train = roc_auc(best_model, X_train, y_train)\n",
    "print(\"AUC of the train set: %0.5f\" % auc_train)\n",
    "\n",
    "auc_val = roc_auc(best_model, X_val, y_val)\n",
    "print(\"AUC of the evaluation set: %0.5f\" % auc_val)\n",
    "\n",
    "\n",
    "best_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lgbm_org_tuned_01.csv\")\n",
    "write_submit_csv(best_model, X_test, id_code_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lgbm_org_tuned_01.pickle\")\n",
    "pickle.dump(lgbm, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `X_org` and `X_q10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge train\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 399)\n",
      "Number of nulls: 0\n",
      "after train-validatin split\n",
      "(160000, 399) (160000,) (40000, 399) (40000,)\n",
      "\n",
      "Merge test\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 399)\n",
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Merge train\")\n",
    "\n",
    "dfs_train = [X_org_train, X_q10_train]\n",
    "features, X_train = merge_dfs(dfs_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "print(\"after train-validatin split\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nMerge test\")\n",
    "dfs_test = [X_org_test, X_q10_test]\n",
    "_, X_test = merge_dfs(dfs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [16:40<00:00, 10.01s/trial, best loss: -0.8949313604296473]\n",
      "Time elapsed: 1006.87983 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.45506888874984014,\n",
       " 'learning_rate': 0.2142907257779847,\n",
       " 'max_depth': 5,\n",
       " 'min_child_samples': 30,\n",
       " 'num_leaves': 5,\n",
       " 'reg_lambda': 0.01964205870738078,\n",
       " 'subsample': 0.5955495929550342}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 5, 100, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 400, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "trials, best_params, best_model = run_hyperopt(lgbm, params, \n",
    "                                               X_train, y_train, X_val, y_val, \n",
    "                                               num_eval,\n",
    "                                               params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the train set: 0.92550\n",
      "AUC of the evaluation set: 0.89493\n"
     ]
    }
   ],
   "source": [
    "auc_train = roc_auc(best_model, X_train, y_train)\n",
    "print(\"AUC of the train set: %0.5f\" % auc_train)\n",
    "\n",
    "auc_val = roc_auc(best_model, X_val, y_val)\n",
    "print(\"AUC of the evaluation set: %0.5f\" % auc_val)\n",
    "\n",
    "\n",
    "best_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lgbm_org_q10_tuned_01.csv\")\n",
    "write_submit_csv(best_model, X_test, id_code_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lgbm_org_q10_tuned_01.pickle\")\n",
    "pickle.dump(lgbm, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `X_org` and  `X_valcount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge train\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 399)\n",
      "Number of nulls: 0\n",
      "after train-validatin split\n",
      "(160000, 399) (160000,) (40000, 399) (40000,)\n",
      "\n",
      "Merge test\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 399)\n",
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Merge train\")\n",
    "\n",
    "dfs_train = [X_org_train, X_valcount_train]\n",
    "features, X_train = merge_dfs(dfs_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "print(\"after train-validatin split\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nMerge test\")\n",
    "dfs_test = [X_org_test, X_valcount_test]\n",
    "_, X_test = merge_dfs(dfs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [35:10<00:00, 10.55s/trial, best loss: -0.8938862455371834]\n",
      "Time elapsed: 2116.44064 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6876462443291219,\n",
       " 'learning_rate': 0.2153616828802118,\n",
       " 'max_depth': 9,\n",
       " 'min_child_samples': 210,\n",
       " 'num_leaves': 5,\n",
       " 'reg_lambda': 1.3014094628213906,\n",
       " 'subsample': 0.8033241520875941}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 5, 100, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 400, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 200\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "trials, best_params, best_model = run_hyperopt(lgbm, params, \n",
    "                                               X_train, y_train, X_val, y_val, \n",
    "                                               num_eval,\n",
    "                                               params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the train set: 0.92709\n",
      "AUC of the evaluation set: 0.89389\n"
     ]
    }
   ],
   "source": [
    "auc_train = roc_auc(best_model, X_train, y_train)\n",
    "print(\"AUC of the train set: %0.5f\" % auc_train)\n",
    "\n",
    "auc_val = roc_auc(best_model, X_val, y_val)\n",
    "print(\"AUC of the evaluation set: %0.5f\" % auc_val)\n",
    "\n",
    "\n",
    "best_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lgbm_org_valcount_tuned_01.csv\")\n",
    "write_submit_csv(best_model, X_test, id_code_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lgbm_org_valcount_tuned_01.pickle\")\n",
    "pickle.dump(lgbm, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `X_org`,  `X_valcount` and `X_target_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge train\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 598)\n",
      "Number of nulls: 0\n",
      "after train-validatin split\n",
      "(160000, 598) (160000,) (40000, 598) (40000,)\n",
      "\n",
      "Merge test\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 598)\n",
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Merge train\")\n",
    "\n",
    "dfs_train = [X_org_train, X_valcount_train, X_target_mean_train]\n",
    "features, X_train = merge_dfs(dfs_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "print(\"after train-validatin split\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nMerge test\")\n",
    "dfs_test = [X_org_test, X_valcount_test, X_target_mean_test]\n",
    "_, X_test = merge_dfs(dfs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [46:13<00:00, 13.87s/trial, best loss: -0.8933248225243986]\n",
      "Time elapsed: 2784.12794 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8895404893244775,\n",
       " 'learning_rate': 0.11940750339427914,\n",
       " 'max_depth': 8,\n",
       " 'min_child_samples': 350,\n",
       " 'num_leaves': 10,\n",
       " 'reg_lambda': 0.1123393750039746,\n",
       " 'subsample': 0.9844517256389533}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 5, 100, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 400, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 200\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "trials, best_params, best_model = run_hyperopt(lgbm, params, \n",
    "                                               X_train, y_train, X_val, y_val, \n",
    "                                               num_eval,\n",
    "                                               params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the train set: 0.94304\n",
      "AUC of the evaluation set: 0.89332\n"
     ]
    }
   ],
   "source": [
    "auc_train = roc_auc(best_model, X_train, y_train)\n",
    "print(\"AUC of the train set: %0.5f\" % auc_train)\n",
    "\n",
    "auc_val = roc_auc(best_model, X_val, y_val)\n",
    "print(\"AUC of the evaluation set: %0.5f\" % auc_val)\n",
    "\n",
    "\n",
    "best_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lgbm_org_valcount_target_mean_tuned_01.csv\")\n",
    "write_submit_csv(best_model, X_test, id_code_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lgbm_org_valcount_tuned_target_mean_01.pickle\")\n",
    "pickle.dump(lgbm, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `X_org`,  `X_valcount`,  `X_target_mean` and `X_woe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge train\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "(200000, 199)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 797)\n",
      "Number of nulls: 0\n",
      "after train-validatin split\n",
      "(160000, 797) (160000,) (40000, 797) (40000,)\n",
      "\n",
      "Merge test\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 199)\n",
      "(200000, 199)\n",
      "(200000, 199)\n",
      "shape of concatenated df (200000, 797)\n",
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Merge train\")\n",
    "\n",
    "dfs_train = [X_org_train, X_valcount_train, X_target_mean_train, X_woe_train]\n",
    "features, X_train = merge_dfs(dfs_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "print(\"after train-validatin split\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nMerge test\")\n",
    "dfs_test = [X_org_test, X_valcount_test, X_target_mean_test, X_woe_test]\n",
    "_, X_test = merge_dfs(dfs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [56:29<00:00, 16.95s/trial, best loss: -0.8930499323836626] \n",
      "Time elapsed: 3401.18754 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9619837276989326,\n",
       " 'learning_rate': 0.2086694232326363,\n",
       " 'max_depth': 10,\n",
       " 'min_child_samples': 200,\n",
       " 'num_leaves': 5,\n",
       " 'reg_lambda': 0.04141993319888672,\n",
       " 'subsample': 0.5314150101983962}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 5, 100, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 400, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 200\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "trials, best_params, best_model = run_hyperopt(lgbm, params, \n",
    "                                               X_train, y_train, X_val, y_val, \n",
    "                                               num_eval,\n",
    "                                               params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the train set: 0.92802\n",
      "AUC of the evaluation set: 0.89305\n"
     ]
    }
   ],
   "source": [
    "auc_train = roc_auc(best_model, X_train, y_train)\n",
    "print(\"AUC of the train set: %0.5f\" % auc_train)\n",
    "\n",
    "auc_val = roc_auc(best_model, X_val, y_val)\n",
    "print(\"AUC of the evaluation set: %0.5f\" % auc_val)\n",
    "\n",
    "\n",
    "best_model.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "out_sub = os.path.join(SUB_DIR, \"lgbm_org_valcount_target_mean_woe_tuned_01.csv\")\n",
    "write_submit_csv(best_model, X_test, id_code_test, out_sub)\n",
    "\n",
    "out_model = os.path.join(MODELS_DIR, \"lgbm_org_valcount_tuned_target_mean_woe_01.pickle\")\n",
    "pickle.dump(lgbm, open(out_model, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `X_org` and `X_interact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 1000.00 MB\n",
      "Memory usage after changing types 500.00 MB\n",
      "Memory usage before changing types 1000.00 MB\n",
      "Memory usage after changing types 500.00 MB\n",
      "Merge train\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 625)\n",
      "shape of concatenated df (200000, 825)\n",
      "Number of nulls: 0\n",
      "after train-validatin split\n",
      "(160000, 825) (160000,) (40000, 825) (40000,)\n",
      "\n",
      "Merge test\n",
      "Shape of dfs\n",
      "(200000, 200)\n",
      "(200000, 625)\n",
      "shape of concatenated df (200000, 825)\n",
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "X_interact_train = load_csv(os.path.join(INP_DIR, \"X_interact_0_train.csv\"))\n",
    "X_interact_test = load_csv(os.path.join(INP_DIR, \"X_interact_0_test.csv\"))\n",
    "\n",
    "\n",
    "print(\"Merge train\")\n",
    "\n",
    "dfs_train = [X_org_train, X_interact_train]\n",
    "features, X_train = merge_dfs(dfs_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_full_train, test_size=0.2, \n",
    "                                                  stratify=y_full_train, random_state=21083)\n",
    "\n",
    "print(\"after train-validatin split\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nMerge test\")\n",
    "dfs_test = [X_org_test, X_interact_train]\n",
    "_, X_test = merge_dfs(dfs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [32:37<00:00, 19.58s/trial, best loss: -0.8909490139629812]\n",
      "Time elapsed: 1969.33530 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5136490874102092,\n",
       " 'learning_rate': 0.49112375034053984,\n",
       " 'max_depth': 2,\n",
       " 'min_child_samples': 40,\n",
       " 'num_leaves': 55,\n",
       " 'reg_lambda': 418.67783601550366,\n",
       " 'subsample': 0.572003252273251}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 5, 100, 5)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 10, 400, 10)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.001), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.005), np.log(1)),\n",
    "}\n",
    "\n",
    "# categorical_feature\n",
    "params_fixed = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\" ,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "trials, best_params, best_model = run_hyperopt(lgbm, params, \n",
    "                                               X_train, y_train, X_val, y_val, \n",
    "                                               num_eval,\n",
    "                                               params_fixed=params_fixed)\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
