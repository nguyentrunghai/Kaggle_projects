{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtypes(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if (df[col].dtype == \"object\") and (df[col].nunique() < df.shape[0]):\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "        elif df[col].dtype == float:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "\n",
    "        elif df[col].dtype == int:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtypes(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollinearColumnRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold, col_regex=None, exclude_cols=None):\n",
    "        \"\"\"\n",
    "        :param threshold: float in [0, 1], if two columns have correlation greater than threshold\n",
    "                          one of them will be removed\n",
    "        :param col_regex: str, regular expression to select columns\n",
    "        \"\"\"\n",
    "        self._threshold = threshold\n",
    "        self._col_regex = col_regex\n",
    "        if exclude_cols is None:\n",
    "            self._exclude_cols = []\n",
    "        else:\n",
    "            self._exclude_cols = exclude_cols\n",
    "    \n",
    "    def _collinear_columns(self, df, threshold):\n",
    "        if self._col_regex is None:\n",
    "            df_sel = df.select_dtypes([\"number\", \"bool\"])\n",
    "        else:\n",
    "            df_sel = df.filter(regex=self._col_regex)\n",
    "            df_sel = df_sel.select_dtypes([\"number\", \"bool\"])\n",
    "        \n",
    "        df_sel = df_sel.astype(\"float32\")\n",
    "        \n",
    "        all_cols = df_sel.columns.to_list()\n",
    "        all_cols = [col for col in all_cols if col not in self._exclude_cols]\n",
    "        df_sel = df_sel[all_cols]\n",
    "        ncols = len(all_cols)\n",
    "        \n",
    "        corr_mat = df_sel.corr().abs()\n",
    "        self._corr_mat = corr_mat\n",
    "        collin_cols = []\n",
    "        for i in range(ncols-1):\n",
    "            col_i = all_cols[i]\n",
    "            if col_i in collin_cols:\n",
    "                continue\n",
    "            \n",
    "            for j in range(i + 1, ncols):\n",
    "                col_j = all_cols[j]\n",
    "                if col_j in collin_cols:\n",
    "                    continue\n",
    "                \n",
    "                corr = corr_mat.loc[col_i, col_j]\n",
    "                if corr > threshold:\n",
    "                    collin_cols.append(col_j)\n",
    "        \n",
    "        collin_cols = list(set(collin_cols))\n",
    "        return collin_cols\n",
    "    \n",
    "    \n",
    "    def fit(self, df):\n",
    "        self._collin_cols = self._collinear_columns(df, self._threshold)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        all_cols = df.columns.to_list()\n",
    "        nonexist_cols = [col for col in self._collin_cols if col not in all_cols]\n",
    "        if len(nonexist_cols) > 0:\n",
    "            print(\"WARNING: These collinear cols to be droped do not exist in df:\", nonexist_cols)\n",
    "            \n",
    "        droped_col = [col for col in self._collin_cols if col in all_cols]\n",
    "        print(\"Number of columns droped due to collinearity:\", len(droped_col))\n",
    "        return df.drop(droped_col, axis=\"columns\")\n",
    "\n",
    "\n",
    "class SameCatColsRemover(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, threshold=0.99):\n",
    "        self._threshold = threshold\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        ncols = len(cols)\n",
    "        \n",
    "        self._cols_to_drop = []\n",
    "        for i in range(ncols - 1):\n",
    "            col_i = cols[i]\n",
    "            if col_i in self._cols_to_drop:\n",
    "                continue\n",
    "            \n",
    "            for j in range(i + 1, ncols):\n",
    "                col_j = cols[j]\n",
    "                if col_j in self._cols_to_drop:\n",
    "                    continue\n",
    "                \n",
    "                if (df_train[col_i].astype(\"object\") == df_train[col_j].astype(\"object\")).mean() > self._threshold:\n",
    "                    self._cols_to_drop.append(col_j)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        print(\"Number of same columns droped:\", len(self._cols_to_drop))\n",
    "        return df.drop(self._cols_to_drop, axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumColsQCuter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, labels=None, exclude_cols=None, \n",
    "                 nunique_min=1000, keep_old=True, \n",
    "                 output_type=np.int32):\n",
    "        \n",
    "        if labels is None:\n",
    "            self._labels = [1, 2, 3, 4]\n",
    "        else:\n",
    "            self._labels = list(labels)\n",
    "        self._nbins = len(self._labels)\n",
    "        assert self._isunique(self._labels), \"labels must be unique\"\n",
    "        \n",
    "        self._exclude_cols = [\"ID_code\", \"target\"]\n",
    "        if exclude_cols is not None:\n",
    "            self._exclude_cols = self._exclude_cols + list(exclude_cols)\n",
    "        \n",
    "        self._nunique_min = nunique_min\n",
    "        \n",
    "        self._suffix = \"_%dQCUT\" % len(self._labels)\n",
    "        \n",
    "        self._keep_old = keep_old\n",
    "        self._output_type = output_type\n",
    "    \n",
    "    def _isunique(self, x):\n",
    "        return len(np.unique(x)) == len(x)\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        \n",
    "        quantiles = np.linspace(0, 1, self._nbins + 1)\n",
    "        quantiles = quantiles[1: -1]\n",
    "        \n",
    "        sel_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        sel_cols = [col for col in sel_cols if col not in self._exclude_cols]\n",
    "        sel_cols = [col for col in sel_cols if df_train[col].nunique() >= self._nunique_min]\n",
    "        \n",
    "        self._bins = {}\n",
    "        for col in sel_cols:\n",
    "            #if df_train[col].isnull().any():\n",
    "            #    raise ValueError(col + \" has null values\")\n",
    "            \n",
    "            bins = df_train[col].quantile(quantiles).values\n",
    "            bins = np.array([-np.inf] + list(bins) + [np.inf])\n",
    "            \n",
    "            if self._isunique(bins):\n",
    "                self._bins[col] = bins\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        for col, bins in self._bins.items():\n",
    "            new_col_name = col + self._suffix\n",
    "            df[new_col_name] = pd.cut(df[col], bins, labels=self._labels)\n",
    "            df[new_col_name] = df[new_col_name].astype(self._output_type)\n",
    "            \n",
    "            new_cols.append(new_col_name)\n",
    "            \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]\n",
    "        \n",
    "\n",
    "class CatValueCounter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, keep_old=True, exclude_cols=None, suffix=\"_VALCOUNT\"):\n",
    "        self._keep_old = keep_old\n",
    "        self._suffix = suffix\n",
    "        \n",
    "        self._exclude_cols = [\"ID_code\", \"target\"]\n",
    "        if exclude_cols is not None:\n",
    "            self._exclude_cols = self._exclude_cols + list(exclude_cols)\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        sel_cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        sel_cols = [col for col in sel_cols if col not in self._exclude_cols]\n",
    "        \n",
    "        self._val_counts = {}\n",
    "        for col in sel_cols:\n",
    "            self._val_counts[col] = df_train[col].value_counts(normalize=True)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        for col, val_count in self._val_counts.items():\n",
    "            new_col = col + self._suffix\n",
    "            df[new_col] = df[col].map(val_count)\n",
    "            df[new_col] = df[new_col].fillna(0)\n",
    "            \n",
    "            new_cols.append(new_col)\n",
    "        \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]\n",
    "\n",
    "\n",
    "class NumValueCounter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nunique_min=1000, bins=100, keep_old=True, exclude_cols=None, suffix=\"_VALCOUNT\"):\n",
    "        self._nunique_min = nunique_min\n",
    "        self._bins = bins\n",
    "        self._keep_old = keep_old\n",
    "        self._suffix = suffix\n",
    "        \n",
    "        self._exclude_cols = [\"ID_code\", \"target\"]\n",
    "        if exclude_cols is not None:\n",
    "            self._exclude_cols = self._exclude_cols + list(exclude_cols)\n",
    "    \n",
    "    def _cal_bin_edges(self, ser):\n",
    "        val_min = ser.min()\n",
    "        val_max = ser.max()\n",
    "        \n",
    "        edges = np.linspace(val_min, val_max, self._bins + 1)\n",
    "        edges[0] = -np.inf\n",
    "        edges[-1] = np.inf\n",
    "        return edges\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        sel_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        sel_cols = [col for col in sel_cols if col not in self._exclude_cols]\n",
    "        sel_cols = [col for col in sel_cols if df_train[col].nunique() >= self._nunique_min]\n",
    "        \n",
    "        self._val_counts = {}\n",
    "        self._bin_edges = {}\n",
    "        \n",
    "        for col in sel_cols:\n",
    "            edges = self._cal_bin_edges(df_train[col])\n",
    "            self._bin_edges[col] = edges\n",
    "            \n",
    "            discrete_ser = pd.cut(df_train[col], edges, labels=list(range(self._bins)))\n",
    "            self._val_counts[col] = discrete_ser.value_counts(normalize=True)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        \n",
    "        for col, edges in self._bin_edges.items():\n",
    "            discrete_ser = pd.cut(df[col], edges, labels=list(range(self._bins)))\n",
    "            \n",
    "            val_count = self._val_counts[col]\n",
    "            new_col = col + self._suffix\n",
    "            df[new_col] = discrete_ser.map(val_count)\n",
    "            df[new_col] = df[new_col].fillna(0)\n",
    "            \n",
    "            new_cols.append(new_col)\n",
    "        \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetMeanFromNumCols(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nunique_min=1000, bins=10, keep_old=True, exclude_cols=None, suffix=\"_TARGETMEANNUM\"):\n",
    "        self._nunique_min = nunique_min\n",
    "        self._bins = bins\n",
    "        self._keep_old = keep_old\n",
    "        self._suffix = suffix\n",
    "        \n",
    "        self._exclude_cols = [\"ID_code\", \"target\"]\n",
    "        if exclude_cols is not None:\n",
    "            self._exclude_cols = self._exclude_cols + list(exclude_cols)\n",
    "    \n",
    "    def _cal_bin_edges(self, ser):\n",
    "        quantiles = np.linspace(0, 1, self._bins + 1)\n",
    "        quantiles = quantiles[1: -1]\n",
    "        \n",
    "        edges = ser.quantile(quantiles).values\n",
    "        edges = np.array([-np.inf] + list(edges) + [np.inf])\n",
    "        return edges\n",
    "    \n",
    "    def _isunique(self, x):\n",
    "        return len(np.unique(x)) == len(x)\n",
    "    \n",
    "    def fit(self, df_train, y_train):\n",
    "        assert isinstance(y_train, pd.Series)\n",
    "        assert df_train.shape[0] == y_train.shape[0]\n",
    "        assert (df_train.index == y_train.index).all()\n",
    "        \n",
    "        self._y_mean = y_train.mean()\n",
    "        \n",
    "        sel_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        sel_cols = [col for col in sel_cols if col not in self._exclude_cols]\n",
    "        sel_cols = [col for col in sel_cols if df_train[col].nunique() >= self._nunique_min]\n",
    "        \n",
    "        self._target_means = {}\n",
    "        self._bin_edges = {}\n",
    "        \n",
    "        for col in sel_cols:\n",
    "            edges = self._cal_bin_edges(df_train[col])\n",
    "            \n",
    "            if self._isunique(edges):\n",
    "                self._bin_edges[col] = edges\n",
    "                \n",
    "                bin_label = pd.cut(df_train[col], edges, labels=list(range(self._bins)))\n",
    "                tmp_df = pd.DataFrame({\"bin_label\": bin_label, \"target\": y_train})\n",
    "                \n",
    "                self._target_means[col] = tmp_df.groupby([\"bin_label\"])[\"target\"].mean()\n",
    "                self._target_means[col] = self._target_means[col].fillna(self._y_mean)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        \n",
    "        for col, edges in self._bin_edges.items():\n",
    "            bin_label = pd.cut(df[col], edges, labels=list(range(self._bins)))\n",
    "            \n",
    "            target_mean = self._target_means[col]\n",
    "            new_col = col + self._suffix\n",
    "            df[new_col] = bin_label.map(target_mean).astype(np.float32)\n",
    "            df[new_col] = df[new_col].fillna(self._y_mean)\n",
    "            \n",
    "            new_cols.append(new_col)\n",
    "        \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]\n",
    "\n",
    "\n",
    "class WeightOfEvidenceNum(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nunique_min=1000, bins=10, keep_old=True, exclude_cols=None, suffix=\"_WOENUM\"):\n",
    "        self._nunique_min = nunique_min\n",
    "        self._bins = bins\n",
    "        self._keep_old = keep_old\n",
    "        self._suffix = suffix\n",
    "        \n",
    "        self._exclude_cols = [\"ID_code\", \"target\"]\n",
    "        if exclude_cols is not None:\n",
    "            self._exclude_cols = self._exclude_cols + list(exclude_cols)\n",
    "    \n",
    "    def _cal_bin_edges(self, ser):\n",
    "        quantiles = np.linspace(0, 1, self._bins + 1)\n",
    "        quantiles = quantiles[1: -1]\n",
    "        \n",
    "        edges = ser.quantile(quantiles).values\n",
    "        edges = np.array([-np.inf] + list(edges) + [np.inf])\n",
    "        return edges\n",
    "    \n",
    "    def _isunique(self, x):\n",
    "        return len(np.unique(x)) == len(x)\n",
    "    \n",
    "    def fit(self, df_train, y_train):\n",
    "        assert isinstance(y_train, pd.Series)\n",
    "        assert df_train.shape[0] == y_train.shape[0]\n",
    "        assert (df_train.index == y_train.index).all()\n",
    "        \n",
    "        sel_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        sel_cols = [col for col in sel_cols if col not in self._exclude_cols]\n",
    "        sel_cols = [col for col in sel_cols if df_train[col].nunique() >= self._nunique_min]\n",
    "        \n",
    "        self._woes = {}\n",
    "        self._bin_edges = {}\n",
    "        \n",
    "        for col in sel_cols:\n",
    "            edges = self._cal_bin_edges(df_train[col])\n",
    "            \n",
    "            if self._isunique(edges):\n",
    "                self._bin_edges[col] = edges\n",
    "                \n",
    "                bin_label = pd.cut(df_train[col], edges, labels=list(range(self._bins)))\n",
    "                tmp_df = pd.DataFrame({\"bin_label\": bin_label, \"target\": y_train})\n",
    "                \n",
    "                bad_dist = tmp_df.groupby([\"bin_label\"])[\"target\"].mean()\n",
    "                good_dist = 1. - bad_dist\n",
    "                \n",
    "                woe = np.log(good_dist / bad_dist) * 100\n",
    "                woe = woe.fillna(0.)\n",
    "                woe_min = woe.replace(-np.inf, np.nan).min() / 100.\n",
    "                woe_max = woe.replace(np.inf, np.nan).max() * 100.\n",
    "                \n",
    "                woe = woe.replace(-np.inf, woe_min)\n",
    "                woe = woe.replace(np.inf, woe_max)\n",
    "                self._woes[col] = woe\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        \n",
    "        for col, edges in self._bin_edges.items():\n",
    "            bin_label = pd.cut(df[col], edges, labels=list(range(self._bins)))\n",
    "            \n",
    "            woe = self._woes[col]\n",
    "            new_col = col + self._suffix\n",
    "            df[new_col] = bin_label.map(woe).astype(np.float32)\n",
    "            df[new_col] = df[new_col].fillna(0.)\n",
    "            \n",
    "            new_cols.append(new_col)\n",
    "        \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_random_disjoint_subsets(x, subset_size, randomstate=None):\n",
    "    assert subset_size <= len(x) // 2\n",
    "    rndstate = np.random.RandomState(randomstate)\n",
    "    rndstate.shuffle(x)\n",
    "    return x[:subset_size], x[-subset_size:]\n",
    "\n",
    "\n",
    "class RandomInteractColsExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset_size=15, keep_old=True, randomstate=None):\n",
    "        self._subset_size = subset_size\n",
    "        self._keep_old = keep_old\n",
    "        self._randomstate = randomstate\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        cols = df_train.columns.to_list()\n",
    "        self._sel_cols = two_random_disjoint_subsets(cols, self._subset_size, randomstate=self._randomstate)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        new_cols = []\n",
    "        \n",
    "        cols_1, cols_2 = self._sel_cols\n",
    "        for c1 in cols_1:\n",
    "            for c2 in cols_2:\n",
    "                new_col = c1 + \"_\" + c2 + \"_INTERACT\"\n",
    "                new_cols.append(new_col)\n",
    "                \n",
    "                df[new_col] = df[c1] * df[c2]\n",
    "        \n",
    "        if self._keep_old:\n",
    "            return df\n",
    "        else:\n",
    "            return df[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/download\"\n",
    "OUT_DIR = \"data/data_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 323.20 MB\n",
      "Memory usage after changing types 162.40 MB\n",
      "Memory usage before changing types 321.60 MB\n",
      "Memory usage after changing types 161.60 MB\n",
      "df_train.shape (200000, 202)\n",
      "df_test.shape (200000, 201)\n"
     ]
    }
   ],
   "source": [
    "df_train = load_csv(os.path.join(INP_DIR, \"train.csv\"))\n",
    "df_test = load_csv(os.path.join(INP_DIR, \"test.csv\"))\n",
    "\n",
    "print(\"df_train.shape\", df_train.shape)\n",
    "print(\"df_test.shape\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.522699</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.780300</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.430500</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.356001</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.604200</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.722200</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.034700</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.969700</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.287600</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.997400</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193    var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.522699  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.430500   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.604200   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.034700  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.287600  -1.5121   \n",
       "\n",
       "   var_196  var_197    var_198  var_199  \n",
       "0   7.8784   8.5635  12.780300  -1.0914  \n",
       "1   8.1267   8.7889  18.356001   1.9518  \n",
       "2  -6.5213   8.2675  14.722200   0.3965  \n",
       "3  -2.9275  10.2922  17.969700  -8.9996  \n",
       "4   3.9267   9.5031  17.997400  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_org_train = df_train.drop([\"ID_code\", \"target\"], axis=\"columns\")\n",
    "y_train = df_train[[\"target\"]]\n",
    "\n",
    "X_org_train.to_csv(os.path.join(OUT_DIR, \"X_org_train.csv\"), index=False)\n",
    "y_train.to_csv(os.path.join(OUT_DIR, \"y_train.csv\"), index=False)\n",
    "\n",
    "\n",
    "X_org_test = df_test.drop([\"ID_code\"], axis=\"columns\")\n",
    "id_code_test = df_test[[\"ID_code\"]]\n",
    "\n",
    "X_org_test.to_csv(os.path.join(OUT_DIR, \"X_org_test.csv\"), index=False)\n",
    "id_code_test.to_csv(os.path.join(OUT_DIR, \"id_code_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate quintile columns by bining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_q10_train.shape (200000, 199)\n",
      "X_q10_test.shape (200000, 199)\n",
      "Number of columns droped due to collinearity: 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "X_q10_train.shape (200000, 199)\n",
      "X_q10_test.shape (200000, 199)\n"
     ]
    }
   ],
   "source": [
    "qs = [i for i in range(1, 11)]\n",
    "\n",
    "numcolsqcuter = NumColsQCuter(labels=qs, keep_old=False, output_type=np.int32)\n",
    "numcolsqcuter.fit(X_org_train)\n",
    "X_q10_train = numcolsqcuter.transform(X_org_train)\n",
    "X_q10_test = numcolsqcuter.transform(X_org_test)\n",
    "\n",
    "print(\"X_q10_train.shape\", X_q10_train.shape)\n",
    "print(\"X_q10_test.shape\", X_q10_test.shape)\n",
    "\n",
    "\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(X_q10_train)\n",
    "X_q10_train = remover.transform(X_q10_train)\n",
    "X_q10_test = remover.transform(X_q10_test)\n",
    "print(\"X_q10_train.shape\", X_q10_train.shape)\n",
    "print(\"X_q10_test.shape\", X_q10_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_10QCUT</th>\n",
       "      <th>var_1_10QCUT</th>\n",
       "      <th>var_2_10QCUT</th>\n",
       "      <th>var_3_10QCUT</th>\n",
       "      <th>var_4_10QCUT</th>\n",
       "      <th>var_5_10QCUT</th>\n",
       "      <th>var_6_10QCUT</th>\n",
       "      <th>var_7_10QCUT</th>\n",
       "      <th>var_8_10QCUT</th>\n",
       "      <th>var_9_10QCUT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_10QCUT</th>\n",
       "      <th>var_191_10QCUT</th>\n",
       "      <th>var_192_10QCUT</th>\n",
       "      <th>var_193_10QCUT</th>\n",
       "      <th>var_194_10QCUT</th>\n",
       "      <th>var_195_10QCUT</th>\n",
       "      <th>var_196_10QCUT</th>\n",
       "      <th>var_197_10QCUT</th>\n",
       "      <th>var_198_10QCUT</th>\n",
       "      <th>var_199_10QCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_10QCUT  var_1_10QCUT  var_2_10QCUT  var_3_10QCUT  var_4_10QCUT  \\\n",
       "0             4             2             7             3             6   \n",
       "1             7             3             9             3             8   \n",
       "2             3             5             7             7             4   \n",
       "3             6             5             3             6             9   \n",
       "4             5             6             8             5             8   \n",
       "\n",
       "   var_5_10QCUT  var_6_10QCUT  var_7_10QCUT  var_8_10QCUT  var_9_10QCUT  ...  \\\n",
       "0             4             4             8             1             1  ...   \n",
       "1            10             6             6             8             7  ...   \n",
       "2             4            10             4             1             2  ...   \n",
       "3             7             7             4             1             7  ...   \n",
       "4             9             8             8            10             6  ...   \n",
       "\n",
       "   var_190_10QCUT  var_191_10QCUT  var_192_10QCUT  var_193_10QCUT  \\\n",
       "0               7               2               8               4   \n",
       "1               9               6               7              10   \n",
       "2               5               8               5               4   \n",
       "3               7               3               3               4   \n",
       "4               2               8               1              10   \n",
       "\n",
       "   var_194_10QCUT  var_195_10QCUT  var_196_10QCUT  var_197_10QCUT  \\\n",
       "0               6               1               9               4   \n",
       "1               3              10               9               5   \n",
       "2               9              10               1               3   \n",
       "3              10               3               3              10   \n",
       "4               1               2               6               8   \n",
       "\n",
       "   var_198_10QCUT  var_199_10QCUT  \n",
       "0               2               6  \n",
       "1               8               7  \n",
       "2               4               7  \n",
       "3               8               4  \n",
       "4               8               4  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q10_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_10QCUT</th>\n",
       "      <th>var_1_10QCUT</th>\n",
       "      <th>var_2_10QCUT</th>\n",
       "      <th>var_3_10QCUT</th>\n",
       "      <th>var_4_10QCUT</th>\n",
       "      <th>var_5_10QCUT</th>\n",
       "      <th>var_6_10QCUT</th>\n",
       "      <th>var_7_10QCUT</th>\n",
       "      <th>var_8_10QCUT</th>\n",
       "      <th>var_9_10QCUT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_10QCUT</th>\n",
       "      <th>var_191_10QCUT</th>\n",
       "      <th>var_192_10QCUT</th>\n",
       "      <th>var_193_10QCUT</th>\n",
       "      <th>var_194_10QCUT</th>\n",
       "      <th>var_195_10QCUT</th>\n",
       "      <th>var_196_10QCUT</th>\n",
       "      <th>var_197_10QCUT</th>\n",
       "      <th>var_198_10QCUT</th>\n",
       "      <th>var_199_10QCUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_10QCUT  var_1_10QCUT  var_2_10QCUT  var_3_10QCUT  var_4_10QCUT  \\\n",
       "0             6            10             8             9             6   \n",
       "1             3             8             6             3             2   \n",
       "2             1             1             5             6             4   \n",
       "3             3             6             7             5             1   \n",
       "4             7             7             9             7             2   \n",
       "\n",
       "   var_5_10QCUT  var_6_10QCUT  var_7_10QCUT  var_8_10QCUT  var_9_10QCUT  ...  \\\n",
       "0             7             7             7             7             9  ...   \n",
       "1             6             8             8             1             2  ...   \n",
       "2            10             3             9             7             7  ...   \n",
       "3             9             4             9             8             5  ...   \n",
       "4             4            10             1             8             4  ...   \n",
       "\n",
       "   var_190_10QCUT  var_191_10QCUT  var_192_10QCUT  var_193_10QCUT  \\\n",
       "0               2              10               1               5   \n",
       "1              10               7               3              10   \n",
       "2               3               9               6               4   \n",
       "3              10               8               5               6   \n",
       "4               6               8               4               5   \n",
       "\n",
       "   var_194_10QCUT  var_195_10QCUT  var_196_10QCUT  var_197_10QCUT  \\\n",
       "0               1              10               7              10   \n",
       "1               3               7               3               9   \n",
       "2               1              10               1               1   \n",
       "3               3              10               6               7   \n",
       "4               7               5               1               1   \n",
       "\n",
       "   var_198_10QCUT  var_199_10QCUT  \n",
       "0               5               4  \n",
       "1               9               1  \n",
       "2              10               1  \n",
       "3               2               5  \n",
       "4               3               4  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_q10_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q10_train.to_csv(os.path.join(OUT_DIR, \"X_q10_train.csv\"), index=False)\n",
    "X_q10_test.to_csv(os.path.join(OUT_DIR, \"X_q10_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate value count columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valcount_train.shape (200000, 199)\n",
      "X_valcount_test.shape (200000, 199)\n",
      "X_valcount_train.isnull().sum().sum() 0\n",
      "X_valcount_test.isnull().sum().sum() 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "X_valcount_train.shape (200000, 199)\n",
      "X_valcount_test.shape (200000, 199)\n"
     ]
    }
   ],
   "source": [
    "value_counter = NumValueCounter(keep_old=False)\n",
    "value_counter.fit(X_org_train)\n",
    "\n",
    "X_valcount_train = value_counter.transform(X_org_train)\n",
    "X_valcount_test = value_counter.transform(X_org_test)\n",
    "\n",
    "print(\"X_valcount_train.shape\", X_valcount_train.shape)\n",
    "print(\"X_valcount_test.shape\", X_valcount_test.shape)\n",
    "print(\"X_valcount_train.isnull().sum().sum()\", X_valcount_train.isnull().sum().sum())\n",
    "print(\"X_valcount_test.isnull().sum().sum()\", X_valcount_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(X_valcount_train)\n",
    "X_valcount_train = remover.transform(X_valcount_train)\n",
    "X_valcount_test = remover.transform(X_valcount_test)\n",
    "print(\"X_valcount_train.shape\", X_valcount_train.shape)\n",
    "print(\"X_valcount_test.shape\", X_valcount_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_VALCOUNT</th>\n",
       "      <th>var_1_VALCOUNT</th>\n",
       "      <th>var_2_VALCOUNT</th>\n",
       "      <th>var_3_VALCOUNT</th>\n",
       "      <th>var_4_VALCOUNT</th>\n",
       "      <th>var_5_VALCOUNT</th>\n",
       "      <th>var_6_VALCOUNT</th>\n",
       "      <th>var_7_VALCOUNT</th>\n",
       "      <th>var_8_VALCOUNT</th>\n",
       "      <th>var_9_VALCOUNT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_VALCOUNT</th>\n",
       "      <th>var_191_VALCOUNT</th>\n",
       "      <th>var_192_VALCOUNT</th>\n",
       "      <th>var_193_VALCOUNT</th>\n",
       "      <th>var_194_VALCOUNT</th>\n",
       "      <th>var_195_VALCOUNT</th>\n",
       "      <th>var_196_VALCOUNT</th>\n",
       "      <th>var_197_VALCOUNT</th>\n",
       "      <th>var_198_VALCOUNT</th>\n",
       "      <th>var_199_VALCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.017310</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.018030</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022535</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018230</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>0.023465</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>0.023160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023055</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026610</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.015245</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.022425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.021585</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.022655</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.017435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.025925</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.022360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>0.019985</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_VALCOUNT  var_1_VALCOUNT  var_2_VALCOUNT  var_3_VALCOUNT  \\\n",
       "0        0.023180        0.014420        0.020180        0.018425   \n",
       "1        0.022535        0.018725        0.011875        0.019795   \n",
       "2        0.023055        0.021240        0.020710        0.022340   \n",
       "3        0.023185        0.021860        0.023130        0.022530   \n",
       "4        0.025325        0.021790        0.017820        0.021800   \n",
       "\n",
       "   var_4_VALCOUNT  var_5_VALCOUNT  var_6_VALCOUNT  var_7_VALCOUNT  \\\n",
       "0        0.025530        0.018470        0.025020        0.020355   \n",
       "1        0.022620        0.007615        0.023985        0.021825   \n",
       "2        0.024285        0.019355        0.005935        0.022510   \n",
       "3        0.020200        0.021585        0.024920        0.022655   \n",
       "4        0.022620        0.019950        0.024220        0.018585   \n",
       "\n",
       "   var_8_VALCOUNT  var_9_VALCOUNT  ...  var_190_VALCOUNT  var_191_VALCOUNT  \\\n",
       "0        0.010525        0.009340  ...          0.027125          0.017310   \n",
       "1        0.020770        0.016915  ...          0.018230          0.022005   \n",
       "2        0.010525        0.011855  ...          0.026610          0.018380   \n",
       "3        0.005750        0.017435  ...          0.026240          0.020190   \n",
       "4        0.005105        0.022360  ...          0.018440          0.021150   \n",
       "\n",
       "   var_192_VALCOUNT  var_193_VALCOUNT  var_194_VALCOUNT  var_195_VALCOUNT  \\\n",
       "0          0.023575          0.026110          0.020655          0.008920   \n",
       "1          0.027595          0.004885          0.020115          0.007790   \n",
       "2          0.032310          0.026110          0.015245          0.005835   \n",
       "3          0.024865          0.025925          0.009340          0.020320   \n",
       "4          0.012755          0.012100          0.008540          0.019105   \n",
       "\n",
       "   var_196_VALCOUNT  var_197_VALCOUNT  var_198_VALCOUNT  var_199_VALCOUNT  \n",
       "0          0.018030          0.025010          0.014545          0.021400  \n",
       "1          0.017220          0.023465          0.020685          0.023160  \n",
       "2          0.009335          0.022070          0.024330          0.022425  \n",
       "3          0.016410          0.010905          0.020300          0.019065  \n",
       "4          0.019310          0.019985          0.020300          0.019065  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valcount_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0_VALCOUNT</th>\n",
       "      <th>var_1_VALCOUNT</th>\n",
       "      <th>var_2_VALCOUNT</th>\n",
       "      <th>var_3_VALCOUNT</th>\n",
       "      <th>var_4_VALCOUNT</th>\n",
       "      <th>var_5_VALCOUNT</th>\n",
       "      <th>var_6_VALCOUNT</th>\n",
       "      <th>var_7_VALCOUNT</th>\n",
       "      <th>var_8_VALCOUNT</th>\n",
       "      <th>var_9_VALCOUNT</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_VALCOUNT</th>\n",
       "      <th>var_191_VALCOUNT</th>\n",
       "      <th>var_192_VALCOUNT</th>\n",
       "      <th>var_193_VALCOUNT</th>\n",
       "      <th>var_194_VALCOUNT</th>\n",
       "      <th>var_195_VALCOUNT</th>\n",
       "      <th>var_196_VALCOUNT</th>\n",
       "      <th>var_197_VALCOUNT</th>\n",
       "      <th>var_198_VALCOUNT</th>\n",
       "      <th>var_199_VALCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.019705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015905</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.02347</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.016955</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.01703</td>\n",
       "      <td>0.008395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.023045</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>0.020705</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.01307</td>\n",
       "      <td>0.005505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.018980</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.01613</td>\n",
       "      <td>0.021035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022170</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.017970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.02091</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_0_VALCOUNT  var_1_VALCOUNT  var_2_VALCOUNT  var_3_VALCOUNT  \\\n",
       "0        0.023185        0.002985        0.017820        0.013280   \n",
       "1        0.022580        0.019700        0.020070        0.019175   \n",
       "2        0.006135        0.002035        0.023045        0.022010   \n",
       "3        0.022580        0.021790        0.020710        0.021800   \n",
       "4        0.022170        0.021175        0.011185        0.022225   \n",
       "\n",
       "   var_4_VALCOUNT  var_5_VALCOUNT  var_6_VALCOUNT  var_7_VALCOUNT  \\\n",
       "0        0.025870        0.021110        0.024920        0.021170   \n",
       "1        0.016155        0.020885        0.021290        0.020355   \n",
       "2        0.022120        0.003415        0.024355        0.016390   \n",
       "3        0.013615        0.018980        0.024275        0.014890   \n",
       "4        0.015815        0.019140        0.007030        0.007215   \n",
       "\n",
       "   var_8_VALCOUNT  var_9_VALCOUNT  ...  var_190_VALCOUNT  var_191_VALCOUNT  \\\n",
       "0        0.021070        0.019705  ...          0.015905          0.009195   \n",
       "1        0.012380        0.011855  ...          0.008525          0.023730   \n",
       "2        0.020705        0.018530  ...          0.021340          0.012415   \n",
       "3        0.019230        0.017765  ...          0.011155          0.023625   \n",
       "4        0.020765        0.017970  ...          0.027125          0.022430   \n",
       "\n",
       "   var_192_VALCOUNT  var_193_VALCOUNT  var_194_VALCOUNT  var_195_VALCOUNT  \\\n",
       "0          0.001740          0.027500          0.011735          0.004765   \n",
       "1          0.025480          0.008020          0.020115          0.024435   \n",
       "2          0.031905          0.027055          0.007435          0.006640   \n",
       "3          0.032310          0.027710          0.018975          0.005835   \n",
       "4          0.029515          0.028070          0.019650          0.024640   \n",
       "\n",
       "   var_196_VALCOUNT  var_197_VALCOUNT  var_198_VALCOUNT  var_199_VALCOUNT  \n",
       "0          0.019855          0.004135           0.02347          0.019065  \n",
       "1          0.016955          0.017140           0.01703          0.008395  \n",
       "2          0.006805          0.004040           0.01307          0.005505  \n",
       "3          0.019310          0.021705           0.01613          0.021035  \n",
       "4          0.012420          0.004870           0.02091          0.019065  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valcount_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valcount_train.to_csv(os.path.join(OUT_DIR, \"X_valcount_train.csv\"), index=False)\n",
    "X_valcount_test.to_csv(os.path.join(OUT_DIR, \"X_valcount_test.csv\"), index=False)\n",
    "del X_valcount_train, X_valcount_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate mean target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_target_mean_train.shape (200000, 199)\n",
      "X_target_mean_test.shape (200000, 199)\n",
      "X_target_mean_train.isnull().sum().sum() 0\n",
      "X_test_mean_train.isnull().sum().sum() 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "X_target_mean_train.shape (200000, 199)\n",
      "X_target_mean_test.shape (200000, 199)\n"
     ]
    }
   ],
   "source": [
    "target_mean = TargetMeanFromNumCols(keep_old=False)\n",
    "target_mean.fit(X_org_train, y_train[\"target\"])\n",
    "X_target_mean_train = target_mean.transform(X_org_train)\n",
    "X_target_mean_test = target_mean.transform(X_org_test)\n",
    "\n",
    "print(\"X_target_mean_train.shape\", X_target_mean_train.shape)\n",
    "print(\"X_target_mean_test.shape\", X_target_mean_test.shape)\n",
    "print(\"X_target_mean_train.isnull().sum().sum()\", X_target_mean_train.isnull().sum().sum())\n",
    "print(\"X_test_mean_train.isnull().sum().sum()\", X_target_mean_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(X_target_mean_train)\n",
    "X_target_mean_train = remover.transform(X_target_mean_train)\n",
    "X_target_mean_test = remover.transform(X_target_mean_test)\n",
    "print(\"X_target_mean_train.shape\", X_target_mean_train.shape)\n",
    "print(\"X_target_mean_test.shape\", X_target_mean_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target_mean_train.to_csv(os.path.join(OUT_DIR, \"X_target_mean_train.csv\"), index=False)\n",
    "X_target_mean_test.to_csv(os.path.join(OUT_DIR, \"X_target_mean_test.csv\"), index=False)\n",
    "del X_target_mean_train, X_target_mean_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Weight of Evidence columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_woe_train.shape (200000, 199)\n",
      "X_woe_test.shape (200000, 199)\n",
      "X_woe_train.isnull().sum().sum() 0\n",
      "X_woe_test.isnull().sum().sum() 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "Number of columns droped due to collinearity: 0\n",
      "X_woe_train.shape (200000, 199)\n",
      "X_woe_test.shape (200000, 199)\n"
     ]
    }
   ],
   "source": [
    "woe = WeightOfEvidenceNum(keep_old=False)\n",
    "woe.fit(X_org_train, y_train[\"target\"])\n",
    "X_woe_train = woe.transform(X_org_train)\n",
    "X_woe_test = woe.transform(X_org_test)\n",
    "\n",
    "print(\"X_woe_train.shape\", X_woe_train.shape)\n",
    "print(\"X_woe_test.shape\", X_woe_test.shape)\n",
    "print(\"X_woe_train.isnull().sum().sum()\", X_woe_train.isnull().sum().sum())\n",
    "print(\"X_woe_test.isnull().sum().sum()\", X_woe_test.isnull().sum().sum())\n",
    "\n",
    "\n",
    "remover = CollinearColumnRemover(0.95)\n",
    "remover.fit(X_woe_train)\n",
    "X_woe_train = remover.transform(X_woe_train)\n",
    "X_woe_test = remover.transform(X_woe_test)\n",
    "print(\"X_woe_train.shape\", X_woe_train.shape)\n",
    "print(\"X_woe_test.shape\", X_woe_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_woe_train.to_csv(os.path.join(OUT_DIR, \"X_woe_train.csv\"), index=False)\n",
    "X_woe_test.to_csv(os.path.join(OUT_DIR, \"X_woe_test.csv\"), index=False)\n",
    "del X_woe_train, X_woe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract interaction columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_0_train.csv and data/data_/X_interact_0_test.csv\n",
      "\n",
      "1\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_1_train.csv and data/data_/X_interact_1_test.csv\n",
      "\n",
      "2\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_2_train.csv and data/data_/X_interact_2_test.csv\n",
      "\n",
      "3\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_3_train.csv and data/data_/X_interact_3_test.csv\n",
      "\n",
      "4\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_4_train.csv and data/data_/X_interact_4_test.csv\n",
      "\n",
      "5\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_5_train.csv and data/data_/X_interact_5_test.csv\n",
      "\n",
      "6\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_6_train.csv and data/data_/X_interact_6_test.csv\n",
      "\n",
      "7\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_7_train.csv and data/data_/X_interact_7_test.csv\n",
      "\n",
      "8\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_8_train.csv and data/data_/X_interact_8_test.csv\n",
      "\n",
      "9\n",
      "X_interact_train.shape: (200000, 625)\n",
      "X_interact_test.shape: (200000, 625)\n",
      "X_interact_train.isnull().sum().sum(): 0\n",
      "X_interact_test.isnull().sum().sum(): 0\n",
      "Saving to: data/data_/X_interact_9_train.csv and data/data_/X_interact_9_test.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repeats = 10\n",
    "\n",
    "for i in range(repeats):\n",
    "    print(i)\n",
    "    inter_cols = RandomInteractColsExtractor(subset_size=25, keep_old=False)\n",
    "    inter_cols.fit(X_org_train)\n",
    "    \n",
    "    X_interact_train = inter_cols.transform(X_org_train)\n",
    "    X_interact_test = inter_cols.transform(X_org_test)\n",
    "    \n",
    "    print(\"X_interact_train.shape:\", X_interact_train.shape)\n",
    "    print(\"X_interact_test.shape:\", X_interact_test.shape)\n",
    "    print(\"X_interact_train.isnull().sum().sum():\", X_interact_train.isnull().sum().sum())\n",
    "    print(\"X_interact_test.isnull().sum().sum():\", X_interact_test.isnull().sum().sum())\n",
    "    \n",
    "    out_train = os.path.join(OUT_DIR, \"X_interact_%d_train.csv\"%i)\n",
    "    out_test = os.path.join(OUT_DIR, \"X_interact_%d_test.csv\"%i)\n",
    "    print(\"Saving to: \" + out_train + \" and \" + out_test)\n",
    "    \n",
    "    X_interact_train.to_csv(out_train, index=False)\n",
    "    X_interact_test.to_csv(out_test, index=False)\n",
    "    \n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
