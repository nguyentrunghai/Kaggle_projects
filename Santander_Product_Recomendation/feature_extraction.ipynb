{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_ser(ser):\n",
    "    \n",
    "    if ser.dtype == int:\n",
    "        return ser.astype(np.int32)\n",
    "    \n",
    "    if ser.dtype == float:\n",
    "        return ser.astype(np.float32)\n",
    "    \n",
    "    if ser.dtype == np.object:\n",
    "        return ser.astype(\"category\")\n",
    "    \n",
    "    return ser\n",
    "    \n",
    "\n",
    "def change_dtype_df(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"])\n",
    "    df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"])\n",
    "    \n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = change_dtype_ser(df[col])\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtype_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/data_/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/anaconda3-2020.02/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 6946.48 MB\n",
      "Memory usage after changing types 3302.66 MB\n",
      "Memory usage before changing types 116.20 MB\n",
      "Memory usage after changing types 49.28 MB\n"
     ]
    }
   ],
   "source": [
    "df_train = load_csv(os.path.join(INP_DIR, \"train_cleaned.csv\"))\n",
    "df_test = load_csv(os.path.join(INP_DIR, \"test_cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop this column becuase it is too imbalanced\n",
    "df_train = df_train.drop([\"ind_empleado\"], axis=1)\n",
    "df_test = df_test.drop([\"ind_empleado\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days from when the data is recorded \n",
    "df_train[\"fecha_alta\"] = (df_train[\"fecha_alta\"] - df_train[\"fecha_dato\"]).dt.days\n",
    "df_test[\"fecha_alta\"] = (df_test[\"fecha_alta\"] - df_test[\"fecha_dato\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum(), df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13647309, 67), (929615, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'pais_residencia', 'sexo', 'age',\n",
       "       'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall',\n",
       "       'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1',\n",
       "       'ind_ahor_fin_ult1_NEW_PUR', 'ind_aval_fin_ult1_NEW_PUR',\n",
       "       'ind_cco_fin_ult1_NEW_PUR', 'ind_cder_fin_ult1_NEW_PUR',\n",
       "       'ind_cno_fin_ult1_NEW_PUR', 'ind_ctju_fin_ult1_NEW_PUR',\n",
       "       'ind_ctma_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR',\n",
       "       'ind_ctpp_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR',\n",
       "       'ind_deme_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR',\n",
       "       'ind_ecue_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR',\n",
       "       'ind_hip_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR',\n",
       "       'ind_pres_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR',\n",
       "       'ind_tjcr_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR',\n",
       "       'ind_viv_fin_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR',\n",
       "       'ind_nom_pens_ult1_NEW_PUR', 'ind_recibo_ult1_NEW_PUR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'pais_residencia', 'sexo', 'age',\n",
       "       'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall',\n",
       "       'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n"
     ]
    }
   ],
   "source": [
    "PROD_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1$\", col)]\n",
    "print(PROD_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1_NEW_PUR', 'ind_aval_fin_ult1_NEW_PUR', 'ind_cco_fin_ult1_NEW_PUR', 'ind_cder_fin_ult1_NEW_PUR', 'ind_cno_fin_ult1_NEW_PUR', 'ind_ctju_fin_ult1_NEW_PUR', 'ind_ctma_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR', 'ind_ctpp_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR', 'ind_deme_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR', 'ind_ecue_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR', 'ind_hip_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR', 'ind_pres_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR', 'ind_tjcr_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR', 'ind_viv_fin_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR', 'ind_nom_pens_ult1_NEW_PUR', 'ind_recibo_ult1_NEW_PUR'] \n",
      "\n",
      "ind_recibo_ult1_NEW_PUR      27.197280\n",
      "ind_nom_pens_ult1_NEW_PUR    15.048197\n",
      "ind_nomina_ult1_NEW_PUR      13.101134\n",
      "ind_cco_fin_ult1_NEW_PUR     12.426018\n",
      "ind_tjcr_fin_ult1_NEW_PUR    12.304237\n",
      "ind_cno_fin_ult1_NEW_PUR      6.601516\n",
      "ind_ecue_fin_ult1_NEW_PUR     4.682679\n",
      "ind_dela_fin_ult1_NEW_PUR     2.255774\n",
      "ind_reca_fin_ult1_NEW_PUR     1.639950\n",
      "ind_ctma_fin_ult1_NEW_PUR     1.243010\n",
      "ind_valo_fin_ult1_NEW_PUR     0.860982\n",
      "ind_ctop_fin_ult1_NEW_PUR     0.689141\n",
      "ind_fond_fin_ult1_NEW_PUR     0.656654\n",
      "ind_deco_fin_ult1_NEW_PUR     0.545703\n",
      "ind_ctpp_fin_ult1_NEW_PUR     0.429604\n",
      "ind_plan_fin_ult1_NEW_PUR     0.109709\n",
      "ind_ctju_fin_ult1_NEW_PUR     0.086986\n",
      "ind_deme_fin_ult1_NEW_PUR     0.044381\n",
      "ind_pres_fin_ult1_NEW_PUR     0.026096\n",
      "ind_cder_fin_ult1_NEW_PUR     0.024143\n",
      "ind_hip_fin_ult1_NEW_PUR      0.013314\n",
      "ind_viv_fin_ult1_NEW_PUR      0.012427\n",
      "ind_aval_fin_ult1_NEW_PUR     0.000710\n",
      "ind_ahor_fin_ult1_NEW_PUR     0.000355\n",
      "dtype: float64 \n",
      "\n",
      "['ind_recibo_ult1_NEW_PUR', 'ind_nom_pens_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR', 'ind_cco_fin_ult1_NEW_PUR', 'ind_tjcr_fin_ult1_NEW_PUR', 'ind_cno_fin_ult1_NEW_PUR', 'ind_ecue_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR', 'ind_ctma_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR', 'ind_ctpp_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR']\n"
     ]
    }
   ],
   "source": [
    "NEW_PURCH_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1_NEW_PUR$\", col)]\n",
    "print(NEW_PURCH_COLS, \"\\n\")\n",
    "\n",
    "prod_popul = df_train[NEW_PURCH_COLS].sum(axis=0)\n",
    "prod_popul = prod_popul.sort_values(ascending=False)/prod_popul.sum() * 100\n",
    "print(prod_popul, \"\\n\")\n",
    "\n",
    "SIXTEEN_MOST_POP_PROD = prod_popul.sort_values(ascending=False).index[:16].to_list()\n",
    "print(SIXTEEN_MOST_POP_PROD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pais_residencia', 'sexo', 'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall', 'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento']\n"
     ]
    }
   ],
   "source": [
    "DEMOG_COLS = [col for col in df_train.columns \n",
    "              if col not in PROD_COLS + NEW_PURCH_COLS + [\"fecha_dato\", \"ncodpers\"]]\n",
    "print(DEMOG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_unique(x):\n",
    "    return len(x) == x.nunique()\n",
    "\n",
    "\n",
    "def extract_subset(df, row_filter, cols):\n",
    "    df = df.copy()\n",
    "    return df.loc[row_filter, cols]\n",
    "\n",
    "\n",
    "def extract_y(df, timestamp, y_cols=SIXTEEN_MOST_POP_PROD):\n",
    "    # only use row when customer buys exactly one product\n",
    "    any_new_pur = df[y_cols].sum(axis=1) == 1\n",
    "    row_filter = (df[\"fecha_dato\"] == timestamp) & any_new_pur\n",
    "    cols = [\"ncodpers\"] + y_cols\n",
    "    \n",
    "    df_out = extract_subset(df, row_filter, cols)\n",
    "    assert _is_unique(df_out[\"ncodpers\"]), \"ncodpers must be unique\"\n",
    "    \n",
    "    df_out.columns = [col.replace(\"_NEW_PUR\", \"\") if col.endswith(\"_NEW_PUR\") else col for col in df_out.columns]\n",
    "    #df_out = df_out.set_index(\"ncodpers\")\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def extract_x_demog(df, timestamp, customer_ids, demog_cols=DEMOG_COLS):\n",
    "    row_filter = (df[\"fecha_dato\"] == timestamp) & df[\"ncodpers\"].isin(customer_ids)\n",
    "    cols = [\"ncodpers\"] + demog_cols\n",
    "    \n",
    "    df_out = extract_subset(df, row_filter, cols)\n",
    "    assert _is_unique(df_out[\"ncodpers\"]), \"ncodpers must be unique\"\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# This function can give dataframe having less rows than len(customer_ids)\n",
    "# This is becuse number of row at lag_timestamp is not the same as at timestamp\n",
    "def extract_y_prod_lag(df, timestamp_lag, customer_ids, suffix=\"_LAG\", prod_cols=PROD_COLS):\n",
    "    row_filter = (df[\"fecha_dato\"] == timestamp_lag) & df[\"ncodpers\"].isin(customer_ids)\n",
    "    cols = [\"ncodpers\"] + prod_cols\n",
    "    \n",
    "    df_out = extract_subset(df, row_filter, cols)\n",
    "    assert _is_unique(df_out[\"ncodpers\"]), \"ncodpers must be unique\"\n",
    "    \n",
    "    df_out.columns = [\"ncodpers\"] + [col + suffix for col in df_out.columns if col != \"ncodpers\"]\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "def extract_X_y_train(df, timestamp, timestamp_lags):\n",
    "    y_train = extract_y(df, timestamp)\n",
    "    print(\"y_train.shape\", y_train.shape)\n",
    "    \n",
    "    x_demog = extract_x_demog(df, timestamp, customer_ids=y_train[\"ncodpers\"])\n",
    "    print(\"x_demog.shape:\", x_demog.shape)\n",
    "    assert y_train.shape[0] == x_demog.shape[0], \"x_demog must have the same number of rows as y_train\"\n",
    "    \n",
    "    x_lags = []\n",
    "    for t, lag in enumerate(timestamp_lags):\n",
    "        assert pd.to_datetime(lag) < pd.to_datetime(timestamp), lag + \" lag is not before timestamp \" +  timestamp\n",
    "        lag_label = \"_LAG%d\" % (t + 1)\n",
    "        \n",
    "        x_lag = extract_y_prod_lag(df, lag, customer_ids=y_train[\"ncodpers\"], suffix=lag_label)\n",
    "        print(lag, lag_label, x_lag.shape)\n",
    "        x_lags.append(x_lag)\n",
    "    \n",
    "    X_train = y_train[[\"ncodpers\"]].merge(x_demog, how=\"left\", on=\"ncodpers\")\n",
    "    print(\"Nulls after merging y and x_demog:\", X_train.isnull().sum().sum())\n",
    "    \n",
    "    for t, x_lag in enumerate(x_lags):\n",
    "        X_train = X_train.merge(x_lag, how=\"left\", on=\"ncodpers\")\n",
    "        print(\"Nulls at %d:\" %(t + 1), X_train.isnull().sum().sum())\n",
    "    \n",
    "    print(\"X_train.shape:\", X_train.shape)\n",
    "    print(\"y_train.shape:\", y_train.shape)\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def extract_X_test(train, test, timestamp, timestamp_lags):\n",
    "    x_demog = extract_x_demog(test, timestamp, customer_ids=test[\"ncodpers\"])\n",
    "    print(\"x_demog.shape:\", x_demog.shape)\n",
    "    print(\"Nulls of x_demog:\", x_demog.isnull().sum().sum())\n",
    "    \n",
    "    x_lags = []\n",
    "    for t, lag in enumerate(timestamp_lags):\n",
    "        assert pd.to_datetime(lag) < pd.to_datetime(timestamp), lag + \" lag is not before timestamp \" +  timestamp\n",
    "        lag_label = \"_LAG%d\" % (t + 1)\n",
    "        \n",
    "        x_lag = extract_y_prod_lag(train, lag, customer_ids=test[\"ncodpers\"], suffix=lag_label)\n",
    "        print(lag, lag_label, x_lag.shape)\n",
    "        x_lags.append(x_lag)\n",
    "        \n",
    "    X_test = x_demog\n",
    "    for t, x_lag in enumerate(x_lags):\n",
    "        X_test = X_test.merge(x_lag, how=\"left\", on=\"ncodpers\")\n",
    "        print(\"Nulls at %d:\" %(t + 1), X_test.isnull().sum().sum())\n",
    "    \n",
    "    print(\"X_test.shape:\", X_test.shape)\n",
    "    return X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
