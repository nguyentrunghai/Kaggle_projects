{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_ser(ser):\n",
    "    \n",
    "    if ser.dtype == int:\n",
    "        return ser.astype(np.int32)\n",
    "    \n",
    "    if ser.dtype == float:\n",
    "        return ser.astype(np.float32)\n",
    "    \n",
    "    if ser.dtype == np.object:\n",
    "        return ser.astype(\"category\")\n",
    "    \n",
    "    return ser\n",
    "    \n",
    "\n",
    "def change_dtype_df(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"])\n",
    "    df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"])\n",
    "    \n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = change_dtype_ser(df[col])\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtype_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/data_\"\n",
    "OUT_DIR1 = \"data/data1_\"\n",
    "OUT_DIR2 = \"data/data2_\"\n",
    "OUT_DIR3 = \"data/data3_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hai/opt/python_virtual_environments/xgboost/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3337: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 9566.76 MB\n",
      "Memory usage after changing types 4612.80 MB\n",
      "Memory usage before changing types 116.20 MB\n",
      "Memory usage after changing types 49.28 MB\n"
     ]
    }
   ],
   "source": [
    "df_train = load_csv(os.path.join(INP_DIR, \"train_cleaned.csv\"))\n",
    "df_test = load_csv(os.path.join(INP_DIR, \"test_cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop this column becuase it is too imbalanced\n",
    "df_train = df_train.drop([\"ind_empleado\"], axis=1)\n",
    "df_test = df_test.drop([\"ind_empleado\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days from when the data is recorded \n",
    "df_train[\"fecha_alta\"] = (df_train[\"fecha_alta\"] - df_train[\"fecha_dato\"]).dt.days\n",
    "df_test[\"fecha_alta\"] = (df_test[\"fecha_alta\"] - df_test[\"fecha_dato\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum(), df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13647309, 91), (929615, 19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'pais_residencia', 'sexo', 'age',\n",
       "       'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall',\n",
       "       'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1',\n",
       "       'ind_ahor_fin_ult1_NEW_PUR', 'ind_aval_fin_ult1_NEW_PUR',\n",
       "       'ind_cco_fin_ult1_NEW_PUR', 'ind_cder_fin_ult1_NEW_PUR',\n",
       "       'ind_cno_fin_ult1_NEW_PUR', 'ind_ctju_fin_ult1_NEW_PUR',\n",
       "       'ind_ctma_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR',\n",
       "       'ind_ctpp_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR',\n",
       "       'ind_deme_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR',\n",
       "       'ind_ecue_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR',\n",
       "       'ind_hip_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR',\n",
       "       'ind_pres_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR',\n",
       "       'ind_tjcr_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR',\n",
       "       'ind_viv_fin_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR',\n",
       "       'ind_nom_pens_ult1_NEW_PUR', 'ind_recibo_ult1_NEW_PUR',\n",
       "       'ind_ahor_fin_ult1_PUR_OR_CANCEL', 'ind_aval_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_cco_fin_ult1_PUR_OR_CANCEL', 'ind_cder_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_cno_fin_ult1_PUR_OR_CANCEL', 'ind_ctju_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_ctma_fin_ult1_PUR_OR_CANCEL', 'ind_ctop_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_ctpp_fin_ult1_PUR_OR_CANCEL', 'ind_deco_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_deme_fin_ult1_PUR_OR_CANCEL', 'ind_dela_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_ecue_fin_ult1_PUR_OR_CANCEL', 'ind_fond_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_hip_fin_ult1_PUR_OR_CANCEL', 'ind_plan_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_pres_fin_ult1_PUR_OR_CANCEL', 'ind_reca_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_tjcr_fin_ult1_PUR_OR_CANCEL', 'ind_valo_fin_ult1_PUR_OR_CANCEL',\n",
       "       'ind_viv_fin_ult1_PUR_OR_CANCEL', 'ind_nomina_ult1_PUR_OR_CANCEL',\n",
       "       'ind_nom_pens_ult1_PUR_OR_CANCEL', 'ind_recibo_ult1_PUR_OR_CANCEL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_dato', 'ncodpers', 'pais_residencia', 'sexo', 'age',\n",
       "       'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes',\n",
       "       'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall',\n",
       "       'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n"
     ]
    }
   ],
   "source": [
    "PROD_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1$\", col)]\n",
    "print(PROD_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of prod\n",
    "df_train[\"TOTAL_PRODS\"] = df_train[PROD_COLS].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1_NEW_PUR', 'ind_aval_fin_ult1_NEW_PUR', 'ind_cco_fin_ult1_NEW_PUR', 'ind_cder_fin_ult1_NEW_PUR', 'ind_cno_fin_ult1_NEW_PUR', 'ind_ctju_fin_ult1_NEW_PUR', 'ind_ctma_fin_ult1_NEW_PUR', 'ind_ctop_fin_ult1_NEW_PUR', 'ind_ctpp_fin_ult1_NEW_PUR', 'ind_deco_fin_ult1_NEW_PUR', 'ind_deme_fin_ult1_NEW_PUR', 'ind_dela_fin_ult1_NEW_PUR', 'ind_ecue_fin_ult1_NEW_PUR', 'ind_fond_fin_ult1_NEW_PUR', 'ind_hip_fin_ult1_NEW_PUR', 'ind_plan_fin_ult1_NEW_PUR', 'ind_pres_fin_ult1_NEW_PUR', 'ind_reca_fin_ult1_NEW_PUR', 'ind_tjcr_fin_ult1_NEW_PUR', 'ind_valo_fin_ult1_NEW_PUR', 'ind_viv_fin_ult1_NEW_PUR', 'ind_nomina_ult1_NEW_PUR', 'ind_nom_pens_ult1_NEW_PUR', 'ind_recibo_ult1_NEW_PUR']\n"
     ]
    }
   ],
   "source": [
    "NEW_PUR_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1_NEW_PUR$\", col)]\n",
    "print(NEW_PUR_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ahor_fin_ult1_PUR_OR_CANCEL', 'ind_aval_fin_ult1_PUR_OR_CANCEL', 'ind_cco_fin_ult1_PUR_OR_CANCEL', 'ind_cder_fin_ult1_PUR_OR_CANCEL', 'ind_cno_fin_ult1_PUR_OR_CANCEL', 'ind_ctju_fin_ult1_PUR_OR_CANCEL', 'ind_ctma_fin_ult1_PUR_OR_CANCEL', 'ind_ctop_fin_ult1_PUR_OR_CANCEL', 'ind_ctpp_fin_ult1_PUR_OR_CANCEL', 'ind_deco_fin_ult1_PUR_OR_CANCEL', 'ind_deme_fin_ult1_PUR_OR_CANCEL', 'ind_dela_fin_ult1_PUR_OR_CANCEL', 'ind_ecue_fin_ult1_PUR_OR_CANCEL', 'ind_fond_fin_ult1_PUR_OR_CANCEL', 'ind_hip_fin_ult1_PUR_OR_CANCEL', 'ind_plan_fin_ult1_PUR_OR_CANCEL', 'ind_pres_fin_ult1_PUR_OR_CANCEL', 'ind_reca_fin_ult1_PUR_OR_CANCEL', 'ind_tjcr_fin_ult1_PUR_OR_CANCEL', 'ind_valo_fin_ult1_PUR_OR_CANCEL', 'ind_viv_fin_ult1_PUR_OR_CANCEL', 'ind_nomina_ult1_PUR_OR_CANCEL', 'ind_nom_pens_ult1_PUR_OR_CANCEL', 'ind_recibo_ult1_PUR_OR_CANCEL']\n"
     ]
    }
   ],
   "source": [
    "PUR_CANCEL_COLS = [col for col in df_train.columns if re.match(r\"^ind_.*_ult1_PUR_OR_CANCEL$\", col)]\n",
    "print(PUR_CANCEL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pais_residencia', 'sexo', 'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext', 'canal_entrada', 'indfall', 'cod_prov', 'ind_actividad_cliente', 'renta', 'segmento']\n"
     ]
    }
   ],
   "source": [
    "DEMOG_COLS = [col for col in df_train.columns \n",
    "    if col not in PROD_COLS + NEW_PUR_COLS + PUR_CANCEL_COLS + [\"fecha_dato\", \"ncodpers\", \"TOTAL_PRODS\"]]\n",
    "print(DEMOG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_ahor_fin_ult1',\n",
       " 'ind_aval_fin_ult1',\n",
       " 'ind_cco_fin_ult1',\n",
       " 'ind_cder_fin_ult1',\n",
       " 'ind_cno_fin_ult1',\n",
       " 'ind_ctju_fin_ult1',\n",
       " 'ind_ctma_fin_ult1',\n",
       " 'ind_ctop_fin_ult1',\n",
       " 'ind_ctpp_fin_ult1',\n",
       " 'ind_deco_fin_ult1',\n",
       " 'ind_deme_fin_ult1',\n",
       " 'ind_dela_fin_ult1',\n",
       " 'ind_ecue_fin_ult1',\n",
       " 'ind_fond_fin_ult1',\n",
       " 'ind_hip_fin_ult1',\n",
       " 'ind_plan_fin_ult1',\n",
       " 'ind_pres_fin_ult1',\n",
       " 'ind_reca_fin_ult1',\n",
       " 'ind_tjcr_fin_ult1',\n",
       " 'ind_valo_fin_ult1',\n",
       " 'ind_viv_fin_ult1',\n",
       " 'ind_nomina_ult1',\n",
       " 'ind_nom_pens_ult1',\n",
       " 'ind_recibo_ult1',\n",
       " 'ind_ahor_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_aval_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_cco_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_cder_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_cno_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctju_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctma_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctop_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ctpp_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_deco_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_deme_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_dela_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_ecue_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_fond_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_hip_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_plan_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_pres_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_reca_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_tjcr_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_valo_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_viv_fin_ult1_PUR_OR_CANCEL',\n",
       " 'ind_nomina_ult1_PUR_OR_CANCEL',\n",
       " 'ind_nom_pens_ult1_PUR_OR_CANCEL',\n",
       " 'ind_recibo_ult1_PUR_OR_CANCEL',\n",
       " 'ind_nuevo',\n",
       " 'antiguedad',\n",
       " 'indrel',\n",
       " 'tiprel_1mes',\n",
       " 'ind_actividad_cliente',\n",
       " 'renta',\n",
       " 'segmento',\n",
       " 'TOTAL_PRODS']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEMOG_LAG_COLS = [\"ind_nuevo\", \"antiguedad\", \"indrel\", \"tiprel_1mes\", \n",
    "            \"ind_actividad_cliente\", \"renta\", \"segmento\", \"TOTAL_PRODS\"]\n",
    "\n",
    "LAG_COLS = PROD_COLS + PUR_CANCEL_COLS + DEMOG_LAG_COLS\n",
    "LAG_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subset(df, row_filter, cols):\n",
    "    return df.loc[row_filter, cols]\n",
    "\n",
    "\n",
    "\n",
    "def suffixing_cols(df, suffix=\"_LAG\", exclude_cols=[\"ncodpers\"]):\n",
    "    new_cols = [col + suffix if col not in exclude_cols else col for col in df.columns]\n",
    "    df.columns = new_cols \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def extract_by_timestamp_newpur(df, timestamp, sel_prod_cols, \n",
    "                                new_pur_suffix=\"_NEW_PUR\", \n",
    "                                sel_cols=DEMOG_COLS):\n",
    "    \"\"\"extract rows by timestamp and new purchase columns\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if \"ncodpers\" not in sel_cols:\n",
    "        sel_cols = [\"ncodpers\"] + sel_cols\n",
    "    \n",
    "    extracted_dfs = []\n",
    "    targets = []\n",
    "    for prod_col in sel_prod_cols:\n",
    "        pur_col = prod_col + new_pur_suffix\n",
    "        row_filter = (df[\"fecha_dato\"] == timestamp) & (df[pur_col] == 1)\n",
    "        \n",
    "        sub_df = extract_subset(df, row_filter, sel_cols)\n",
    "        #print(\"sub_df.shape:\", sub_df.shape)\n",
    "        extracted_dfs.append(sub_df)\n",
    "        \n",
    "        ys = [prod_col] * sub_df.shape[0]\n",
    "        targets.extend(ys)\n",
    "    \n",
    "    extracted_dfs = pd.concat(extracted_dfs, axis=0).reset_index(drop=True)\n",
    "    extracted_dfs[\"TARGET\"] = targets\n",
    "    \n",
    "    extracted_dfs = extracted_dfs.sort_values(by=\"ncodpers\")\n",
    "    return extracted_dfs\n",
    "\n",
    "\n",
    "def extract_by_timestamp_custid(df, timestamp, customer_ids, sel_cols):\n",
    "    df = df.copy()\n",
    "    \n",
    "    customer_ids = np.unique(customer_ids)\n",
    "    \n",
    "    if \"ncodpers\" not in sel_cols:\n",
    "        sel_cols = [\"ncodpers\"] + sel_cols\n",
    "    #print(\"sel_cols:\", sel_cols)\n",
    "    \n",
    "    row_filter = (df[\"fecha_dato\"] == timestamp) & df[\"ncodpers\"].isin(customer_ids)\n",
    "    df_out = extract_subset(df, row_filter, sel_cols)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def extract_X_y_train(df, timestamp, timestamp_lags, sel_prod_cols,\n",
    "                      demog_cols=DEMOG_COLS, lag_cols=LAG_COLS):\n",
    "    out_df = extract_by_timestamp_newpur(df, timestamp, sel_prod_cols, sel_cols=demog_cols)\n",
    "    \n",
    "    customer_ids = out_df[\"ncodpers\"]\n",
    "    for t, lag in enumerate(timestamp_lags):\n",
    "        assert pd.to_datetime(lag) < pd.to_datetime(timestamp), lag + \" lag is not before timestamp \" +  timestamp\n",
    "        lag_label = \"_LAG%d\" % (t + 1)\n",
    "        \n",
    "        lag_df = extract_by_timestamp_custid(df, lag, customer_ids=customer_ids, sel_cols=lag_cols)\n",
    "        lag_df = suffixing_cols(lag_df, lag_label, exclude_cols=[\"ncodpers\"])\n",
    "        \n",
    "        print(lag, lag_label, lag_df.shape)\n",
    "        \n",
    "        out_df = out_df.merge(lag_df, how=\"left\", on=\"ncodpers\")\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def extract_X_test(train, test, timestamp, timestamp_lags, demog_cols=DEMOG_COLS, lag_cols=LAG_COLS):\n",
    "    customer_ids = test[\"ncodpers\"]\n",
    "    out_df = extract_by_timestamp_custid(test, timestamp, customer_ids=customer_ids, sel_cols=demog_cols)\n",
    "    \n",
    "    for t, lag in enumerate(timestamp_lags):\n",
    "        assert pd.to_datetime(lag) < pd.to_datetime(timestamp), lag + \" lag is not before timestamp \" +  timestamp\n",
    "        lag_label = \"_LAG%d\" % (t + 1)\n",
    "        \n",
    "        lag_df = extract_by_timestamp_custid(train, lag, customer_ids=customer_ids, sel_cols=lag_cols)\n",
    "        lag_df = suffixing_cols(lag_df, lag_label, exclude_cols=[\"ncodpers\"])\n",
    "        \n",
    "        print(lag, lag_label, lag_df.shape)\n",
    "        \n",
    "        out_df = out_df.merge(lag_df, how=\"left\", on=\"ncodpers\")\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_purchase(df, timestamp, pur_cols, suffix=\"_NEW_PUR\", threshold=None):\n",
    "    prod_popul = df.loc[df[\"fecha_dato\"] == timestamp, pur_cols].sum(axis=0)\n",
    "    prod_popul = prod_popul.sort_values(ascending=False)\n",
    "    prod_popul.index = [idx.replace(suffix, \"\") for idx in prod_popul.index]\n",
    "    prod_popul = prod_popul[prod_popul > 0]\n",
    "    \n",
    "    if threshold is None:\n",
    "        index = prod_popul.index\n",
    "    else:\n",
    "        index = prod_popul.index[:threshold]\n",
    "    return prod_popul[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-01-28T00:00:00.000000000', '2015-02-28T00:00:00.000000000',\n",
       "       '2015-03-28T00:00:00.000000000', '2015-04-28T00:00:00.000000000',\n",
       "       '2015-05-28T00:00:00.000000000', '2015-06-28T00:00:00.000000000',\n",
       "       '2015-07-28T00:00:00.000000000', '2015-08-28T00:00:00.000000000',\n",
       "       '2015-09-28T00:00:00.000000000', '2015-10-28T00:00:00.000000000',\n",
       "       '2015-11-28T00:00:00.000000000', '2015-12-28T00:00:00.000000000',\n",
       "       '2016-01-28T00:00:00.000000000', '2016-02-28T00:00:00.000000000',\n",
       "       '2016-03-28T00:00:00.000000000', '2016-04-28T00:00:00.000000000',\n",
       "       '2016-05-28T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"fecha_dato\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `2016-05`  with 6-month lags to predict `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "popul_pur_2016_04 = most_popular_purchase(df_train, \"2016-04-28\", NEW_PUR_COLS)\n",
    "popul_pur_2016_05 = most_popular_purchase(df_train, \"2016-05-28\", NEW_PUR_COLS, threshold=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind_recibo_ult1      10163\n",
       "ind_nom_pens_ult1     5513\n",
       "ind_nomina_ult1       5488\n",
       "ind_tjcr_fin_ult1     4248\n",
       "ind_cco_fin_ult1      3878\n",
       "ind_ecue_fin_ult1     2709\n",
       "ind_cno_fin_ult1      2347\n",
       "ind_ctma_fin_ult1      531\n",
       "ind_reca_fin_ult1      279\n",
       "ind_ctop_fin_ult1      226\n",
       "ind_valo_fin_ult1      183\n",
       "ind_ctpp_fin_ult1      131\n",
       "ind_fond_fin_ult1       61\n",
       "ind_dela_fin_ult1       46\n",
       "ind_ctju_fin_ult1       40\n",
       "ind_plan_fin_ult1       22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popul_pur_2016_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_ctju_fin_ult1', 'ind_ctop_fin_ult1', 'ind_dela_fin_ult1', 'ind_cno_fin_ult1', 'ind_nom_pens_ult1', 'ind_reca_fin_ult1', 'ind_valo_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_fond_fin_ult1', 'ind_nomina_ult1', 'ind_recibo_ult1', 'ind_ecue_fin_ult1', 'ind_plan_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_ctma_fin_ult1', 'ind_cco_fin_ult1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_LABES = set(popul_pur_2016_04.index).intersection(set(popul_pur_2016_05.index))\n",
    "Y_LABES = list(Y_LABES)\n",
    "print(Y_LABES)\n",
    "len(Y_LABES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_04`, `y_2016_04`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-28 _LAG1 (26728, 57)\n",
      "2016-02-28 _LAG2 (25043, 57)\n",
      "2016-01-28 _LAG3 (24247, 57)\n",
      "2015-12-28 _LAG4 (23548, 57)\n",
      "2015-11-28 _LAG5 (22797, 57)\n",
      "2015-10-28 _LAG6 (22300, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33005, 355)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-04-28\"\n",
    "timestamp_lags = [\"2016-03-28\", \"2016-02-28\", \"2016-01-28\", \n",
    "                  \"2015-12-28\", \"2015-11-28\", \"2015-10-28\"]\n",
    "\n",
    "X_y_2016_04 = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "X_y_2016_04.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_2016_04.to_csv(os.path.join(OUT_DIR1, \"X_y_2016_04.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_05`, `y_2016_05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-28 _LAG1 (27856, 57)\n",
      "2016-03-28 _LAG2 (26353, 57)\n",
      "2016-02-28 _LAG3 (25674, 57)\n",
      "2016-01-28 _LAG4 (24918, 57)\n",
      "2015-12-28 _LAG5 (23950, 57)\n",
      "2015-11-28 _LAG6 (23535, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35865, 355)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-05-28\"\n",
    "timestamp_lags = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\",\n",
    "                  \"2015-12-28\", \"2015-11-28\"]\n",
    "\n",
    "X_y_2016_05 = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "X_y_2016_05.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_2016_05.to_csv(os.path.join(OUT_DIR1, \"X_y_2016_05.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-28 _LAG1 (929615, 57)\n",
      "2016-04-28 _LAG2 (925252, 57)\n",
      "2016-03-28 _LAG3 (920975, 57)\n",
      "2016-02-28 _LAG4 (915679, 57)\n",
      "2016-01-28 _LAG5 (909885, 57)\n",
      "2015-12-28 _LAG6 (903429, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(929615, 354)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-06-28\"\n",
    "timestamp_lags = [\"2016-05-28\", \"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\",\n",
    "                  \"2015-12-28\"]\n",
    "\n",
    "X_2016_06 = extract_X_test(df_train, df_test, timestamp, timestamp_lags)\n",
    "X_2016_06.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_06.to_csv(os.path.join(OUT_DIR1, \"X_2016_06.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `2016-05`  with 12-month lags to predict `2016-06`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_04`, `y_2016_04`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-28 _LAG1 (26728, 57)\n",
      "2016-02-28 _LAG2 (25043, 57)\n",
      "2016-01-28 _LAG3 (24247, 57)\n",
      "2015-12-28 _LAG4 (23548, 57)\n",
      "2015-11-28 _LAG5 (22797, 57)\n",
      "2015-10-28 _LAG6 (22300, 57)\n",
      "2015-09-28 _LAG7 (21811, 57)\n",
      "2015-08-28 _LAG8 (21407, 57)\n",
      "2015-07-28 _LAG9 (21135, 57)\n",
      "2015-06-28 _LAG10 (20215, 57)\n",
      "2015-05-28 _LAG11 (20056, 57)\n",
      "2015-04-28 _LAG12 (19878, 57)\n"
     ]
    }
   ],
   "source": [
    "timestamp = \"2016-04-28\"\n",
    "timestamp_lags = [\"2016-03-28\", \"2016-02-28\", \"2016-01-28\", \n",
    "                  \"2015-12-28\", \"2015-11-28\", \"2015-10-28\",\n",
    "                  \"2015-09-28\", \"2015-08-28\", \"2015-07-28\", \n",
    "                  \"2015-06-28\", \"2015-05-28\", \"2015-04-28\"]\n",
    "\n",
    "X_y_2016_04 = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "X_y_2016_04.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_2016_04.to_csv(os.path.join(OUT_DIR2, \"X_y_2016_04.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_05`, `y_2016_05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-28 _LAG1 (27856, 57)\n",
      "2016-03-28 _LAG2 (26353, 57)\n",
      "2016-02-28 _LAG3 (25674, 57)\n",
      "2016-01-28 _LAG4 (24918, 57)\n",
      "2015-12-28 _LAG5 (23950, 57)\n",
      "2015-11-28 _LAG6 (23535, 57)\n",
      "2015-10-28 _LAG7 (23161, 57)\n",
      "2015-09-28 _LAG8 (22707, 57)\n",
      "2015-08-28 _LAG9 (22297, 57)\n",
      "2015-07-28 _LAG10 (22036, 57)\n",
      "2015-06-28 _LAG11 (21093, 57)\n",
      "2015-05-28 _LAG12 (20946, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35865, 691)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-05-28\"\n",
    "timestamp_lags = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\",\n",
    "                  \"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\",\n",
    "                 \"2015-08-28\", \"2015-07-28\", \"2015-06-28\", \"2015-05-28\"]\n",
    "\n",
    "X_y_2016_05 = extract_X_y_train(df_train, timestamp, timestamp_lags, Y_LABES)\n",
    "X_y_2016_05.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_2016_05.to_csv(os.path.join(OUT_DIR2, \"X_y_2016_05.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-28 _LAG1 (929615, 57)\n",
      "2016-04-28 _LAG2 (925252, 57)\n",
      "2016-03-28 _LAG3 (920975, 57)\n",
      "2016-02-28 _LAG4 (915679, 57)\n",
      "2016-01-28 _LAG5 (909885, 57)\n",
      "2015-12-28 _LAG6 (903429, 57)\n",
      "2015-11-28 _LAG7 (896458, 57)\n",
      "2015-10-28 _LAG8 (881573, 57)\n",
      "2015-09-28 _LAG9 (854574, 57)\n",
      "2015-08-28 _LAG10 (832230, 57)\n",
      "2015-07-28 _LAG11 (818424, 57)\n",
      "2015-06-28 _LAG12 (622404, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(929615, 690)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = \"2016-06-28\"\n",
    "timestamp_lags = [\"2016-05-28\", \"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\",\n",
    "                  \"2015-12-28\", \"2015-11-28\", \"2015-10-28\", \"2015-09-28\", \"2015-08-28\",\n",
    "                 \"2015-07-28\", \"2015-06-28\"]\n",
    "\n",
    "X_2016_06 = extract_X_test(df_train, df_test, timestamp, timestamp_lags)\n",
    "X_2016_06.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_06.to_csv(os.path.join(OUT_DIR2, \"X_2016_06.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `2015-06`  with 4-month lags to predict `2016-06`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2015_05`, `y_2015_05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2015-05-28\"\n",
    "timestamp_lags = [\"2015-04-28\", \"2015-03-28\", \"2015-02-28\", \"2015-01-28\"]\n",
    "\n",
    "X_2015_05, y_2015_05 = extract_X_y_train(df_train, timestamp, timestamp_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2015_05.to_csv(os.path.join(OUT_DIR3, \"X_2015_05.csv\"), index=False)\n",
    "y_2015_05.to_csv(os.path.join(OUT_DIR3, \"y_2015_05.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2015_06`, `y_2015_06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2015-06-28\"\n",
    "timestamp_lags = [\"2015-05-28\", \"2015-04-28\", \"2015-03-28\", \"2015-02-28\"]\n",
    "\n",
    "X_2015_06, y_2015_06 = extract_X_y_train(df_train, timestamp, timestamp_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2015_06.to_csv(os.path.join(OUT_DIR3, \"X_2015_06.csv\"), index=False)\n",
    "y_2015_06.to_csv(os.path.join(OUT_DIR3, \"y_2015_06.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_05`, `y_2016_05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2016-05-28\"\n",
    "timestamp_lags = [\"2016-04-28\", \"2016-03-28\", \"2016-02-28\", \"2016-01-28\"]\n",
    "\n",
    "X_2016_05, y_2016_05 = extract_X_y_train(df_train, timestamp, timestamp_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_05.to_csv(os.path.join(OUT_DIR3, \"X_2016_05.csv\"), index=False)\n",
    "y_2016_05.to_csv(os.path.join(OUT_DIR3, \"y_2016_05.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `X_2016_06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"2016-06-28\"\n",
    "timestamp_lags = [\"2016-05-28\", \"2016-04-28\", \"2016-03-28\", \"2016-02-28\"]\n",
    "\n",
    "X_2016_06 = extract_X_test(df_train, df_test, timestamp, timestamp_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_06.to_csv(os.path.join(OUT_DIR3, \"X_2016_06.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
