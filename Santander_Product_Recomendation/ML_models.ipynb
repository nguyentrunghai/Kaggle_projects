{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use data at `2016-05` to predict product purchase for `2016-06`.\n",
    "\n",
    "The best MAP@7 in private leader board is 0.03140. The worst is 0.00448."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import ml_metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/data1_\"\n",
    "SUB_DIR = \"data/submit_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_ser(ser):\n",
    "    \n",
    "    if ser.dtype == int:\n",
    "        return ser.astype(np.int32)\n",
    "    \n",
    "    if ser.dtype == float:\n",
    "        return ser.astype(np.float32)\n",
    "    \n",
    "    if ser.dtype == np.object:\n",
    "        return ser.astype(\"category\")\n",
    "    \n",
    "    return ser\n",
    "    \n",
    "\n",
    "def change_dtype_df(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = change_dtype_ser(df[col])\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtype_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_04 = load_csv(os.path.join(INP_DIR, \"X_2016_04.csv\"))\n",
    "y_2016_04 = load_csv(os.path.join(INP_DIR, \"y_2016_04.csv\"))\n",
    "\n",
    "X_2016_04 = X_2016_04.drop([\"ncodpers\"], axis=1)\n",
    "y_2016_04 = y_2016_04.drop([\"ncodpers\"], axis=1)\n",
    "\n",
    "X_2016_04.shape, y_2016_04.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2016_04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_05 = load_csv(os.path.join(INP_DIR, \"X_2016_05.csv\"))\n",
    "y_2016_05 = load_csv(os.path.join(INP_DIR, \"y_2016_05.csv\"))\n",
    "\n",
    "X_2016_05 = X_2016_05.drop([\"ncodpers\"], axis=1)\n",
    "y_2016_05 = y_2016_05.drop([\"ncodpers\"], axis=1)\n",
    "\n",
    "X_2016_05.shape, y_2016_05.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2016_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_06 = load_csv(os.path.join(INP_DIR, \"X_2016_06.csv\"))\n",
    "\n",
    "ncodpers_test = X_2016_06[\"ncodpers\"]\n",
    "X_2016_06 = X_2016_06.drop([\"ncodpers\"], axis=1)\n",
    "\n",
    "X_2016_06.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2016_06.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method=\"mean\"):\n",
    "        self._method = method\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        num_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        \n",
    "        self._impute_values = {}\n",
    "        for col in num_cols:\n",
    "            self._impute_values[col] = df_train[col].agg(self._method)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        for col, val in self._impute_values.items():\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(val)\n",
    "        return df\n",
    "    \n",
    "\n",
    "class CatImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, val=\"MISSING\"):\n",
    "        self._val = val\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        cat_cols = df_train.select_dtypes([\"object\", \"category\", \"bool\"]).columns.to_list()\n",
    "        \n",
    "        self._impute_values = {}\n",
    "        for col in cat_cols:\n",
    "            self._impute_values[col] = self._val\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        for col, val in self._impute_values.items():\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].astype(\"object\").fillna(val).astype(\"category\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_classes=20, to_array=False):\n",
    "        self._to_array = to_array\n",
    "        self._max_classes = max_classes\n",
    "        \n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        df_cat = train_df.select_dtypes([\"object\", \"category\"])\n",
    "        self._cat_cols = df_cat.columns.to_list()\n",
    "        \n",
    "        self._cat_cols = [col for col in self._cat_cols if train_df[col].nunique() <= self._max_classes]\n",
    "        print(\"Columns to one-hot encode:\", self._cat_cols)\n",
    "        df_cat = train_df[self._cat_cols]\n",
    "        \n",
    "        if len(self._cat_cols) > 0:\n",
    "            self._cat_cols_ohe = pd.get_dummies(df_cat, drop_first=True).columns.to_list()\n",
    "        else:\n",
    "            self._cat_cols_ohe = []\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        if len(self._cat_cols) == 0:\n",
    "            print(\"No cat cols in df_train, so do nothing.\")\n",
    "            return df\n",
    "        \n",
    "        df_cat = df[self._cat_cols]\n",
    "        print(\"df_cat.columns\", df_cat.columns)\n",
    "        \n",
    "        # one-hot encode\n",
    "        df_cat = pd.get_dummies(df_cat)\n",
    "        # drop cols that are present in test_df but absent in train_df\n",
    "        cols_to_drop = [col for col in df_cat.columns if col not in self._cat_cols_ohe]\n",
    "        print(\"cols_to_drop:\", cols_to_drop)\n",
    "        df_cat = df_cat.drop(cols_to_drop, axis=\"columns\")\n",
    "        \n",
    "        # change to float32\n",
    "        for col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].astype(\"float32\")\n",
    "        \n",
    "        # if some some colums are absent in test but present in train, make them all zero \n",
    "        cat_cols_ohe = df_cat.columns.to_list()\n",
    "        for col in self._cat_cols_ohe:\n",
    "            if col not in cat_cols_ohe:\n",
    "                df_cat[col] = 0\n",
    "                df_cat[col] = df_cat[col].astype(np.uint8)\n",
    "        \n",
    "        num_cols = [col for col in df.columns if col not in self._cat_cols]\n",
    "        df_num = df[num_cols]\n",
    "        \n",
    "        df = pd.concat([df_num, df_cat], axis=\"columns\")\n",
    "        self._features = df.columns.to_list()\n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df\n",
    "\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_array=False):\n",
    "        self._to_array = to_array\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        all_cols = df_train.columns.to_list()\n",
    "        cat_cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        \n",
    "        self._cat_col_idx = [i for i, col in enumerate(all_cols) if col in cat_cols]\n",
    "        \n",
    "        self._label_maps = {}\n",
    "        self._missing_imputers = {}\n",
    "        for col in cat_cols:\n",
    "            label = df_train[col].unique()\n",
    "            self._label_maps[col] = {c: n for n, c in enumerate(label)}\n",
    "            \n",
    "            mode_label = df_train[col].mode().iloc[0]\n",
    "            self._missing_imputers[col] = self._label_maps[col][mode_label]\n",
    "        \n",
    "        print(\"Cols to label encode:\", list(self._label_maps.keys()))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        for col, label_map in self._label_maps.items():\n",
    "            df[col] = df[col].map(label_map).astype(np.float32)\n",
    "            if df[col].isnull().any():\n",
    "                df[col] = df[col].astype(np.float32).fillna(self._missing_imputers[col])\n",
    "                \n",
    "        self._features = df.columns.to_list()\n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "    def get_cat_cols(self):\n",
    "        return self._cat_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean average precision at k\n",
    "def mapk(y, y_prob, k=7):\n",
    "    y = y[:, np.newaxis]\n",
    "    # ascending\n",
    "    y_pred = np.argsort(y_prob, axis=1)\n",
    "    # descending\n",
    "    y_pred = y_pred[:, ::-1]\n",
    "    \n",
    "    return ml_metrics.mapk(y, y_pred, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submit(y_prob, target_labels, ncodpers, filepath, k=7):\n",
    "    # ascending\n",
    "    y_pred = np.argsort(y_prob, axis=1)\n",
    "    # descending\n",
    "    y_pred = y_pred[:, ::-1]\n",
    "    # cut a k\n",
    "    y_pred = y_pred[:, :k]\n",
    "    \n",
    "    added_prods = target_labels[y_pred]\n",
    "    added_prods = [\" \".join(line) for line in added_prods]\n",
    "    \n",
    "    sub_df = pd.DataFrame(ncodpers)\n",
    "    sub_df[\"added_products\"] = added_prods\n",
    "    \n",
    "    sub_df.to_csv(filepath, index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_to_int(a_dict):\n",
    "    new_dict = copy.deepcopy(a_dict)\n",
    "    for k, v in new_dict.items():\n",
    "        if np.isclose(np.round(v), v):\n",
    "            new_dict[k] = int(new_dict[k])\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def run_hyperopt(classifier,\n",
    "                 params_tuned, \n",
    "                 X_train, y_train,\n",
    "                 X_val, y_val,\n",
    "                 num_eval,\n",
    "                 params_fixed=None,\n",
    "                 rstate=None):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective(params):\n",
    "        classifier.set_params(**params_fixed, **params)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        y_val_prob = classifier.predict_proba(X_val)\n",
    "        map7 = mapk(y_val, y_val_prob, k=7)\n",
    "        \n",
    "        return {\"loss\": -map7, \"status\": STATUS_OK}\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "        \n",
    "    trials = Trials()\n",
    "    best_params = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    best_params = whole_to_int(best_params)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    \n",
    "    return trials, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_2016_04)\n",
    "X_train = num_imputer.transform(X_2016_04)\n",
    "X_val = num_imputer.transform(X_2016_05)\n",
    "\n",
    "\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_val = ohe.transform(X_val)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train)\n",
    "X_train = le.transform(X_train)\n",
    "X_val = le.transform(X_val)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "target_labels = y_2016_04.columns.values\n",
    "y_train = np.argmax(y_2016_04.values, axis=1)\n",
    "y_val = np.argmax(y_2016_05.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "y_train_prob = lr.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = lr.predict(X_val)\n",
    "y_val_prob = lr.predict_proba(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation acc: %0.4f\" %acc_val)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "map7_val = mapk(y_val, y_val_prob, k=7)\n",
    "print(\"Validation MAP@7: %0.4f\" %map7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_2016_05)\n",
    "X_train = num_imputer.transform(X_2016_05)\n",
    "X_test = num_imputer.transform(X_2016_06)\n",
    "\n",
    "\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train)\n",
    "X_train = le.transform(X_train)\n",
    "X_test = le.transform(X_test)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "target_labels = y_2016_05.columns.values\n",
    "y_train = np.argmax(y_2016_05.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "y_train_prob = lr.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "y_test_prob = lr.predict_proba(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit this gives MAP@7 = 0.01855 for public and MAP@7 = 0.01859 for private score.\n",
    "write_submit(y_test_prob, target_labels, ncodpers_test, \n",
    "             os.path.join(SUB_DIR, \"lr_2016_05.csv\"), k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_2016_04)\n",
    "X_train = num_imputer.transform(X_2016_04)\n",
    "X_val = num_imputer.transform(X_2016_05)\n",
    "\n",
    "\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_val = ohe.transform(X_val)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train)\n",
    "X_train = le.transform(X_train)\n",
    "X_val = le.transform(X_val)\n",
    "\n",
    "target_labels = y_2016_04.columns.values\n",
    "y_train = np.argmax(y_2016_04.values, axis=1)\n",
    "y_val = np.argmax(y_2016_05.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 20, 1)),\n",
    "    #\"min_samples_split\": scope.int(hp.quniform(\"min_samples_split\", 20, 400, 10)),\n",
    "    \"min_samples_leaf\": scope.int(hp.quniform(\"min_samples_leaf\", 20, 200, 10)), \n",
    "    \"max_features\": scope.int(hp.quniform(\"max_features\", 5, 100, 5)),\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    \"n_jobs\": 16,\n",
    "    \"n_estimators\": 100\n",
    "}\n",
    "\n",
    "\n",
    "num_eval = 100\n",
    "rf = RandomForestClassifier()\n",
    "trials, best_params = run_hyperopt(rf, params, \n",
    "                                   X_train, y_train, X_val, y_val, \n",
    "                                   num_eval,\n",
    "                                   params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**params_fixed, **best_params)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "y_train_prob = rf.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = rf.predict(X_val)\n",
    "y_val_prob = rf.predict_proba(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation acc: %0.4f\" %acc_val)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "map7_val = mapk(y_val, y_val_prob, k=7)\n",
    "print(\"Validation MAP@7: %0.4f\" %map7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_2016_05)\n",
    "X_train = num_imputer.transform(X_2016_05)\n",
    "X_test = num_imputer.transform(X_2016_06)\n",
    "\n",
    "\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(X_train)\n",
    "X_train = le.transform(X_train)\n",
    "X_test = le.transform(X_test)\n",
    "\n",
    "\n",
    "target_labels = y_2016_05.columns.values\n",
    "y_train = np.argmax(y_2016_05.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**params_fixed, **best_params)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "y_train_prob = rf.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_prob = rf.predict_proba(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit this gives MAP@7 = 0.02387 for public and MAP@7 = 0.02423 for private score.\n",
    "write_submit(y_test_prob, target_labels, ncodpers_test, \n",
    "             os.path.join(SUB_DIR, \"rf_2016_05.csv\"), k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_2016_04)\n",
    "X_train = num_imputer.transform(X_2016_04)\n",
    "X_val = num_imputer.transform(X_2016_05)\n",
    "\n",
    "\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_val = ohe.transform(X_val)\n",
    "\n",
    "\n",
    "le = LabelEncoder(to_array=True)\n",
    "le.fit(X_train)\n",
    "X_train = le.transform(X_train)\n",
    "X_val = le.transform(X_val)\n",
    "\n",
    "target_labels = y_2016_04.columns.values\n",
    "y_train = np.argmax(y_2016_04.values, axis=1)\n",
    "y_val = np.argmax(y_2016_05.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 14, 1)),\n",
    "    \"min_child_weight\": scope.int(hp.quniform(\"min_child_weight\", 1, 50, 1)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.01), np.log(10000)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.001), np.log(1.)),\n",
    "    #\"gamma\": hp.uniform(\"gamma\", 0., 5.),\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "    \"n_estimators\": 250\n",
    "}\n",
    "\n",
    "num_eval = 50\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "trials, best_params = run_hyperopt(xgb, params, \n",
    "                                   X_train, y_train, X_val, y_val, \n",
    "                                   num_eval,\n",
    "                                   params_fixed=params_fixed)\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
