{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best MAP@7 in private leader board is 0.03140. The worst is 0.00448."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import ml_metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtype_ser(ser):\n",
    "    \n",
    "    if ser.dtype == int:\n",
    "        return ser.astype(np.int32)\n",
    "    \n",
    "    if ser.dtype == float:\n",
    "        return ser.astype(np.float32)\n",
    "    \n",
    "    if ser.dtype == np.object:\n",
    "        return ser.astype(\"category\")\n",
    "    \n",
    "    return ser\n",
    "    \n",
    "\n",
    "def change_dtype_df(df):\n",
    "    \"\"\"\n",
    "    change types of columns to reduce memory size\n",
    "    :param df: dataframe\n",
    "    :return df: dataframe\n",
    "    \"\"\"\n",
    "    memory = df.memory_usage().sum() / 10**6\n",
    "    print(\"Memory usage before changing types %0.2f MB\" % memory)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = change_dtype_ser(df[col])\n",
    "\n",
    "    memory = df.memory_usage().sum() / 10 ** 6\n",
    "    print(\"Memory usage after changing types %0.2f MB\" % memory)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = change_dtype_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method=\"mean\"):\n",
    "        self._method = method\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        num_cols = df_train.select_dtypes([\"number\"]).columns.to_list()\n",
    "        self._train_cols = df_train.columns.to_list()\n",
    "        \n",
    "        self._impute_values = {}\n",
    "        for col in num_cols:\n",
    "            self._impute_values[col] = df_train[col].agg(self._method)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        cols = df.columns.to_list()\n",
    "        assert set(cols) == set(self._train_cols), \"Do not have the same set of cols as train\"\n",
    "        \n",
    "        for col, val in self._impute_values.items():\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(val)\n",
    "        \n",
    "        # align columns\n",
    "        df = df[self._train_cols]\n",
    "        return df\n",
    "    \n",
    "\n",
    "class CatImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, val=\"MISSING\"):\n",
    "        self._val = val\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        cat_cols = df_train.select_dtypes([\"object\", \"category\", \"bool\"]).columns.to_list()\n",
    "        self._train_cols = df_train.columns.to_list()\n",
    "        \n",
    "        self._impute_values = {}\n",
    "        for col in cat_cols:\n",
    "            self._impute_values[col] = self._val\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        cols = df.columns.to_list()\n",
    "        assert set(cols) == set(self._train_cols), \"Do not have the same set of cols as train\"\n",
    "        \n",
    "        for col, val in self._impute_values.items():\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].astype(\"object\").fillna(val).astype(\"category\")\n",
    "                \n",
    "        # align columns\n",
    "        df = df[self._train_cols]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UDOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_classes=20, to_array=False):\n",
    "        self._to_array = to_array\n",
    "        self._max_classes = max_classes\n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        self._cols_before = train_df.columns.to_list()\n",
    "        \n",
    "        df_cat = train_df.select_dtypes([\"object\", \"category\"])\n",
    "        self._cat_cols = df_cat.columns.to_list()\n",
    "        \n",
    "        self._cat_cols = [col for col in self._cat_cols if train_df[col].nunique() <= self._max_classes]\n",
    "        #print(\"Columns to one-hot encode:\", self._cat_cols)\n",
    "        df_cat = train_df[self._cat_cols]\n",
    "        \n",
    "        if len(self._cat_cols) > 0:\n",
    "            self._cat_cols_ohe = pd.get_dummies(df_cat, drop_first=True).columns.to_list()\n",
    "        else:\n",
    "            self._cat_cols_ohe = []\n",
    "        \n",
    "        num_cols = [col for col in train_df.columns if col not in self._cat_cols]\n",
    "        self._cols_after = num_cols + self._cat_cols_ohe\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        cols_before = df.columns.to_list()\n",
    "        assert set(cols_before) == set(self._cols_before), \"Do not have the same columns as train before transformed\"\n",
    "        \n",
    "        if len(self._cat_cols) == 0:\n",
    "            print(\"No cat cols in df_train, so do nothing.\")\n",
    "            return df[self._cols_after]\n",
    "        \n",
    "        df_cat = df[self._cat_cols]\n",
    "        #print(\"df_cat.columns\", df_cat.columns)\n",
    "        \n",
    "        # one-hot encode\n",
    "        df_cat = pd.get_dummies(df_cat)\n",
    "        # drop cols that are present in test_df but absent in train_df\n",
    "        cols_to_drop = [col for col in df_cat.columns if col not in self._cat_cols_ohe]\n",
    "        #print(\"cols_to_drop:\", cols_to_drop)\n",
    "        df_cat = df_cat.drop(cols_to_drop, axis=\"columns\")\n",
    "        \n",
    "        # change to float32\n",
    "        for col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].astype(\"float32\")\n",
    "        \n",
    "        # if some some colums are absent in test but present in train, make them all zero \n",
    "        cat_cols_ohe = df_cat.columns.to_list()\n",
    "        for col in self._cat_cols_ohe:\n",
    "            if col not in cat_cols_ohe:\n",
    "                df_cat[col] = 0\n",
    "                df_cat[col] = df_cat[col].astype(np.uint8)\n",
    "        \n",
    "        num_cols = [col for col in df.columns if col not in self._cat_cols]\n",
    "        cols_after = num_cols + df_cat.columns.to_list()\n",
    "        assert set(cols_after) == set(self._cols_after), \"Do not have the same columns as train after transformed\"\n",
    "        \n",
    "        df_num = df[num_cols]\n",
    "        \n",
    "        df = pd.concat([df_num, df_cat], axis=\"columns\")\n",
    "        # align columns\n",
    "        df = df[self._cols_after]\n",
    "        self._features = df.columns.to_list()\n",
    "        \n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df\n",
    "\n",
    "\n",
    "class UDLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_array=False):\n",
    "        self._to_array = to_array\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        self._train_cols = df_train.columns.to_list()\n",
    "        cat_cols = df_train.select_dtypes([\"category\", \"object\"]).columns.to_list()\n",
    "        \n",
    "        self._cat_col_idx = [i for i, col in enumerate(self._train_cols) if col in cat_cols]\n",
    "        \n",
    "        self._label_maps = {}\n",
    "        self._missing_imputers = {}\n",
    "        for col in cat_cols:\n",
    "            label = df_train[col].unique()\n",
    "            self._label_maps[col] = {c: n for n, c in enumerate(label)}\n",
    "            \n",
    "            mode_label = df_train[col].mode().iloc[0]\n",
    "            self._missing_imputers[col] = self._label_maps[col][mode_label]\n",
    "        \n",
    "        #print(\"Cols to label encode:\", list(self._label_maps.keys()))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        cols = df.columns.to_list()\n",
    "        assert set(cols) == set(self._train_cols), \"do not have the same set of columns as train\"\n",
    "        \n",
    "        for col, label_map in self._label_maps.items():\n",
    "            df[col] = df[col].map(label_map).astype(np.float32)\n",
    "            if df[col].isnull().any():\n",
    "                df[col] = df[col].astype(np.float32).fillna(self._missing_imputers[col])\n",
    "        \n",
    "        # align columns\n",
    "        df = df[self._train_cols]\n",
    "        \n",
    "        self._features = df.columns.to_list()\n",
    "        if self._to_array:\n",
    "            return df.values.astype(np.float32)\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "    def get_cat_cols(self):\n",
    "        return self._cat_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same_cols(df1, df2):\n",
    "    cols1 = df1.columns\n",
    "    cols2 = df2.columns\n",
    "    for c1, c2 in zip(cols1, cols2):\n",
    "        if c1 != c2:\n",
    "            print(c1, c2)\n",
    "    return None\n",
    "\n",
    "def col_align(df1, df2, to_array=False):\n",
    "    cols1 = df1.columns.to_list()\n",
    "    cols2 = df2.columns.to_list()\n",
    "    assert set(cols1) == set(cols2), \"df1 and df2 do not have the same set of columns\"\n",
    "    \n",
    "    if to_array:\n",
    "        return df1.values.astype(np.float32), df2[cols1].values.astype(np.float32)\n",
    "    else:\n",
    "        return df1, df2[cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean average precision at k\n",
    "def mapk(y, y_prob, k=7):\n",
    "    y = y[:, np.newaxis]\n",
    "    # ascending\n",
    "    y_pred = np.argsort(y_prob, axis=1)\n",
    "    # descending\n",
    "    y_pred = y_pred[:, ::-1]\n",
    "    \n",
    "    return ml_metrics.mapk(y, y_pred, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submit(y_prob, target_labels, ncodpers, filepath, k=7):\n",
    "    # ascending\n",
    "    y_pred = np.argsort(y_prob, axis=1)\n",
    "    # descending\n",
    "    y_pred = y_pred[:, ::-1]\n",
    "    # cut a k\n",
    "    y_pred = y_pred[:, :k]\n",
    "    \n",
    "    added_prods = target_labels[y_pred]\n",
    "    added_prods = [\" \".join(line) for line in added_prods]\n",
    "    \n",
    "    sub_df = pd.DataFrame(ncodpers)\n",
    "    sub_df[\"added_products\"] = added_prods\n",
    "    \n",
    "    sub_df.to_csv(filepath, index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_to_int(a_dict):\n",
    "    new_dict = copy.deepcopy(a_dict)\n",
    "    for k, v in new_dict.items():\n",
    "        if np.isclose(np.round(v), v):\n",
    "            new_dict[k] = int(new_dict[k])\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def run_hyperopt(classifier,\n",
    "                 params_tuned, \n",
    "                 X_train, y_train,\n",
    "                 X_val, y_val,\n",
    "                 num_eval,\n",
    "                 metric,\n",
    "                 params_fixed=None,\n",
    "                 rstate=None):\n",
    "    assert metric in [\"map7\", \"acc\"]\n",
    "    \n",
    "    time_start = time.time()\n",
    "    if params_fixed is None:\n",
    "        params_fixed = {\"n_jobs\": 20, \"n_estimators\": 100}\n",
    "    \n",
    "    def objective_map7(params):\n",
    "        classifier.set_params(**params_fixed, **params)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        y_val_prob = classifier.predict_proba(X_val)\n",
    "        map7 = mapk(y_val, y_val_prob, k=7)\n",
    "        \n",
    "        return {\"loss\": -map7, \"status\": STATUS_OK}\n",
    "    \n",
    "    def objective_acc(params):\n",
    "        classifier.set_params(**params_fixed, **params)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        y_val_pred = classifier.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        \n",
    "        return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "    \n",
    "    if metric == \"map7\":\n",
    "        print(\"Use map7\")\n",
    "        objective = objective_map7\n",
    "    else:\n",
    "        print(\"Use acc\")\n",
    "        objective = objective_acc\n",
    "    \n",
    "    if rstate is not None:\n",
    "        rstate = np.random.RandomState(rstate)\n",
    "        \n",
    "    trials = Trials()\n",
    "    best_params = fmin(objective, \n",
    "                      params_tuned, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate=rstate)\n",
    "    \n",
    "    best_params = whole_to_int(best_params)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_elapse = time_end - time_start\n",
    "    print(\"Time elapsed: %0.5f s\" % time_elapse)\n",
    "    \n",
    "    return trials, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIR = \"data/data1_\"\n",
    "SUB_DIR = \"data/submit_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before changing types 1036.11 MB\n",
      "Memory usage after changing types 497.64 MB\n",
      "Memory usage before changing types 101.92 MB\n",
      "Memory usage after changing types 48.92 MB\n",
      "Memory usage before changing types 2632.67 MB\n",
      "Memory usage after changing types 1267.08 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((364826, 355), (35887, 355), (929615, 354))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y_train_df = load_csv(os.path.join(INP_DIR, \"X_y_train.csv\"))\n",
    "X_y_val_df = load_csv(os.path.join(INP_DIR, \"X_y_val.csv\"))\n",
    "X_test_df = load_csv(os.path.join(INP_DIR, \"X_test.csv\"))\n",
    "\n",
    "X_y_train_df.shape, X_y_val_df.shape, X_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with most popular products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_popular_prods(y_train, X_test, out_filepath):\n",
    "    seven_most_popul = y_train.value_counts().index[:7].to_list()\n",
    "    seven_most_popul = \" \".join(seven_most_popul)\n",
    "    \n",
    "    sub_df = X_test[[\"ncodpers\"]].copy()\n",
    "    sub_df[\"added_products\"] = seven_most_popul\n",
    "    \n",
    "    sub_df.to_csv(out_filepath, index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filepath = os.path.join(SUB_DIR, \"popula_prods.csv\")\n",
    "\n",
    "# submiting this gives MAP@7 = 0.01580 for public and MAP@7 = 0.01589 for private score.\n",
    "predict_popular_prods(X_y_train_df[\"TARGET\"], X_test_df, out_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (364826, 353)\n",
      "y_train.shape (364826,)\n",
      "X_val.shape (35887, 353)\n",
      "y_val.shape (35887,)\n",
      "X_test.shape (929615, 353)\n",
      "Impute numerical cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "Impute cat cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "One-hot encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n",
      "Label encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((364826, 388), (35887, 388), (929615, 388))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_y_train_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "y_train = X_y_train_df[\"TARGET\"]\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "\n",
    "X_val = X_y_val_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_val.shape\", X_val.shape)\n",
    "y_val = X_y_val_df[\"TARGET\"]\n",
    "print(\"y_val.shape\", y_val.shape)\n",
    "\n",
    "X_test = X_test_df.drop([\"ncodpers\"], axis=1)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "ncodpers_test = X_test_df[\"ncodpers\"]\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "\n",
    "target_classes = le.classes_\n",
    "\n",
    "print(\"Impute numerical cols\")\n",
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_train)\n",
    "X_train = num_imputer.transform(X_train)\n",
    "X_val = num_imputer.transform(X_val)\n",
    "X_test = num_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute cat cols\")\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"One-hot encoding\")\n",
    "udohe = UDOneHotEncoder()\n",
    "udohe.fit(X_train)\n",
    "X_train = udohe.transform(X_train)\n",
    "X_val = udohe.transform(X_val)\n",
    "X_test = udohe.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Label encoding\")\n",
    "ud_le = UDLabelEncoder()\n",
    "ud_le.fit(X_train)\n",
    "X_train = ud_le.transform(X_train)\n",
    "X_val = ud_le.transform(X_val)\n",
    "X_test = ud_le.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.6251\n",
      "Validation acc: 0.6335\n",
      "Train MAP@7: 0.7746\n",
      "Validation MAP@7: 0.7782\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "y_train_prob = lr.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = lr.predict(X_val)\n",
    "y_val_prob = lr.predict_proba(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation acc: %0.4f\" %acc_val)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "map7_val = mapk(y_val, y_val_prob, k=7)\n",
    "print(\"Validation MAP@7: %0.4f\" %map7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.6248\n",
      "Train MAP@7: 0.7749\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_train_prob = lr.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "y_test_prob = lr.predict_proba(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "\n",
    "\n",
    "# submiting this gives MAP@7 = 0.02662 for public and MAP@7 = 0.02687 for private score.\n",
    "write_submit(y_test_prob, target_classes, ncodpers_test, \n",
    "             os.path.join(SUB_DIR, \"lr_d1.csv\"), k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (364826, 353)\n",
      "y_train.shape (364826,)\n",
      "X_val.shape (35887, 353)\n",
      "y_val.shape (35887,)\n",
      "X_test.shape (929615, 353)\n",
      "Impute numerical cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "Impute cat cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "One-hot encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n",
      "Label encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((364826, 388), (35887, 388), (929615, 388))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_y_train_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "y_train = X_y_train_df[\"TARGET\"]\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "\n",
    "X_val = X_y_val_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_val.shape\", X_val.shape)\n",
    "y_val = X_y_val_df[\"TARGET\"]\n",
    "print(\"y_val.shape\", y_val.shape)\n",
    "\n",
    "X_test = X_test_df.drop([\"ncodpers\"], axis=1)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "ncodpers_test = X_test_df[\"ncodpers\"]\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "\n",
    "target_classes = le.classes_\n",
    "\n",
    "print(\"Impute numerical cols\")\n",
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_train)\n",
    "X_train = num_imputer.transform(X_train)\n",
    "X_val = num_imputer.transform(X_val)\n",
    "X_test = num_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute cat cols\")\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"One-hot encoding\")\n",
    "udohe = UDOneHotEncoder()\n",
    "udohe.fit(X_train)\n",
    "X_train = udohe.transform(X_train)\n",
    "X_val = udohe.transform(X_val)\n",
    "X_test = udohe.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Label encoding\")\n",
    "ud_le = UDLabelEncoder(to_array=True)\n",
    "ud_le.fit(X_train)\n",
    "X_train = ud_le.transform(X_train)\n",
    "X_val = ud_le.transform(X_val)\n",
    "X_test = ud_le.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this runs too slowly\n",
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 30, 2)),\n",
    "    \"min_samples_split\": scope.int(hp.quniform(\"min_samples_split\", 10, 500, 20)),\n",
    "    \"min_samples_leaf\": scope.int(hp.quniform(\"min_samples_leaf\", 5, 200, 10)), \n",
    "    \"max_features\": scope.int(hp.quniform(\"max_features\", 20, 300, 10)),\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    \"n_jobs\": 20,\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 100\n",
    "metric = \"map7\"\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "trials, best_params = run_hyperopt(rf, params, \n",
    "                                   X_train, y_train, X_val, y_val, \n",
    "                                   num_eval, metric,\n",
    "                                   params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**params_fixed, **best_params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_train_prob = rf.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = rf.predict(X_val)\n",
    "y_val_prob = rf.predict_proba(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation acc: %0.4f\" %acc_val)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "map7_val = mapk(y_val, y_val_prob, k=7)\n",
    "print(\"Validation MAP@7: %0.4f\" %map7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fixed = {\n",
    "    \"n_jobs\": 20,\n",
    "    \"n_estimators\": 1000\n",
    "}\n",
    "\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7953\n",
      "Train MAP@7: 0.8915\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(**params_fixed, **best_params)\n",
    "rf.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_train_prob = rf.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_prob = rf.predict_proba(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "\n",
    "\n",
    "# submiting this gives MAP@7 = 0.02758 for public and MAP@7 = 0.02799 for private score.\n",
    "write_submit(y_test_prob, target_classes, ncodpers_test, \n",
    "             os.path.join(SUB_DIR, \"rf_d1.csv\"), k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (364826, 353)\n",
      "y_train.shape (364826,)\n",
      "X_val.shape (35887, 353)\n",
      "y_val.shape (35887,)\n",
      "X_test.shape (929615, 353)\n",
      "Impute numerical cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "Impute cat cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "One-hot encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n",
      "Label encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((364826, 388), (35887, 388), (929615, 388))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_y_train_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "y_train = X_y_train_df[\"TARGET\"]\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "\n",
    "X_val = X_y_val_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_val.shape\", X_val.shape)\n",
    "y_val = X_y_val_df[\"TARGET\"]\n",
    "print(\"y_val.shape\", y_val.shape)\n",
    "\n",
    "X_test = X_test_df.drop([\"ncodpers\"], axis=1)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "ncodpers_test = X_test_df[\"ncodpers\"]\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "\n",
    "target_classes = le.classes_\n",
    "\n",
    "print(\"Impute numerical cols\")\n",
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_train)\n",
    "X_train = num_imputer.transform(X_train)\n",
    "X_val = num_imputer.transform(X_val)\n",
    "X_test = num_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute cat cols\")\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"One-hot encoding\")\n",
    "udohe = UDOneHotEncoder()\n",
    "udohe.fit(X_train)\n",
    "X_train = udohe.transform(X_train)\n",
    "X_val = udohe.transform(X_val)\n",
    "X_test = udohe.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Label encoding\")\n",
    "ud_le = UDLabelEncoder(to_array=True)\n",
    "ud_le.fit(X_train)\n",
    "X_train = ud_le.transform(X_train)\n",
    "X_val = ud_le.transform(X_val)\n",
    "X_test = ud_le.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use map7\n",
      "100%|██████████| 50/50 [17:50:39<00:00, 1284.80s/trial, best loss: -0.7876664450716335]  \n",
      "Time elapsed: 64239.86104 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8714541979195253,\n",
       " 'learning_rate': 0.01839666166429914,\n",
       " 'max_depth': 11,\n",
       " 'min_child_weight': 12,\n",
       " 'reg_lambda': 0.0001365632931605928,\n",
       " 'subsample': 0.913070589798433}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 2, 14, 1)),\n",
    "    \"min_child_weight\": scope.int(hp.quniform(\"min_child_weight\", 1, 20, 1)), \n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.4, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 1.0),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", np.log(0.000001), np.log(100)),\n",
    "    #\"reg_alpha\": hp.loguniform(\"reg_alpha\", np.log(0.001), np.log(1000)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.001), np.log(1.)),\n",
    "    #\"gamma\": hp.uniform(\"gamma\", 0., 5.),\n",
    "}\n",
    "\n",
    "params_fixed = {\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "    \"n_estimators\": 500\n",
    "}\n",
    "\n",
    "num_eval = 50\n",
    "metric = \"map7\"\n",
    "xgb = XGBClassifier()\n",
    "trials, best_params = run_hyperopt(xgb, params, \n",
    "                                   X_train, y_train, X_val, y_val, \n",
    "                                   num_eval, metric,\n",
    "                                   params_fixed=params_fixed)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'colsample_bytree': 0.8714541979195253,\n",
    " 'learning_rate': 0.01839666166429914,\n",
    " 'max_depth': 11,\n",
    " 'min_child_weight': 12,\n",
    " 'reg_lambda': 0.0001365632931605928,\n",
    " 'subsample': 0.913070589798433}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.6606\n",
      "Validation acc: 0.6475\n",
      "Train MAP@7: 0.7980\n",
      "Validation MAP@7: 0.7877\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(**params_fixed, **best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "y_train_prob = xgb.predict_proba(X_train)\n",
    "\n",
    "y_val_pred = xgb.predict(X_val)\n",
    "y_val_prob = xgb.predict_proba(X_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation acc: %0.4f\" %acc_val)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "map7_val = mapk(y_val, y_val_prob, k=7)\n",
    "print(\"Validation MAP@7: %0.4f\" %map7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.6596\n",
      "Train MAP@7: 0.7978\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(**params_fixed, **best_params)\n",
    "xgb.fit(np.concatenate([X_train, X_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "y_train_prob = xgb.predict_proba(X_train)\n",
    "\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "y_test_prob = xgb.predict_proba(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "\n",
    "map7_train = mapk(y_train, y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "\n",
    "\n",
    "# submiting this gives MAP@7 = 0.02870 for public and MAP@7 = 0.02899 for private score.\n",
    "write_submit(y_test_prob, target_classes, ncodpers_test, \n",
    "             os.path.join(SUB_DIR, \"xgb_d1.csv\"), k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (364826, 353)\n",
      "y_train.shape (364826, 1)\n",
      "X_val.shape (35887, 353)\n",
      "y_val.shape (35887, 1)\n",
      "X_test.shape (929615, 353)\n",
      "Impute numerical cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "Impute cat cols\n",
      "(364826, 353) (35887, 353) (929615, 353)\n",
      "One-hot encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n",
      "Label encoding\n",
      "(364826, 388) (35887, 388) (929615, 388)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((364826, 388), (35887, 388), (929615, 388))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_y_train_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "y_train = X_y_train_df[[\"TARGET\"]]\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "\n",
    "X_val = X_y_val_df.drop([\"ncodpers\", \"TARGET\"], axis=1)\n",
    "print(\"X_val.shape\", X_val.shape)\n",
    "y_val = X_y_val_df[[\"TARGET\"]]\n",
    "print(\"y_val.shape\", y_val.shape)\n",
    "\n",
    "X_test = X_test_df.drop([\"ncodpers\"], axis=1)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "ncodpers_test = X_test_df[\"ncodpers\"]\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(y_train)\n",
    "y_train = ohe.transform(y_train).toarray()\n",
    "y_val = ohe.transform(y_val).toarray()\n",
    "\n",
    "target_classes = ohe.categories_[0]\n",
    "\n",
    "\n",
    "print(\"Impute numerical cols\")\n",
    "num_imputer = NumImputer()\n",
    "num_imputer.fit(X_train)\n",
    "X_train = num_imputer.transform(X_train)\n",
    "X_val = num_imputer.transform(X_val)\n",
    "X_test = num_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Impute cat cols\")\n",
    "cat_imputer = CatImputer()\n",
    "cat_imputer.fit(X_train)\n",
    "X_train = cat_imputer.transform(X_train)\n",
    "X_val = cat_imputer.transform(X_val)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"One-hot encoding\")\n",
    "udohe = UDOneHotEncoder()\n",
    "udohe.fit(X_train)\n",
    "X_train = udohe.transform(X_train)\n",
    "X_val = udohe.transform(X_val)\n",
    "X_test = udohe.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "print(\"Label encoding\")\n",
    "ud_le = UDLabelEncoder()\n",
    "ud_le.fit(X_train)\n",
    "X_train = ud_le.transform(X_train)\n",
    "X_val = ud_le.transform(X_val)\n",
    "X_test = ud_le.transform(X_test)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               38900     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22)                2222      \n",
      "=================================================================\n",
      "Total params: 61,322\n",
      "Trainable params: 61,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_shape = X_train.shape[-1:]\n",
    "output_shape = y_train.shape[-1]\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(100, input_shape=input_shape, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(output_shape, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=5e-4)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 1.1126 - acc: 0.6139 - val_loss: 0.9919 - val_acc: 0.6322\n",
      "Epoch 2/100\n",
      "5701/5701 [==============================] - 24s 4ms/step - loss: 1.0347 - acc: 0.6295 - val_loss: 0.9847 - val_acc: 0.6355\n",
      "Epoch 3/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 1.0175 - acc: 0.6325 - val_loss: 0.9789 - val_acc: 0.6348\n",
      "Epoch 4/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 1.0064 - acc: 0.6353 - val_loss: 0.9820 - val_acc: 0.6397\n",
      "Epoch 5/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9994 - acc: 0.6359 - val_loss: 0.9710 - val_acc: 0.6423\n",
      "Epoch 6/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9930 - acc: 0.6367 - val_loss: 0.9730 - val_acc: 0.6389\n",
      "Epoch 7/100\n",
      "5701/5701 [==============================] - 24s 4ms/step - loss: 0.9882 - acc: 0.6372 - val_loss: 0.9810 - val_acc: 0.6343\n",
      "Epoch 8/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9842 - acc: 0.6385 - val_loss: 0.9821 - val_acc: 0.6357\n",
      "Epoch 9/100\n",
      "5701/5701 [==============================] - 24s 4ms/step - loss: 0.9801 - acc: 0.6395 - val_loss: 0.9798 - val_acc: 0.6399\n",
      "Epoch 10/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9760 - acc: 0.6399 - val_loss: 0.9961 - val_acc: 0.6290\n",
      "Epoch 11/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9735 - acc: 0.6404 - val_loss: 0.9816 - val_acc: 0.6386\n",
      "Epoch 12/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9708 - acc: 0.6410 - val_loss: 0.9799 - val_acc: 0.6418\n",
      "Epoch 13/100\n",
      "5701/5701 [==============================] - 24s 4ms/step - loss: 0.9683 - acc: 0.6413 - val_loss: 0.9892 - val_acc: 0.6383\n",
      "Epoch 14/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9655 - acc: 0.6418 - val_loss: 0.9838 - val_acc: 0.6393\n",
      "Epoch 15/100\n",
      "5701/5701 [==============================] - 25s 4ms/step - loss: 0.9634 - acc: 0.6411 - val_loss: 1.0018 - val_acc: 0.6363\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, monitor=\"val_acc\", mode=\"max\", \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100, batch_size=64,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6e776c2d10>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(history.history[\"loss\"], label=\"loss\")\n",
    "ax[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history[\"acc\"], label=\"acc\")\n",
    "ax[1].plot(history.history[\"val_acc\"], label=\"val_acc\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.6377\n",
      "Validation acc: 0.6423\n",
      "Train MAP@7: 0.7830\n",
      "Validation MAP@7: 0.7828\n"
     ]
    }
   ],
   "source": [
    "_, acc_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Train acc: %0.4f\" %acc_train)\n",
    "_, acc_val = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"Validation acc: %0.4f\" %acc_val)\n",
    "\n",
    "y_train_prob = model.predict(X_train)\n",
    "y_val_prob = model.predict(X_val)\n",
    "\n",
    "map7_train = mapk(np.argmax(y_train, axis=1), y_train_prob, k=7)\n",
    "print(\"Train MAP@7: %0.4f\" %map7_train)\n",
    "map7_val = mapk(np.argmax(y_val, axis=1), y_val_prob, k=7)\n",
    "print(\"Validation MAP@7: %0.4f\" %map7_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for `2016-06`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model.predict(X_test)\n",
    "\n",
    "# submiting this gives MAP@7 = 0.02752 for public and MAP@7 = 0.02768 for private score.\n",
    "write_submit(y_test_prob, target_classes, ncodpers_test, \n",
    "             os.path.join(SUB_DIR, \"nn_d1.csv\"), k=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
